
































 
    
       
            
       
       
       
      
         




















 
 




















observationObservation


claimClaim

factFact

assumptionAssumption
noteNote
lieLie theory derivation
















 
 
 
 
 

 
 
 
 
 
 
 
 
 
 




 
 
 

 
 
 
 
 


 


























































mycomment












M>X<L>r<Bayes Complexity of Learners vs Overfitting]Bayes Complexity of Learners vs OverfittingGrzegorz GÅ‚uchgrzegorz.gluch@epfl.ch
Ruediger Urbankeruediger.urbanke@epfl.ch
 EPFL, Lausanne, Switzerland[
    Hiroshi C. Watanabe
    March 30, 2023
=======================




We introduce a new notion of complexity
of functions and we show that it has the following properties: (i) it governs a PAC Bayes-like generalization bound, (ii) for neural networks it relates to natural notions of complexity of functions (such as the variation), and (iii) it explains the generalization gap between neural networks
and linear schemes. While there is a large set of papers which describes bounds that 
have each such property in isolation, and even some that have two, as far as we know, this is a first notion that satisfies all three of them. Moreover, in contrast to previous works, our notion naturally generalizes to neural networks with several layers. 

Even though the computation of our complexity is nontrivial in general, an upper-bound is often easy to derive, even for higher number of layers and functions with structure, such as period functions. 
An upper-bound we derive allows to show a separation in the number of samples needed for good generalization between 2 and 4-layer neural networks for periodic functions. 





Â§ INTRODUCTION

There is a large body of literature devoted to the question of generalization, both from a practical point of view as well as concerning our theoretical understanding, e.g., <cit.>, to mention just a few. We add to this discussion. In particular, we ask what role is played by the hypothesis class assuming a Bayesian point of view. Our main observation is that there is a striking theoretical difference between linear schemes and neural networks. In a nutshell, neural networks, when trained with appropriate gradient methods using a modest amount of training data, strongly prefer hypothesis that are â€œeasyâ€ to represent in the sense that there is a large parameter space that approximately represents this hypothesis. For linear schemes no such preference exists. This leads us to a notion of a complexity of a function with respect to a given hypothesis class and prior. We then show that (i) this complexity is the main component in a standard PAC-Bayes bound, and (ii) that the ordering implied by this complexity corresponds well to â€œnaturalâ€ notions of complexity of functions that have previously been discussed in the literature. In words, neural networks learn â€œsimpleâ€ functions and hence do not tend to overfit.

For n âˆˆ we define [n] = {1,â€¦,n}. Let  be the input space,  be the output space and := Ã— be the sample space. Let â„‹_Î¸ be the hypothesis class, parameterized by Î¸âˆˆâ„^m. We define the loss as a function â„“: â„‹Ã—â†’_+. We focus on the clipped to C version of the quadratic loss but our results can be generalized to other loss functions. We denote by _x a distribution on the input space , and by  a distribution on the sample space . Finally, we let ={z_1, â‹¯ z_N} be the given sample set, where we assume that the individual samples are chosen iid according to the distribution ğ’Ÿ.



 Â§.Â§ The PAC Bayes Bound

Our starting point is a version of the well-known PAC-Bayes bound, see <cit.>.

Let the loss function â„“ be bounded, i.e., â„“: â„‹Ã—ğ’µâ†’ [0, C]. 
Let P be a prior on â„‹ and Q be any other distribution on â„‹ (possibly dependent on ). Then 

    _[L_ğ’Ÿ(Q)]  â‰¤_[ L_(Q) + Câˆš(D(Q  P)/2N)],

where

    L_ğ’Ÿ(Q)     = _z âˆ¼ğ’Ÿ; h âˆ¼ Q[â„“(h, z)],

    L_(Q)     = _ h âˆ¼ Q[1/Nâˆ‘_n=1^Nâ„“(h, z_i)],

and the divergence D(Q  P) is defined as

    D(Q P) = âˆ« Q logQ/P.

There is a large body of literature that discusses use cases, interpretations, and extensions of this bound. Let us just mention a few closely related works.

A related prior notion is that of flat minima. These are minimizers in the parameter space that are surrounded by many functions with similarly small empirical error. The reason for this connection is straightforward. In order for Q to give a good bound two properties have to be fullfilled: (i) Q must be fairly broad so that D(Q  P) is not too large (afterall, P must be broad since we do not know the function a priori), and (ii) Q must give rise to a low expected empirical error. These properties are exactly the characteristics one expects from a flat minimum. The importance of such minima was recognized early on, see e.g., <cit.> and <cit.>. More recently <cit.> and <cit.> derive from this insight an algorithm for training discrete neural networks that explicitly drives the local search towards non-isolated solution. Using a Bayesian approach they argue that these minima have good generalization. Building on these ideas <cit.> give an algorithm with the aim to directly optimize (<ref>). They demonstrate empirically that the distributions Q's they find give non-vacuous generalization bounds. 

To summarize, the bound (<ref>) can be used in various ways. In the simplest case, given a prior P and an algorithm that produces a â€œposteriorâ€Q, (<ref>) gives a probabilistic upper bound on the average true risk if we sample the hypothesis according to Q. But (<ref>) can also be taken as the starting point of an optimization problem. Given a prior distribution P one can in principle look for the posterior Q that gives the best such bound. Further, one can split the available data and use one part to find a suitable prior P and the remaining part to define a that posterior Q distribution that minimizes this bound.  

We take the PAC-Bayes bound as our starting point. We impose a Gaussian distribution on the weights of the model. This defines our prior P. In principle other priors can be used for our approach but a Gaussian is the most natural choice and it illustrates the main point of the paper in the cleanest fashion. Further, we postulate that the samples z_n=(x_n, y_n) are iid and, assuming that the true parameter is Î¸, come from the stochastic model


    x_n â†¦ y_n = f_Î¸(x_n) + Î·_n, Î·_n âˆ¼ğ’©(0,Ïƒ_e^2).

In words, we assume that the actual underlying function is  realizable, that we receive noisy samples, and that the noise is Gaussian and independent from sample to sample.  

This gives rise to the posterior distribution,

    Q(Î¸) = P(Î¸) e^- 1/2 Ïƒ_y^2âˆ‘_n=1^N (y_n - f_Î¸(x_n))^2/âˆ« P(Î¸') e^- 1/2 Ïƒ_y^2âˆ‘_n=1^N (y_n - f_Î¸'(x_n))^2 d Î¸'.

One valid criticism of this approach is that it is model dependent. But there is a significant payoff. First recall that this posterior can at least in principle be sampled by running the SG algorithm with Langevin dynamics. For the convenience of the reader we include in SectionÂ <ref> a short review. Most importantly, taking this point of view a fairly clear picture arises why neural networks tend not to overfit. In a nutshell, if we sample from this posterior distribution then we are more likely to sample â€œsimpleâ€ functions. The same framework also shows that this is not the case for linear schemes.
 


 Â§.Â§ Stochastic Gradient Langevin Dynamics

We follow <cit.>. Assume that we are given the data set

    = {z_1, â‹¯, z_N} = {(x_1, y_1), â‹¯, (x_N, y_N)},

where the samples z_n=(x_n, y_n), n=1, â‹¯, N, are chosen iid according to an unknown distribution . We model the relationship between x and y probabilistically in the parametrized form

    y âˆ¼ p(y | x, Î¸).

We use the log-loss 

    _Î¸(x, y) = - ln p(y | x, Î¸).

Assume further that we use the  stochastic gradient Langevin descent (SGLD) algorithm:

    Î¸^(t)   = Î¸^(t-1) - Î·_Z âˆ¼[âˆ‡_Î¸_Î¸(X, Y) - 1/Nln P(Î¸) ] 
       + âˆš(2 Î·/N)ğ’©(0, I),

where t = 1, 2, â‹¯;  Î·>0 is the learning rate, P(Î¸) is the density of the prior, and ğ’©(0, I) denotes a zero-mean Gaussian vector of dimension dim(Î¸) with iid components and variance 1 in each component.





Note that due to the injected noise, the distribution of Î¸ at time Ï„, call it Ï€_Ï„(Î¸), converges to the posterior distribution of Î¸ given the data, i.e., it converges to 

    p(Î¸|{z_1, â‹¯, z_N}) 
    = p(Î¸, {z_1, â‹¯, z_N})/p({z_1, â‹¯, z_N})
       =
    P(Î¸) p({z_1, â‹¯, z_N}|Î¸)/p({z_1, â‹¯, z_N})
        =P(Î¸) âˆ_n=1^N p(y_n | x_n, Î¸)/âˆ_n=1^N p(y_n | x_n)âˆ P(Î¸) âˆ_n=1^N p(y_n | x_n, Î¸).

This is shown in <cit.>. In the sequel we use the more common notation p_Î¸(y_n | x_n) instead of p(y_n | x_n, Î¸). This makes a clear distinction between the parameters of the model and the samples we received.

A few remarks are in order. An obvious choice from a theoretical point of view is to use an iid Gaussian prior. In practice it is best not to use iid Gaussian prior in order to speed up the convergence. Indeed, the main point of <cit.> is to discuss suitable schemes. But for our current conceptual purpose we will ignore this (important) practical consideration. 



Â§ THE PAC BAYES BOUND AND BAYES COMPLEXITY

Let us now get back to the main point of this paper. We start by defining two notions of complexity. Both of them are â€œBayesâ€ complexities in the sense that both relate to the size of the parameter space (as measured by a prior) that approximately represents a given function. We will then see how this complexity enters the PAC-Bayes bound.



  
Contribution. Our main contribution is an introduction of a new notion of complexity of functions and we show that it has the following properties: (i) it governs a PAC Bayes-like generalization bound, (ii) for neural networks it relates to natural notions of complexity of functions, and (iii) it explains the generalization gap between neural networks and linear schemes in some regime. While there is a large set of papers which describes each such criterion, and even some that fulfill both (e.g., <cit.>), as far as we know, this is a first notion that satisfies all three of them. 


For every > 0 we define the sharp complexity of a function g with respect to the hypothesis class â„‹_Î¸ as

    Ï‡^#(â„‹_Î¸, g, _x, ^2)    := -log[ _Î¸{Î¸ : _x âˆ¼_x [(g(x) - f_Î¸(x))^2] â‰¤^2 }],

where the probability _Î¸ is taken wrt to the prior P.


In words, we compute the probability, under prior P, of all these functions f_Î¸ that are close to g under the quadratic loss and distribution _x.

In general, it is difficult to compute Ï‡^# for a given
Ïµ.  However, for realizable functions it is often possible to compute
the limiting value of the sharp complexity, properly normalized, when Ïµ
tends to 0.

We define the sharp complexity of a function g with respect to the hypothesis class

    Ï‡^#(â„‹_Î¸, g, _x)     := lim_Ïµâ†’ 0log[_Î¸{Î¸: _x âˆ¼_x[ (g(x) - f_Î¸(x))^2 ] â‰¤^2 }]/log().


The above definitions of complexity implicitly depend on the hypothesis class â„‹_Î¸. If the hypothesis class (and/or _x) is clear from context we will omit it from notation, e.g. Ï‡^#(g, ^2) = Ï‡^#(g, _x, ^2) = Ï‡^#(â„‹_Î¸, g, _x, ^2). 

We now state the main theorem. It is a generalization bound, which crucially depends on the sharp complexity from DefinitionÂ <ref>. The proof is deferred to AppendixÂ <ref>.


If L_(P) â‰¥ 2Ïƒ_e^2 and g âˆˆsupp(P) then for every Î²âˆˆ (0,1] there exists Ïƒ_alg^2 such that if we set Ïƒ_y^2 = Ïƒ_alg^2 then _âˆ¼^N[L_S(Q(Ïƒ_y^2))] = (1+Î²)Ïƒ_e^2 and

    _âˆ¼^N[L_(Q(Ïƒ_y^2))]
       â‰¤Ïƒ_e^2 + [ Î²Ïƒ_e^2 + C/âˆš(2)âˆš(Ï‡^#(g, _x, Î²Ïƒ_e^2)/N)].


  
Discussion of Assumptions.
Requiring that g âˆˆsupp(P) is only natural as it indicates that g is realizable with prior P. It is also natural to assume that L_(P) â‰¥ 2Ïƒ_e^2 as the lowest possible error is attained by g and is equal Ïƒ_e^2. Thus we require that the expected loss over the prior is twice as big as the minimal one. As P should cover a general class of functions it is only natural that L_(P) â‰¥ 2Ïƒ_e^2.

For a fixed Î², Ïƒ_alg^2 from TheoremÂ <ref> is, in general, not known. However, as proven in AppendixÂ <ref>, we have
lim_Ïƒ_y^2 â†’ 0_âˆ¼^N[L_(Q(Ïƒ_y^2))]= Ïƒ_e^2,   lim_Ïƒ_y^2 â†’âˆ_âˆ¼^N[L_(Q(Ïƒ_y^2))]= 2Ïƒ_e^2.

Moreover, _âˆ¼^N[L_(Q(Ïƒ_y^2))] is continuous in Ïƒ_y^2, which implies that Ïƒ_alg^2 can be found by a binary search-like procedure by holding out some part of  for estimating _âˆ¼^N[L_(Q(Ïƒ_y^2))] for different Ïƒ_y^2 values.



  
Bound (<ref>) in terms of limiting complexity.  Notice that (<ref>) is governed by 
Ï‡^#(g,_x,Î²Ïƒ_e^2). Aaccording to (<ref>), for small enough Î²Ïƒ_e^2, we have

    Ï‡^#(g,_x,Î²Ïƒ_e^2) â‰ˆ -Ï‡^#(g,_x)log(Î²Ïƒ_e^2).

This means that for small enough noise level, where the exact regime for which the approximation holds depends on a specific problem, we have

    _âˆ¼^N[L_(Q(Ïƒ_y^2))]
    âª…
    (1 + Î²) Ïƒ_e^2 + C/âˆš(2)âˆš(-Ï‡^#(g, _x)log(Î²Ïƒ_e^2)/N).

We see that the generalization bound depends crucially on the limiting complexity. 




  
Main message. 
Note that the smallest we can hope to get on the right hand side is Ïƒ_e^2 since this is the variance of the noise and this is achievable if we pick Q that puts all its mass on g.
This means that Î²Ïƒ_e^2 plus the square root term from (<ref>) represents the expected excess generalization error. 

This brings us to the punch line of this paper. In the subsequent sections we will see that
(i) natural notions of complexity that have previously been discussed in the literature align with our new notion when we consider neural networks, whereas 
(ii) for linear schemes our notion of complexity is essentially independent of the function (as long as it is realizable) and as a consequence is as high as for the most complex (in the natural sense) function in our hypothesis class.

To the degree that we assume that reality prefers simple functions this explains why neural nets generalize significantly better than linear schemes.

In SectionÂ <ref> we show that for neural networks and a piece-wise linear function g the limiting complexity is equal to the number of slope changes g. In light of (<ref>), this means that neural networks require the fewer samples (for a good generalization bound) the fewer slope changes g has.

There is a further connection to a natural notion of complexity. In SectionÂ <ref> we show that sharp complexity is related to the variation of g, i.e. the integral of the second derivative of g. Thus, in the light of (<ref>), fewer samples are needed (for a good generalization) for g's with smaller variation.

As we discussed above, sharp and limiting complexity are related via (<ref>) when Î²Ïƒ_e^2 is small. We can thus think of sharp complexity as a refinement of limiting complexity. This is reflected in the two cases discussed above â€“ the number of slope changes can be seen as an approximation of the variation of a function.

In SectionÂ <ref>, on the other hand, we show that for linear schemes the limiting complexity is virtually independent of the function and equal to the number of basis functions. This means that in this case the number of samples needed for a good generalization bound is the same for simple and complicated functions.













Â§ MODELS


Although the basic idea applies to any parametric family, we will consider restricted types of families and demonstrate our concepts with two concrete examples, namely linear schemes and NNs. We will be interested in parametric families of functions from  to . More precisely families of the form â„‹_Î¸ := {_Î¸ : , Î¸âˆˆ^m },
where Î¸ is the vector of parameters. for a function g : â†’ and a distribution _x we define the set of exact representations as A_g,â„‹,_x := {Î¸âˆˆ^m : f_Î¸â‰¡_(_x) g }. If â„‹ and _x are clear from context we will often write A_g. The 0 function will play an important role, thus we also define A_0 := {Î¸âˆˆ^m : f_Î¸â‰¡_(_x) 0 }

 Â§.Â§ Linear Schemes

Consider the linear family _Î¸^(L, o)={f_Î¸(x): f_Î¸(x) = âˆ‘_i=0^d-1_i b_i(x), x âˆˆ = [-1, 1]},
i.e., the vector of parameters Î¸ is equal to the vector of weights . We assume that the functions {b_i(x)} form an orthonormal basis.
Although the exact basis that is used is not of importance one might think of b_i(x) as a polynomial of degree i or the first few Legendre polynomials. In this way the basis functions are naturally ordered by complexity. 




 Â§.Â§ Neural Networks

Consider the family ^NN represented by NNs with layers numbered from 0 (input) to K (output), containing d = d_0, d_1, â€¦, and d_K = d_y neurons respectively. We will limit our attention to d_y = 1. The activation functions for the layers 1 to K are presumed to be Ïƒ_1, â€¦, Ïƒ_K :. The weight matrices will be denoted by W^(1), W^(2), â€¦, W^(K), respectively, where matrix  W^(k) connects layer k-1 to layer k. We define 

    _Î¸(x) := Ïƒ_K (^(K) + W^(K)Ïƒ_K-1( â€¦Ïƒ_1(^(1) + W^(1) x ))) .


Â§ WHY NEURAL NETS GENERALIZE WELL

We now get to the main point of this paper, namely why neural nets generalize much better than other schemes, in particular linear schemes.

The basic idea is simple. We have seen in the previous sections that (i) a suitable version of SGD gives us a posterior of the form (<ref>), and (ii) this posterior gives rise to a an upper bound on the generalization error that depends mainly on the â€œcomplexityâ€ of the underlying true hypothesis.

This notion of complexity of a function depends on the underlying hypothesis class.
To close the circle we will now discuss how this complexity behaves for interesting hypothesis classes. In particular, as we will see that there is a striking difference between linear schemes and neural networks. For linear schemes, every realizable function has essentially the same complexity. This in particular means that we do not expect to learn a â€œsimpleâ€ function (e.g., think of a constant function) with fewer samples than a â€œcomplexâ€ one (think of a highly variable one). For neural nets the complexity behaves entirely differently and there is a large dynamic range. As we will see, in a suitable limit the complexity is to first order determined by the number of degrees of freedom that have to be fixed in order to realize a function. Therefore, for neural nets, simple functions have a much lower complexity than complicated ones. 



 Â§.Â§ Neural Networks with a Single Hidden Layer


We start with analyzing our notion of complexity for the case of NN with a single hidden layer and 1-dimensional input. More precisely let x âˆˆ denote the input and y âˆˆ denote the output.  There are k nodes in the hidden layer. More precisely, the network represents the function
 
    f_Î¸(x) 
        = âˆ‘_i=1^k _i^(2)Ïƒ( _i^(1) x + _i^(1))  + b^(2)
        = âˆ‘_i=1^k _i^(2)[ _i^(1) x + _i^(1)]_+ + b^(2),

i.e., we use ReLU activation functions. 

The _i^(1) denotes the bias of the i-th node, the _i^(2) represents the weight of the i-th output signal, and b^(2) is the global bias term of the output. We let Î¸ = (Î¸_w, Î¸_b) = ((^(1), ^(2)), (^(1), b^(2))) denote the set of all parameters, where Î¸_w denotes the set of weights and Î¸_b denotes the set of bias terms.



  
Parametrization and prior. We will use the following non-standard parametrization of the network

    f_Î¸(x) 
       = âˆ‘_i=1^k _i^(2)[_i^(1)(x - _i^(1)) ]_+ + b^(2)
       = âˆ‘_i=1^k _i^(2)Â·|_i^(1)| Â·[sgn(_i^(1))( x - _i^(1))]_+ + b^(2),

where in the last equality we used the fact that the ReLU activation function is 1-homogenous. Note that there are two kinds of ReLU functions (depending on the sign of w_i^(1)) they are either of the form [x -b]_+ or 0 at [-(x-b)]_+. If we restrict our attention to how f_Î¸ behaves on a compact interval then considering just one of the kinds gives us the same expressive power as having both. This is why for the rest of this section we restrict our attention only to the case of [x-b]_+ as it simplifies the proofs considerably. Thus the final parametrization we consider is

f_Î¸(x) = âˆ‘_i=1^k _i^(2)Â·_i^(1)[x - _i^(1)]_+ + b^(2).


We define the prior on Î¸ as follows: each component of Î¸_w comes i.i.d. from ğ’©(0,Ïƒ_y^2), each component of ^(1) comes i.i.d. from U([0,M]), where M will be fixed later and b^(2) comes i.i.d. from ğ’©(0,Ïƒ_b^2)[The different parametrization and the uniform prior on the bias terms are non-standard choices that we make to simplify the proofs. These choices would not affect the spirit of our results but as always the details need to be verified.].

We will argue that our notion of complexity (Ï‡^#(_x,g,^2) 
and Ï‡^#(_x,g)) corresponds, in a case of NN, to natural notions of complexity of functions. 






  
Target function. We will be interested in target functions g that are representable with a single hidden layer networks. Let g : [0, 1] be continuous and piece-wise linear. I.e., there is a sequence of points 0=t_1 < t_2 < â‹¯ < t_l+1=1 so that for x âˆˆ [t_i, t_i+1], 1 â‰¤ i < l+1,

    g(x) = c_i + Î±_i (x-t_i),

for some constants c_i and Î±_i, where c_i+1 = c_i + Î±_i (x_i+1-x_i). Then f can be written as a sum of ReLU functions, 

    g(x) = b + âˆ‘_i=1^l v_i [x-t_i]_+,

where v_1=Î±_1 and v_i=Î±_i-Î±_i-1, i=2, â‹¯, l. The terms in (<ref>) for which v_i = 0 can be dropped without changing the function. We call the number of nonzero v_i's in (<ref>) to be the number of changes of slope of g. 


  *  Start with the fundamental questions of generalization and review various papers.

  *  Say what the overall idea is, namely NNs with regularizer minimizes the sum of the  complexity of the function plus loss.
    
  *  Start with Srebo paper that says that for a one-hidden NN minimizing the loss plus the square of the norm is equal to finding a hypothesis so that the sum of the loss plus complexity are minimized.
    
    
  *  We show that, suitably generalized, a similar picture emerges for the "general" case.
    
  *  We consider a general network.
        
  *  We consider the SGLD.
        
  *  We impose a Gaussian prior on the weights.
    
  *  We then show that the general measure of complexity is given by the "Bayesian" complexity of a function (need a better word). I.e., in general, the samples we get from the SGLD are such that they minimize the sum of two exponents, one coming from the approximation error and one from the complexity measure.
    
  *  The multiplicity complexity measure is naturally connected to several other perhaps more intuitive complexity measures. E.g., the initial scheme is one example but it would be nice to find at least one other example (perhaps the square functions)
    
  *  We show that if we apply the same framework to linear schemes the complexity measure does not behave in the same way, giving a strong indication why overfitting does not happen to the same degree for NNs.
    
  *  We show what happens if we add layers to a network.
    
  *  We explore the role of dropout (not so sure if we can do this; what does this mean for the dynamics?)


  Â§.Â§.Â§ Complexity in the Asymptotic Case

In this section we explore what is the limiting value of the sharp complexity for the case of NN.


Assume that we are given a Gaussian vector  of length ,
with mean , and with covariance matrix  that has full rank.  Let âˆˆ^.  Let _1, c and _1, c denote the
restrictions of  and  to the first c components and
let _c+1, denote the restriction of  to the
last -c components. Finally, let R âŠ†^-c
be a set of strictly positive Lebesgue measure.  Then

    lim_Ïµâ†’ 0log[{{: _c+1, âˆˆ R âˆ§_1, c-_1, c_2 â‰¤Ïµ}]/log(Ïµ) = c.

Before we proceed to the proof let us quickly discuss how we will apply this observation. Assume that we can represent a given function g(x) exactly within a model _Î¸ by fixing c of the components to a definite value and that the remaining -c components
can be chosen within a range that does not depend on Ïµ. This is e.g. the case for neural networks. Due to the non-linearity some parameters can range freely without changing the function. Assume further, that the model has a finite derivative with respect to each of the c fixed values.  For Gaussian prior we have by LemmaÂ <ref> that the complexity of this function is c. In the above discussion we implicitly assumed that the function has a unique representation. But, as we will discuss in SectionÂ <ref> and in in the appendix, in general, realizable functions do have many representations. Besides the discrete symmetries inherent in many models there are also continuous symmetries that often arise. E.g., the output of a single ReLU can be exactly replicated by the sum of several ReLU functions. Nevertheless, even though the actual probability for a fixed Ïµ can be significantly larger due to this multiplicity, the asymptotic limit remains the same Is it clear?.

Let us start by assuming that the Gaussian distribution has iid components. In this case the probability factors into the probability that the last k-c components are contained in the region R, which by assumption is a strictly positive number, independent of Ïµ and the probability that the first c components are contained in a ball of radius Ïµ around a fixed point. Note that this second probability behaves like ÎºÏµ^c, where Îº is strictly positive and does not depend on Ïµ. The result follows by taking the log, dividing by log(Ïµ) and letting Ïµ tend to 0. 

The general case is similar. Write 

    {: _c+1, âˆˆ R âˆ§_1, c-_1, c_2 â‰¤Ïµ}
       = âˆ«__c+1, kâˆˆ Râˆ«__1, c-_1, c^*â‰¤Ïµ f(_1, c, _c+1, k) 
        = âˆ«__c+1, kâˆˆ R f(_c+1, k) âˆ«__1, c-_1, c^*â‰¤Ïµ  f(_1, c|_c+1, k).

Now note that each value of _c+1, k the inner integral scales like Ïµ^c, and hence this is also true once we integrate over all values of _c+1, k.
[Function with c changes of slope]
Imagine that d=1, that is g : â†’ and assume that g is a piece-wise linear function with c changes of slope. We can represent this function by fixing c degrees freedom to definite values. For instance we can choose c nodes in the hidden layer and represent one change of slope with each of these neurons. If (_x) contains all x's for which the changes of slope occur then LemmaÂ <ref> guarantees that Ï‡^#(ğ’Ÿ_x,g) = cIt's not super clear to me. What about for instance the fact that we can distribute the change of slope as âˆš(a), âˆš(a) and a^1/3, a^2/3?. Plugging this result in (<ref>) we get that for small  the true versus empirical loss gap behaves as

    â‰ˆâˆš(c log(1/)/N + Ïƒ_y^2/N + /2Ïƒ^2_y + ln(N)/Î´ N).

We see that in this case the generalization bound strongly depends on the complexity of g, which in this case is the number of changes of slope.


It will turn out that the key object useful for computing Ï‡^#(g) is a particular notion of dimension of A_g. 

For A, S âŠ†^m we define the Minkowski-Bouligand co-dimension of A w.r.t. S as
_S(A) := lim_R â†’âˆlim_â†’ 0log(( (A + B_) âˆ© B_R âˆ© S))/log() , 
where  is the Lebesgue measure and + denotes the Minkowski sum. 

Our definition is a variation of the standard Minkowski-Bouligand dimension. The first difference is that we measure the co-dimension instead of the dimension. Secondly,  we compute lim_R â†’âˆ. We do this because the sets we will be interested in are unbounded. We also define the co-dimension wrt to an auxilary set S, i.e., all volumes are computed only inside of S. One can view it as restricting the attention to a particular region. In our use cases this region will be equal to the support of the prior. We will sometimes use _P(A) to denote _(P)(A), when P is a distribution.

Technically the notion is not well defined for all sets. Formally, one defines a lower and an upper co-dimension, corresponding to taking lim inf and lim sup. Sets A and S need also be measurable wrt to the Lebesgue measure. We will however assume that for all of our applications the limits are equal, sets are measurable and thus the co-dimension is well defined. This is the case because all sets we will be interested in are defined by polynomial equations.


The first lemma relates sharp complexity and co-dimension.


Let g(x) = b + âˆ‘_i=1^c v_i [x - t_i]_+,
where 0 < t_1 < â€¦ < t_c < 1, v_1,â€¦,v_c â‰  0 and c â‰¤ k. Then
1/5_P(A_g) â‰¤Ï‡^#(g, U([0,1])) â‰¤_P(A_g).

Recall that A_g = {Î¸ : f_Î¸â‰¡_[0,1] g}.


The next lemma computes the co-dimension of a function with c changes of slope.


Let g(x) = b + âˆ‘_i=1^c v_i [x - t_i]_+,
where 0 < t_1 < â€¦ < t_c < 1, v_1,â€¦,v_c â‰  0 and c â‰¤ k. Then
_P(A_g) = 2c+1.

There exists a universal constant C such that for all In the general case there's also b^(2) but I guess it'll work.f_Î¸_0(x) = âˆ‘_i=1^k _i[x - _i^(1)]_+, such that f_Î¸_0_2^2 = ^2, there exists Î¸_1 such that f_Î¸_1â‰¡_[0,1] 0 and Î¸_0 - Î¸_1_2^2 â‰¤ O(^C).

Let L(Î¸) := f_Î¸^2. Consider the following differential equation

    Î¸Ì‡ = - âˆ‡ L(Î¸)/âˆ‡ L(Î¸)||_2,

which can be understood as a normalized gradient flow. By definition

    LÌ‡ = (âˆ‡ L(Î¸))^T Î¸Ì‡(<ref>)= - âˆ‡ L(Î¸)_2.

We will later show that 

    âˆ‡ L(Î¸)_2 â‰¥ L^0.8.

Note that the solution to LÌ‡ = - L^0.8 is of the form L(t) = c (C - t)^0.8. More precisely, with the initial condition L(0) = ^2 we get that C = (^2/c)^1/4/5. What follows is that L ((^2/c)^5/4) = 0. Using (<ref>) we get that there exists t^* < (^2/c)^5/4 such that L(t^*) = 0. Because the change of Î¸ is normalized (see (<ref>)) we get that Î¸(0) - Î¸(t^*)_2^2 â‰¤(^2/c)^4/5 = O (^4/5/4). What is left is to show (<ref>).

We start by computing derivatives of L wrt to Î¸. For every i âˆˆ [1,k]
    âˆ‚ L/âˆ‚_i^(1) = _i âˆ«__i^(1)^1 f_Î¸(x)  dx.

    âˆ‚ L/âˆ‚_i = âˆ«__i^(1)^1 f_Î¸(x)(x - _i^(1))  dx.

We will show that there exists i âˆˆ [1,k] such that max{|âˆ‚ L/âˆ‚_i^(1)|,|âˆ‚ L/âˆ‚_i|} is large. 

For a function f : [0,1] â†’, f(0) = 0, f'(0) = 0 (that one should understand as an abstraction of f_Î¸) consider the following expression (related to (<ref>))

    fâ€(y) âˆ«_a^1 f(y)  dx.

The following computation will be helpful

    Î±(a,b)    := âˆ«_a^b fâ€(y) âˆ«_y^1 f(x)  dx  dy 
       = [f'(y) âˆ«_y^1 f(x)  dx ]_a^b - âˆ«_a^b f'(y) Â· (- f(y))  dy       by parts
       = f'(b)âˆ«_b^1 f(x)  dx - f'(a) âˆ«_a^1 f(x)  dx + [1/2 f^2(x) ]_a^b 
       = f^2(b)/2 + f'(b)âˆ«_b^1 f(x)  dx - f^2(a)/2 - f'(a) âˆ«_a^1 f(x).

Now note that

    Î±(0,b) 
       = f^2(b)/2 + f'(b)âˆ«_b^1 f(x)  dx - f^2(0)/2 - f'(0) âˆ«_0^1 f(x) 
       = f^2(b)/2 + f'(b)âˆ«_b^1 f(x)  dx       As  f'(0) = f(0) = 0.

Let M := max_x âˆˆ [0,1] |f(x)| and x^* âˆˆ f^-1(M). We claim that 

    Î±(0,x^*) = M^2/2.

To see that use (<ref>) and note that either x^* âˆˆ [0,1] and then f'(x^*) = 0 because it is an extremal point, or x^* = 0 and then f'(0)= by definition, or x^* = 1 and then âˆ«_1^1 f(x)  dx = 0. Using (<ref>) and the definition of Î± we get that there exists x_0 âˆˆ [0,x^*] such that

    |fâ€(x_0) âˆ«_x_0^1 f(x)  dx | â‰¥M^2/2 x^*â‰¥M^2/2.

Now note that f_Î¸ satisfies f_Î¸(0) = 0. It might not be true that f'_Î¸(0) = 0 but if we increase all the bias terms by a negligible amount then f'_Î¸(0) = 0 and the quantity of interest (<ref>) changes only negligibly I guess it's true. Moreover observe that for every i âˆˆ [1,k]fâ€_Î¸(_i^(1)) = âˆ‘_j : _j^(1) = _i^(1)_j and for all x âˆˆ [0,1] âˆ–{_1^(1), â€¦, _k^(1)} we have fâ€_Î¸(x) = 0. As the number of nodes is k we get from (<ref>) that there exists i âˆˆ [1,k] such that
|_i âˆ«__i^(1)^1 f(x)  dx | â‰¥M^2/2 k^2. 

If M â‰¥^0.9 then 
|âˆ‚ L/âˆ‚_i^(1)| â‰¥^1.8/2 k^2â‰¥1/2k^2(^2 )^0.9â‰¥1/2k^2 L(Î¸)^0.9,
which implies (<ref>) and ends the proof in this case. Thus we can assume for the rest of the proof that M < ^0.9.

By Holder's inequality we have 

    f_Î¸_1 â‰¥f_Î¸_2^2 / f_Î¸_âˆâ‰¥^2 / ^0.9 = ^1.1.

Let 0 = a_1 â‰¤ a_2 â‰¤â€¦â‰¤ a_k+2 = 1 be the ordering of {b_1^(1), â€¦, b_k^(1)}âˆª{0,1}. Consider a generalization of (<ref>)âˆ«_a^1 f(x) (x - a)  dx.

Let I(a) := âˆ«_a^1 f_Î¸(x)  dx. Note that

    d/d aâˆ«_a^1 f(x) (x - a)  dx = âˆ«_a^1 f(x) = I(a).

Let i âˆˆ [1,k] be such that it satisfies

  * âˆ«_a_i^a_i+2 |f_Î¸(x)| _{sgn(f_Î¸(x)) = sgn(f_Î¸(a_i+1)) } dx â‰¥^1.1/k, 
  * âˆ«_a_i^a_i+2 |f_Î¸(x)| _{sgn(f_Î¸(x)) = sgn(f_Î¸(a_i+1)) } dx â‰¥âˆ«_a_i^a_i+2 |f_Î¸(x)| _{sgn(f_Î¸(x)) â‰ sgn(f_Î¸(a_i+1)) } dx.  
Such an i exists because of (<ref>) and the fact that f_Î¸ crosses 0 at most k times Is it enough of a proof?. Assume without loss of generality that f_Î¸(a_i+1) > 0. By definition f_Î¸ is two-piece linear on [a_i, a_i+2], because of that and the assumption that f_Î¸(a_i+1) > 0 we know that âˆ«_a^1 f_Î¸(x) first increases, then decreases and finally increases (the first and the third phase might not happen). By (<ref>) we know that I(a_i) â‰¥ I(a_i+2). Let a_max := _a I(a), a_min := _a I(a). By (<ref>) we know that I(a_max) - I(a_min) > ^1.1/k. Consider two cases:


  
Case 1: I(a_max) â‰¥I(a_max) - I(a_min)/2.

  
Case 2: I(a_max) < I(a_max) - I(a_min)/2.We need a bound on weights!!! Or do wee

This brings us to the main result of this subsection

[Function with c changes of slope - Bayes Complexity]
Let g : [0,1] â†’ and assume that g is a piece-wise linear function with c â‰¤ k changes of slope. Then
2c+1/5â‰¤Ï‡^#(g, U([0,1])) â‰¤ 2c+1.


We see that the limiting complexity is â‰ˆ c, for c â‰¤ k. This means that the complexity depends strongly on the function and simpler - in a sense of fewer changes of slopes - functions have smaller complexity. In SectionÂ <ref> we will compute the limiting complexity for linear models. It will turn out, see ExampleÂ <ref>, that in this case the complexity doesn't depend on the function and is equal to the number of basis functions used in the linear model.



  Â§.Â§.Â§ The -Complexity Case


We saw in the previous section that for the case of neural networks our notion of complexity corresponds (in the limit and up to constant factors) to the number of degrees of freedom that need to be fixed to represent a given function.
When we evaluate the complexity at more refined scales it can be shown that it is closely related to another natural complexity measure. 

[Function with âˆ« |gâ€(x)| dx = a] Let

    C(g) = max(âˆ« |gâ€(x)| dx, |g'(-âˆ) + g'(+âˆ)| ).

In <cit.> it was shown that, for the case of a single hidden layer NN with 1-D input, for every g : â†’ if we let the width of the network go to infinity Is Î¸_w defined? then

    min_Î¸ : f_Î¸ = gÎ¸_w^2 = C(g).

This means that if we use an â„“_2 regularizer for training a neural network

    Î¸^* = _Î¸( L_S(f_Î¸) + Î»Î¸_w^2 ),

then C(f_Î¸^*) = Î¸^*_w^2. In words, the function that is found via this scheme balances the empirical error and C(g).

In the appendix we show that in some regimes C(g) â‰ˆÏ‡^#(_x, g, ). Plugging it in (<ref>) we get that the expected true versus empirical loss gap is

    â‰ˆâˆš(O_Ïƒ_w^2,(C(g)/N) + Ïƒ_y^2/N + /2Ïƒ^2_y + ln(N)/Î´ N),

where O_Ïƒ_w^2, drops terms dependent on Ïƒ_w^2,. See the appendix for details. We see that the gap crucially relies on C(g). This result can be seen as a quantitative version of ExampleÂ <ref> as âˆ« |gâ€(x)| dx can be seen as a more refined version of the number of changes of slope.



  
Variational Complexity
Let us now introduce a complexity measure for a piece-wise linear function g. 
We start by introducing a complexity measure for a particular choice of the network parameters. The complexity of the function will then be the minimum complexity of the network that represents this function. 
We choose

    C_k(Î¸) = 1/2Î¸_w^2 = 1/2( ^(1)^2 + ^(2)^2 ),

i.e., it is half the squared Euclidean norm of the  weight parameters. 

If we use the representation (<ref>) in its natural form, i.e.,  w^(2)_i =a_i and W^(1)_i = 1, then we have C_k(Î¸) = 1/2âˆ‘_i=1^k (a_i^2+1). But we can do better. Write

    f(x) = c + âˆ‘_i=1^k w^(2)_i [W^(1)_i(x-x_i)]_+,

where w^(2)_i =a_i/âˆš(|a_i|) and W^(1)_i = |w^(2)_i |. This gives us a complexity measure C_k(Î¸) = âˆ‘_i=1^k |a_i| = âˆ‘_i=1^k |Î±_i-Î±_i-1|, where Î±_0=0. Indeed, it is not very hard to see, and it is proved in <cit.>, that this is the best one can do even if we keep f(x) fixed and are allowed to let the number k of hidden nodes tend to infinity. In other words, for the function f described in (<ref>) we have

    C(f) = inf_k âˆˆ, Î¸: f_Î¸ = f C_k(Î¸) = (f'),

where (f') denotes the total variation of f', the derivative of f. Why total variation?
Note that Î±_i denotes the derivative of the function so that |Î±_i-Î±_i-1| is the change in the derivative at the point x_i. Therefore, âˆ‘_i=1^k |Î±_i-Î±_i-1| is the total variation associated to this derivative. 












If we consider a general function f: [0, 1] then for every Ïµ>0, f can be uniformly approximated by a piecewise linear function, see <cit.>. As Ïµ tends to 0 for the best approximation the variation of the piece-wise linear function converges to the total variation of f'. This can equivalently be written as the integral of 
|fâ€|.
It is therefore not surprising that if we look at general functions f: and let the network width tend to infinity then the lowest cost representation has a complexity of

    C(f) = max(âˆ« |fâ€(x)| dx, |f'(-âˆ) + f'(+âˆ)| ).

As we previously mentioned, this concept of the complexity of a function was introduced in <cit.> and this paper also contains a rigorous proof of (<ref>). (Note: The second term in (<ref>) is needed
when we go away from a function that is supported on a finite domain to . To see this consider the complexity of f(x) = Î± x. It is equal to 2Î± (f(x) = âˆš(Î±) [âˆš(Î±) x]_+ - âˆš(Î±) [-âˆš(Î±) x]_+) but âˆ« |fâ€(x)| dx = 0.)











 



















  
Sharp versus Variational Complexity. Now we explain how the notion of sharp complexity is, in some regimes, equivalent to the variational complexity. This gives a concrete example of our promise that sharp complexity aligns well with natural complexity measures.






Assume at first that the target function is of the form g(x) = b + âˆ‘_i=1^c v_i[x - t_i]_+
and requires only a single change of the derivative. I.e., the piece-wise linear function consists of two pieces and we require only one term in the sum, g(x) = a[x - t]_+ + b Call this function g_1, where the 1 indicates that there is only a single change of the derivative and the change is of magnitude a. 




We now ask what is the value of Ï‡^#(g_1, _x, ^2), for _x = U([0,1]) - as this is what appears in (<ref>). We claim that for small , specific choices of M and Ïƒ_w^2, Ïƒ_b^2 and particular regimes of parameters we have

    Ï‡^#(g_1, U([0,1]), ^2) = Î˜(a / Ïƒ_w^2) = Î˜(C(g_1) / Ïƒ_w^2).

This means that the sharp complexity is closely related to the variational complexity of g_1. The more formal version of (<ref>) of which a proof is in AppendixÂ <ref> reads
 
Let t,âˆˆ (0,1), a,bâˆˆ. Define g_1(x) := b + a[x - t]_+. If k â‰¤ M â‰¤1/Ïƒ_w^2, Ïƒ_b^2 â‰¤1/Ïƒ_w^2 and Î©(^1/4),Î©(log(k/Ïƒ_w) Ïƒ_w^2) â‰¤ |a| < 2, Î©(^1/4) â‰¤  |b|, Î©(^1/2) â‰¤min(t,1-t) then
|a|/3 Ïƒ_w^2â‰¤Ï‡^#(g_1, U([0,1]), ^2) â‰¤ 2(|a|/Ïƒ_w^2 + |b|/Ïƒ_b^2) + 11 - 3log().


The above lemma is stated with the most general setting of parameters. To get more insight into the meaning of the lemma we give the following corollary.


For every sufficiently small Ïƒ_e^2 and M = k, Ïƒ_w^2 = 1/k, Ïƒ_b^2 = 1, |b| = Î˜(Ïƒ_e^1/2), Î©( Ïƒ_e^1/4), Î©(log(k)/k) â‰¤ |a| < 2 if we define g_1(x) := b + a[x-1/2]_+ then
Ï‡^#(g_1,U[0,1],Ïƒ_e^2) â‰¤ 3|a|k + 3 log(1/Ïƒ_e).

One can easily verify that the assumptions of LemmaÂ <ref> are satisfied. Applying the lemma we get

    Ï‡^#(g_1,U[0,1],Ïƒ_e^2) 
       â‰¤ 2(|a|/Ïƒ_w^2 + |b|/Ïƒ_b^2) + 11 + 3log(1/Ïƒ_e)  
       â‰¤ 2|a| k + Î˜(Ïƒ_e^1/2) + 11 + 3log(1/Ïƒ_e) 
       â‰¤ 3|a|k + 3 log(1/Ïƒ_e)       As Î©( log(k)/k) â‰¤ |a|.


  
Generalization bound. Now we want to understand what ExampleÂ <ref> gives us for the generalization bound from TheoremÂ <ref>. Setting Î² = 1 in TheoremÂ <ref> and applying ExampleÂ <ref>,  we can bound

    _âˆ¼^N[L_(Q)] 
       â‰¤
    2Ïƒ_e^2 + C/âˆš(2)âˆš(Ï‡^#(g_1, _x, Ïƒ_e^2)/N)
       â‰¤ 2Ïƒ_e^2 + C/âˆš(2)âˆš(3|a|k + 3 log(1/Ïƒ_e)/N).


Now we interpret (<ref>). First note that the setting of parameters in ExampleÂ <ref> is natural. The choice of Ïƒ_w^2 = 1/k and Ïƒ_b^2 = 1 are among standard choices for initialization schemes. We pick |b| = Î˜(Ïƒ_e^1/2) and t = 1/2 in order to analyze functions g_1(x)â‰ˆ a[x - 1/2]_+, where the bias term b is nonzero because of the assumptions of LemmaÂ <ref>. Note that depending on the relation between k and Ïƒ_e^2 one of the terms dominates (<ref>): either 3|a|k or 3 log(1/Ïƒ_e). 

If Ïƒ_e^2 â‰ª k then 3 log(1/Ïƒ_e) dominates and the generalization bound depends mostly on the noise level Ïƒ_e^2[As a side note, notice that the 3 in 3 log(1/Ïƒ_e) corresponds to the 2c+1 bound on the limiting complexity in ExampleÂ <ref>, as we consider a function with one change of slope and a very small ^2 for computing Ï‡^#. This illustrates the relationship between sharp and limiting complexity.].

If Ïƒ_e^2 â‰« k then 3|a|k dominates. In this case we get the promised dependence of the generalization bound on |a|, which we recall is equal to C(g_1). Note that there is a wide range of |a| for which the bound holds, i.e. Î©(log(k)/k) â‰¤ |a| â‰¤ 2. We see that the simpler g_1, measured in terms of C, the better a generalization bound we get. 

















 Â§.Â§ Neural Networks with Several Hidden Layers

Consider now exactly the same set-up as before, except that now we have K=4, i.e., we have three hidden layers and still d = 1. We can still represent piece-wise linear functions (e.g., by using the first layer to represent the function and just a single node in the second layer to sum the output of the previous layers). But the asymptotic complexity of some functions is now different! 

[Periodic function]
Imagine that we want to represent a function g : [0,l] â†’ that is periodic with period 1. That is g(x - 1) = g(x) for all x âˆˆ [1,l]. What we can do is to (i) represent g|_[0,1] in the output of a single neuron v in layer 2 (ii) represent shifted versions of g|_[0,1] (which are equal to g|_[1,2], g|_[2,3], â€¦ due to periodicity) in the outputs of neurons in layer 3 (iii) sum outputs of neurons from layer 3 in the single output neuron in layer 4. Assume moreover that g|_[0,1] has m changes of slope. Then observe that we implemented g fixing O(l+m) degrees of freedom. But g itself has m Â· l changes of slope over the whole domain. 

This representation gives an upper-bound for limiting complexity as there might be other ways to represent the function. 

But because of ExampleÂ <ref> it is enough to arrive at a separation. Indeed if l â‰ˆ m then the asymptotic complexity of g for NN with 4 layers is smaller than for 2 layers, which is in Î©(m l). In words, we obtain a quadratic gain in terms of the number of samples needed to get the same generalization bound. 



We leave it for future work to explore this direction in more depth (no pun intended).


Â§ WHY LINEAR SCHEMES GENERALIZE POORLY


In SectionÂ <ref> we've seen that for NNs our notion of complexity aligns well with natural notions of complexity. This, in the light of the connections to the PAC-Bayes bound, partly explains their good generalization. In this section we will show that for the case of linear schemes the complexity is basically independent of a function.  

We investigate  
the linear model _Î¸^(L, o)={f_Î¸(x): f_Î¸(x) = âˆ‘_i=0^d-1_i b_i(x), x âˆˆ = [-1, 1]}. Further let _x be the uniform distribution on [-1, 1]. We assume a prior on _i's to be iid Gaussians of mean 0 and variance Ïƒ_w^2.

We will see that in this setting all realizable functions have the same complexity. This in the light of (<ref>) tells us that even if reality prefers simple functions the number of samples needed to get a non vacuous bound is as big as the one needed for the highest complexity function in the class.  In short: it is equally â€œeasyâ€ to represent a â€œcomplicatedâ€ function as it is to represent a â€œsimpleâ€ one. Therefore, given some samples, there is no reason to expect that linear models will fit a simple function to the data. Indeed, to the contrary. If the data is noisy, then linear models will tend to overfit this noise.



 Â§.Â§ Orthonormal Basis


For simplicity assume that the basis functions are the Legendre polynomials. I.e., we start with the polynomials {1, x, x^2, ...} and then create from this an orthonormal set on [-1, 1] via the Gram-Schmidt process.

[Constant Function]
Let g(x)=1/âˆš(2). This function is realizable. Indeed,
it is equal to the basis function b_0(x).  Let us compute Ï‡^#(^(L, o),g,
Ïµ^2).  If we pick all weights in f_(x) = âˆ‘_i=0^d-1_i b_i(x) equal to 0 except _0 equal to 1 then we get
g(x).  Hence, taking advantage of the fact that the basis functions
are orthonormal, we have

    _x âˆ¼_x[(f_ - g(x))^2]  =
    1/2âˆ«_-1^1 (f_(x)-g(x))^2 dx  
      
    =    1/2âˆ‘_i=0^d-1 (_i-_{i=0})^2 âˆ«_-1^1 b_i(x)^2 dx  
    = 1/2âˆ‘_i=0^d-1 (_i-_{i=0})^2.

So we need to compute the probability 

    [:  1/2âˆ‘_i=0^d-1 (_i-_{i=0})^2 â‰¤^2].

Recall that our weights are iid Gaussians of mean 0 and variance Ïƒ_w^2. Hence

    âˆ‘_i=1^d-1_i^2  âˆ¼Î“(d-1/2, 2 Ïƒ_w^2 ),

where Î“(k, Î¸) denotes the Gamma distribution with shape
k and scale Î¸.  It follows that the probability we are
interested in can be expressed as [:  1/2âˆ‘_i=0^d-1 (_i-_{i=0})^2 â‰¤^2] = q(Îº=1, Ïƒ_w, Ïµ), where
q(Îº, Ïƒ_w, Ïµ) =
1/âˆš(2 Ï€Ïƒ_w^2)âˆ«_0^Ïµ F(Ïµ^2-x^2; d-1/2, 2 Ïƒ_w^2) [e^-(Îº+x)^2/2 Ïƒ_w^2+e^-(Îº-x)^2/2 Ïƒ_w^2]dx.

Here, F(x; k, Î¸) denotes the cdf of the Gamma distribution
with shape k and scale Î¸. From the above expression we can compute Ï‡^#(^(L, o), g(x) =
1/âˆš(2),Ïµ^2), although there does not seem to be an elementary expression.


For non-negative Îº, Ïƒ_w, and Ïµâˆˆ (0, 1] the function
q(Î±, Ïƒ_w, Ïµ) has the following properties:

  *  Scaling: q(Îº, Ïƒ_w, Ïµ) = Îº q(1, Ïƒ_w/Îº, Ïµ/Îº)
  *  Monotonicity in Îº: q(Îº, Ïƒ_w, Ïµ) is non-increasing in Îº
  *  Monotonicity in Ïƒ_w: q(Îº, Ïƒ_w, Ïµ) is non-increasing in Ïƒ_w
  *  Monotonicity in Ïµ: q(Îº, Ïƒ_w, Ïµ) is non-decreasing in Ïµ
  *  Limit: lim_Ïµâ†’ 0log(q(Îº, Ïƒ_w, Ïµ))/log(Ïµ)=d

If we are just interested in Ï‡^#(^(L, o), g(x) = 1/âˆš(2)),
we can start from Ï‡^#(^(L, o), g(x) = 1/âˆš(2), Ïµ^2)
or we can make use of (v) of LemmaÂ <ref> to get 

    Ï‡^#(^(L, o), g(x) = 1/âˆš(2))=d.

To see this result intuitively note that all weights
have to be fixed to a definite value in order to realize g(x).
[Basis Function]
Although we assumed in the above derivation that g(x)=b_0(x) the
calculation is identical for any g(x)=b_i(x), i=0, â‹¯, d-1.
We conclude that Ï‡^#(^(L, o), b_i(x)) does not depend
on i.  [Realizable Function of Norm 1]
Assume that g(x)= âˆ‘_i=0^d-1_i b_i(x) with
âˆ‘_i=0^d-1_i^2=1. In other words, the function
is realizable and has squared norm equal to 1.

If we â€œrotateâ€ (orthonormal transform) our basis {b_i(x)}_i=0^d
into the new basis {bÌƒ_i(x)}_i=0^d so that
g(x)=bÌƒ_0(x) then due to the rotational symmetry of our
prior we are back to our first example.

We conclude that for any realizable function g(x) of norm 1,
Ï‡^#(^(L, o), g(x), Ïµ^2) = Ï‡^#(^(L, o), b_0(x), Ïµ^2).[Realizable Function]
Assume that g(x)= âˆ‘_i=0^d-1_i b_i(x) with
âˆ‘_i=0^d-1_i^2=Îº^2. In other words, the
function is realizable and has norm equal to Îº.

Using the scaling property of LemmaÂ <ref> we can write 

    Ï‡^#(_(Ïƒ_w)^(L, o), g(x), Ïµ^2 ) 
        = -log(q(Îº, Ïƒ_w, Ïµ)) 
        = -log(Îº q(1, Ïƒ_w/Îº, Ïµ/Îº)) 
        = -log(Îº) + Ï‡^#(_(Ïƒ_w/Îº)^(L, o), b_0(x), Ïµ^2/Îº^2),

where we wrote _(Ïƒ_w)^(L, o) to indicate that in the model
each parameter's prior is a Gaussian with variance Ïƒ_w^2.

This means that the complexity of a function changes depending on the norm of the vector of weights  that represent it. However if we are interested in the asymptotic complexity all functions (apart from the 0 function) have the same complexities as lim_â†’ 0log(Îº) /log() = 0, which leads to the next example.
[Limiting Sharp Complexity]
Assume that g(x)= âˆ‘_i=0^d-1_i b_i(x). Then
Ï‡^#(^(L, o), g(x))=d.


Recall that we showed (ExampleÂ <ref>) that for the case of 2-layer neural networks the limiting complexity depends strongly on the function and simpler functions - in a sense of number of changes of slope - have lower complexity. Here we see that for linear models basically all functions have the same complexity, which is equal to the number of basis functions in the model.

[Unrealizable Function]
Given any function g(x), we can represent it as
g(x)=g_âŠ¥(x)+g_(x), where the two components are orthogonal
and where g_(x) represents the realizable part. We then have
that Ï‡^#(_(Ïƒ_w)^(L, o), g(x), Ïµ^2) is equal to

    âˆ,    g_âŠ¥(x)_2^2 > Ïµ^2, 
    
    -log(q (1, Ïƒ_w, âˆš(Ïµ^2-g_âŠ¥(x)_2^2)) ),    g_âŠ¥(x)_2^2 < Ïµ^2.


 Â§.Â§ Non-Orthonormal Basis
[Non-Orthogonal Basis]
If the functions do not form an orthonormal basis but are independent, then we
can transform them into such base. After the transform the probability distribution is
still a Gaussian but no longer with independent components. Now the
"equal simplicity" lines are ellipsoids.

And if we have dependent components then we also still have Gaussians
but we are in a lower dimensional space.


 Â§.Â§ Summary

We have seen that for the linear model the complexity of a function
g(x) only depends on the norm of the signal. This complexity measure is therefore only
weakly correlated with other natural complexity measures. E.g., if
the basis consists of polynomials of increasing degrees and the reality is modeled by a function of low degree then the bound from (<ref>) is the same as when the reality is modeled by a high degree polynomial. It means that the number of samples needed for a good generalization bound is independent of g.











Â§ GENERALIZATION BOUND


To derive the bound from TheoremÂ <ref> in terms of â€œsharp complexityâ€ we first define a series of related notions that are helpful during the derivation.




We define the  empirical complexity of a function g as 





    Ï‡^E(g, _x, _Ïµ, Ïƒ_y^2) 
       := -log[ ( âˆ«_Î¸ P(Î¸) e^-1/2Ïƒ_y^2Nâˆ‘_n=1^N (g(x_n) + Î·_n - f_Î¸(x_n))^2 d Î¸) ],

where we denoted by _x the x's part of  and by _ the particular realization of noise used for generating , i.e. Î·'s.

In order to compute it, we integrate over the parameter space and weigh the prior P(Î¸) by an exponential factor which is the smaller the further the function f_Î¸ is from g on the given sample _x plus noise _. Recall that noise samples _Ïµ come from an iid Gaussian zero-mean sequence of variance Ïƒ_e^2. We then take the negative logarithm of this integral.

The  true complexity with noise is defined as

    Ï‡^N(g, _x, Ïƒ_y^2, Ïƒ_^2) := 
       -log[ ( âˆ«_Î¸ P(Î¸) e^-1/2Ïƒ_y^2_x âˆ¼_x, âˆ¼ğ’©(0,Ïƒ_e^2) [(g(x) +  - f_Î¸(x))^2] d Î¸) ],

where the sum has been replaced by an expectation using the underlying distribution of the input.

The  exponential complexity is

    Ï‡(g, _x, Ïƒ_y^2) := 
       -log[ ( âˆ«_Î¸ P(Î¸) e^-1/2Ïƒ_y^2_x âˆ¼_x [(g(x) - f_Î¸(x))^2] d Î¸) ].

Note that

    Ï‡(g, _x, Ïƒ_y^2) + Ïƒ_e^2/2 Ïƒ_y^2 = Ï‡^N(g, _x, Ïƒ_y^2, Ïƒ_e^2).


Finally, the  sharp complexity with noise is defined as

    Ï‡^#N(g, _x, Ïƒ_e^2, ^2) 
       := -log[ _Î¸[ _x âˆ¼_x, âˆ¼ğ’©(0,Ïƒ_e^2) [(g(x) +  - f_Î¸(x))^2] â‰¤^2] ].


The following two lemmas establish some relationships between these notions of complexity.

For every _x, every g : â†’, and ^2 > 0 we have:

    Ï‡^#N(g, _x, Ïƒ_e^2, ^2) = Ï‡^#(g, _x, ^2 - Ïƒ_e^2).

    Ï‡^#N(g, _x, Ïƒ_e^2, ^2) 
        = -log[ _Î¸[ _x âˆ¼_x, âˆ¼ğ’©(0,Ïƒ_e^2) [(g(x) +  - f_Î¸(x))^2] â‰¤^2 ] ] 
       = -log[ _Î¸[ _x âˆ¼_x, âˆ¼ğ’©(0,Ïƒ_e^2) [(g(x) - f_Î¸(x))^2] â‰¤^2 - Ïƒ_e^2 ] ] 
       = Ï‡^#(g, _x, ^2 - Ïƒ_e^2),

where in the second equality we write (g(x) + - f_Î¸(x))^2 as the sum of (g(x)-f_Î¸(x))^2, 2(g(x) - f_Î¸(x)) and ^2 and use the fact that [] = 0 and [^2] = Ïƒ_e^2.

For every _x, every g : â†’, and Ïƒ_y^2, Ïƒ_e^2, ^2 > 0 we have:

    Ï‡^N(g, _x, Ïƒ_y^2, Ïƒ_e^2) â‰¤Ï‡^#N(g, _x, Ïƒ_e^2, ^2) + ^2/2Ïƒ_y^2.

    Ï‡^#N(g, Ïƒ_e^2,^2) 
       =
    -log( âˆ«_Î¸ P(Î¸) 1{_x âˆ¼_x, âˆ¼ğ’©(0,Ïƒ_e^2) [(g(x) +  - f_Î¸(x))^2] â‰¤^2 } d Î¸) 
       Î±>0= -log( âˆ«_Î¸ P(Î¸) 1{Î±/2Ïƒ_y^2_x âˆ¼_x, âˆ¼ğ’©(0,Ïƒ_e^2) [(g(x) +  - f_Î¸(x))^2] â‰¤Î±^2/2Ïƒ_y^2} d Î¸) 
       e^ xâ‰¥1{x â‰¥ 0 }â‰¥-log( âˆ«_Î¸ P(Î¸) e^Î±^2/2Ïƒ_y^2 -Î±/2Ïƒ_y^2_x âˆ¼_x, âˆ¼ğ’©(0,Ïƒ_e^2) [(g(x) +  - f_Î¸(x))^2] d Î¸) 
       = Ï‡^N(g, Ïƒ_y^2/Î±, Ïƒ_e^2) - Î±^2/2Ïƒ_y^2.


The sharp complexity is very convenient to work with. Hence we will formulate our final bound in terms of the sharp complexity. The reason we call it  sharp complexity is that the region of Î¸ we integrate over is defined by an indicator function whereas for the true complexity the â€œboundaryâ€ of integration is defined by a smooth function.

Let us now look more closely at the divergence where we assume the data model (<ref>) and that the true hypothesis is g. We have

    D(Q  P) 
       = âˆ«P(Î¸) e^- 1/2 Ïƒ_y^2âˆ‘_n=1^N (y_n - f_Î¸(x_n))^2/âˆ« P(Î¸') e^- 1/2 Ïƒ_y^2âˆ‘_n=1^N (y_n - f_Î¸'(x_n))^2 d Î¸'Â·
       Â·log(
     e^- 1/2 Ïƒ_y^2âˆ‘_n=1^N (y_n - f_Î¸(x_n))^2/âˆ« P(Î¸') e^- 1/2 Ïƒ_y^2âˆ‘_n=1^N (y_n - f_Î¸'(x_n))^2 d Î¸') d Î¸
       â‰¤Ï‡^E(g,_x, _Ïµ,Ïƒ_y^2/N)- N/2Ïƒ_y^2 L_(Q),

where in the last inequality we used the fact that we use a clipped version of a square loss.
Therefore the expectation over S âˆ¼^N of the square root term of the right-hand side of the PAC-Bayes bound (<ref>) can be upper-bounded as

    _âˆ¼^N[Câˆš(D(Q  P)/2 N)] 
       By (<ref>)â‰¤_âˆ¼^N[C âˆš(Ï‡^E(g, _x,_, Ïƒ^2_y/N) - N/2Ïƒ_y^2 L_(Q) /2 N)] 
       âˆš(Â·) concaveâ‰¤C/âˆš(2)âˆš(_âˆ¼^N[Ï‡^E(g, _x,_, Ïƒ^2_y/N) ]/N -L/2Ïƒ_y^2),

where we denoted _âˆ¼^N[L_(Q)] by LÌ‚. Before we proceed we state a helpful lemma.


Let X and Y be independent random variables and f(X, Y) be a non-negative function. Then

    _X [ ln( _Y [ e^-f(X, Y)] )  ]
    â‰¥ln( _Y[e^-_X[f(X, Y)]]).

We limit our proof to the simple case where the distributions are discrete and have a finite support, lets say from {1, â‹¯, I}. We claim that for 1 â‰¤ j <I,

    (âˆ‘_i=1^j p(X=x_i))
    ln( _Y[e^-âˆ‘_i=1^jp(X=x_i) f(x_i, Y)/âˆ‘_i=1^j p(X=x_i) ]) + 
    âˆ‘_i=j+1^I p(X=x_i) [ ln( _Y [ e^-f(x_i, Y)] )  ] 
    â‰¥   
     (âˆ‘_i=1^j+1 p(X=x_i))
    ln( _Y[e^-âˆ‘_i=1^j+1 p(X=x_i) f(x_i, Y)/âˆ‘_i=1^j+1 p(X=x_i) ]) +
    âˆ‘_i=j+2^I p(X=x_i) [ ln( _Y [ e^-f(x_i, Y)] )  ].

This gives us a chain of inequalities. Note that the very first term in this chain is equal to the left-hand side of the desired inequality and the very last term is equal to the right-hand side of the inequality. 

Consider the j-th such inequality. Cancelling common terms, it requires us to prove

    (âˆ‘_i=1^j p(X=x_i))
    ln( _Y[e^-(âˆ‘_i=1^jp(X=x_i) f(x_i, Y)/âˆ‘_i=1^j p(X=x_i) )]) + 
     p(X=x_j+1) [ ln( _Y [ e^-f(x_j+1, Y)] )  ] 
    â‰¥   
     (âˆ‘_i=1^j+1 p(X=x_i))
    ln( _Y[e^-(âˆ‘_i=1^j+1p(X=x_i) f(x_i, Y)/âˆ‘_i=1^j+1 p(X=x_i) )]).

Taking the prefactors into the logs, combining the two log terms on the left-hand side, and finally cancelling the logs, the claimed inequality is true iff

    _Y[e^-âˆ‘_i=1^j p(X=x_i) f(x_i, Y)/âˆ‘_i=1^j p(X=x_i) ]^âˆ‘_i=1^j p(X=x_i)/âˆ‘_i=1^j+1 p(X=x_i)_Y [ e^-f(x_j+1, Y)] ^p(X=x_j+1)/âˆ‘_i=1^j+1 p(X=x_i)â‰¥   _Y [e^-âˆ‘_i=1^j+1 p(X=x_i) f(x_i, Y)/âˆ‘_i=1^j+1 p(X=x_i) ].

But this statement is just an instance of the Hoelder inequality with 1/p+1/q=1, where 1/p=âˆ‘_i=1^j p(X=x_i)/âˆ‘_i=1^j+1 p(X=x_i) and 1/q=p(X=x_j+1)/âˆ‘_i=1^j+1 p(X=x_i).



Now we bound the complexity term from (<ref>) further. We have for every ^2 > 0
    _S âˆ¼^N[Ï‡^E(g, _x,_, Ïƒ_y^2/ N)] 
       = -_S âˆ¼^N[ log( âˆ«_Î¸ P(Î¸) e^-1/2Ïƒ^2_yâˆ‘_n=1^N (g(x_n) + _n  - f_Î¸(x_n))^2 d Î¸)   ] 
       LemÂ <ref>â‰¤ -log( âˆ«_Î¸ P(Î¸) e^-N/2Ïƒ^2_y_x âˆ¼_xâˆ¼ğ’©(0,Ïƒ_e^2) [(g(x) +  - f_Î¸(x))^2] d Î¸) 
       = Ï‡^N(g, _x, Ïƒ^2_y/N, Ïƒ_e^2)
    LemÂ <ref>â‰¤Ï‡^#N(g, _x, Ïƒ_e^2, ^2) + ^2 N /2 Ïƒ^2_y
       LemÂ <ref>=Ï‡^#(g, _x, ^2 - Ïƒ_e^2) + ^2 N /2 Ïƒ^2_y.

Hence by combining (<ref>) and (<ref>) we get that for every ^2 > 0 the expectation over S âˆ¼^N of the PAC-Bayes bound can be bounded as

    _âˆ¼^N[L_(Q) + Câˆš(D(Q  P) /2 N)] 
       â‰¤L + C/âˆš(2)âˆš(Ï‡^#(g, _x, ^2 - Ïƒ_e^2)/N  + 1/2Ïƒ^2_y(^2 - L)).


Let Î²âˆˆ (0,1]. Recall that parameter Ïƒ_y^2 is chosen freely by the learning algorithm. By the assumption of the theorem we have 


    L_(P) â‰¥ 2Ïƒ_e^2.

Because g âˆˆsupp(P), which in words means that g is realizable with prior P, then

    lim_Ïƒ_y^2 â†’ 0L   = lim_Ïƒ_y^2 â†’ 0_âˆ¼^N [ L_(Q) ]  
       = _âˆ¼^N[ lim_Ïƒ_y^2 â†’ 0 L_(Q) ]  
       â‰¤_âˆ¼^N L_(g) 
       = Ïƒ_e^2 .






where in the second equality we used Lebesgue dominated convergence theorem and in the inequality we used the fact that the smaller Ïƒ_y^2 gets the bigger the penalty on âˆ‘_n (y_n - f_Î¸(x_n))^2 in Q, which means that, in the limit, L_(Q) is smaller than L_(h) for every fixed h âˆˆsupp(P) and in particular for g. 

On the other hand, by an analogous argument, we have

    lim_Ïƒ_y^2 â†’âˆL   = _âˆ¼^N[ L_(P) ] 
       = _âˆ¼^N[  _Î¸âˆ¼ P[1/Nâˆ‘_i=1^N â„“(f_Î¸, y_n) ] ] 
       =  _Î¸âˆ¼ P[ _âˆ¼^N[1/Nâˆ‘_i=1^N â„“(f_Î¸, y_n)  ] ] 
       = L_(P)  
       â‰¥ 2 Ïƒ_e^2,

where we used the independence of P and  in the third equality and (<ref>) in the inequality.

Equations (<ref>) and (<ref>) and the fact that L is a continuous function of Ïƒ_y^2 give us that there exists Ïƒ_alg^2 > 0 such that
_âˆ¼^N[L_(Q(Ïƒ_alg^2)) ] = (1 + Î²) Ïƒ_e^2,

where we wrote Q(Ïƒ_alg^2) to explicitly express the dependence of Q on Ïƒ_y^2. With this choice for Ïƒ_y^2 and setting ^2 = (1+Î²)Ïƒ_e^2 applied to (<ref>) we arrive at the statement of TheoremÂ <ref>. Note that with this choice of parameters term 1/2Ïƒ_y^2(^2 - L) from (<ref>) is equal to 0.




Â§ OMITTED PROOFS

Let {x_i}_i=1^k be a set of real numbers. For i=1, â‹¯, k, define the partial sums X_i=âˆ‘_j=1^i x_j. Then

    âˆ‘_i=1^k X_i^2 â‰¥1/8âˆ‘_i=1^k x_i^2.

Define X_0=0. Note that for i=1, â‹¯, k, X_i = X_i-1+x_i. Hence if |X_i-1| â‰¤1/2 |x_i| then |X_i|â‰¥1/2 |x_i| so that X_i^2â‰¥1/4 x_i^2. And if |X_i-1| â‰¥1/2 |x_i| then X_i-1^2â‰¥1/4 x_i^2. Therefore, X_i-1^2+X_i^2 â‰¥1/4 x_i^2. Summing the last inequality over i=1, â‹¯, k, and adding X_k^2 to the left hand side we get 2 âˆ‘_i=1^k X_i^2 â‰¥1/4âˆ‘_i=1^k x_i^2.

Let f(x)= âˆ‘_i=1^k w_i [x-b_i]_+, where 0 â‰¤ b_1 â‰¤â‹¯â‰¤ b_k â‰¤ 1 = b_k+1. For i=1, â‹¯, k, define the partial sums W_i=âˆ‘_j=1^i w_j. Then 

    f^2 â‰¥1/12âˆ‘_i=1^k W_i^2 (b_i+1 - b_i)^3.

Note that there are k non-overlapping intervals, namely [b_1, b_2], â‹¯, [b_k, 1], where the function is potentially non-zero. On the i-th interval the function is linear (or more precisely, affine) with a slope of W_i and, by assumption, the interval has length b_i+1-b_i. On this interval the integral of f(x)^2 must have a value of at least 1/12 W_i^2 (b_i+1-b_i)^3. The last statement follows by minimizing the integral of the square of an affine function with slope W_i over the choice of the parameters.

Let f_Î¸(x)= âˆ‘_i=1^k w_i [x-b_i]_+, where 0 â‰¤ b_1 â‰¤â‹¯â‰¤ b_k < +âˆ.

If f_Î¸^2 < 1/12(k+1)^5 then there exists Î¸^* such that f_Î¸^*â‰¡_[0,1] 0 and

    Î¸ - Î¸^*^2 â‰¤ O ( k^13/5f_Î¸^4/5).

Starting with the parameter Î¸ that defines the function f_Î¸(x), we define a process of changing it until the resulting function is equal to the zero function on [0, 1]. Most importantly, this process does not change Î¸ too much compared to the norm of f_Î¸(x). 

Note that there are two ways of setting the function to 0 on a particular interval. Either, we can make the length of the interval to be 0. This requires to change one of the bias terms by the length of the interval. Or we set the slope of this interval to be 0 (assuming that the function is already 0 at the start of the interval. Our approach uses both of those mechanisms. Let Î¸^0 â†Î¸. The process has two phases. In the first phase we change the bias terms and in the second phase we change the weights. For x âˆˆ [0,1], define the partial sums W(x)=âˆ‘_j: b_j â‰¤ x w_j. 



  
First phase. Let 
S := {[b_1,b_2], â€¦, [b_k-1,b_k],[b_k,1]} and  S_b := {[l,r] âˆˆ S : r - l < |W(l)| }. Let {[l_0,r_0],[l_1,r_1], â€¦, [l_i,r_i]}âŠ† S_b be a maximal continuous subset of intervals in S_b. That is, for all j âˆˆ [i], r_j = l_j+1 and the intervals ending at l_0 and starting at r_i are not in S_b. Perform the following: for all b_j âˆˆ [l_0,r_i] set b_j â† r_i. We do this operation for all maximal, continuous subsets of S_b. This finishes the first phase. Call the resulting vector of parameters Î¸^1. We bound

    Î¸^0 - Î¸^1^2 
       â‰¤ k (âˆ‘_[l,r] âˆˆ S_b (r-l) )^2 
       â‰¤ k^13/5(âˆ‘_[l,r] âˆˆ S_b (r-l)^5 )^2/5      By the Power Mean Inequality
       â‰¤ k^13/5(âˆ‘_[l,r] âˆˆ S_b (r-l)^3 W(l)^2 )^2/5      By definition of  S_b 
       â‰¤ k^13/5 (12 f_Î¸^2)^2/5      By LemmaÂ <ref>


  
Second phase. Observe that f_Î¸^1 has the following properties. For every x âˆˆ [0,1] âˆ–â‹ƒ_[l,r] âˆˆ S_b [l,r) we have W^1(x) = W^0(x). It is enough to make W(l) = 0 for all [l,r] such that [l,r] âˆˆ S âˆ– S_b.  Let i_1 < i_2 < â€¦ < i_p be all i_j's such that [b_i_j, b_i_j+1] âˆˆ S âˆ– S_b. Applying LemmaÂ <ref> to {W_i_1, W_i_2 - W_i_1, â€¦, W_i_p - W_i_p-1} we get that

    8âˆ‘_j=1^p W_i_j^2 â‰¥ W_i_1^2 + (W_i_2 - W_i_1)^2 + â€¦ (W_i_p - W_i_p-1)^2

The RHS of (<ref>) gives an upper-bound on the Â·^2 norm distance needed to change w_i's in Î¸^1 so that all W_i_j = 0. It is because we can change w_1, â€¦, w_i_1 by at most W_i_1^2 to make W_i_1 = 0 and so on for i_2, â€¦, i_p. Call the resulting vector of parameters Î¸^2. We bound the change in the second phase

    Î¸^1 - Î¸^2^2
       â‰¤ 8 âˆ‘_j=1^p W_i_j^2       (<ref>)
       â‰¤ 8k (1/kâˆ‘_j=1^p |W_i_j^5| )^2/5      Power Mean Inequality
       = 8k^3/5( âˆ‘_i : [b_i, b_i+1] âˆˆ S âˆ– S_b  |W_i^5| )^2/5      By definition
       â‰¤ 8k^3/5( âˆ‘_i : [b_i, b_i+1] âˆˆ S âˆ– S_b  (b_i+1 - b_i)^3 |W_i^2| )^2/5      By definition of  S_b 
       â‰¤ 8 k^3/5(12 f_Î¸^2 )^2/5      By LemmaÂ <ref>.

We conclude by

    Î¸^0 - Î¸^2^2 
       â‰¤ 4 max(Î¸^0 - Î¸^1^2, Î¸^1 - Î¸^2^2 )       Triangle inequality
       â‰¤ 96 k^13/5(f_Î¸^2 )^2/5      (<ref>) and (<ref>)

Let S^0 = {[b_1, b_2], â€¦, [b_k,1]} be the set of  active intervals at time t=0. I.e., initially all intervals are active. For t â‰¥ 0
    if there exists an i such that  [b_i^t,b_i+1^t] âˆˆ S^t  and  b_i+1^t - b_i^t < |W^t(b_i^t)|

then perform 

    Î¸^t+1â†Î¸^t, 
       Î±â† b_i^t,  Î²â† b_i+1^t,
       for every only rightendpoint j  such that  b_j^t = Î² set  b^t+1_j â†Î±, 
       S^t+1â† S^t âˆ–{[b^t_i, b^t_i+1] }.

In each step of the process one interval is removed from S, hence the process terminates in at most t_maxâ‰¤ k steps.
The following properties hold for every t < t_max:

  * Î¸^t+1 - Î¸^t^2â‰¤ 2k Â· (b^t_i+1 - b^t_i)^2 < 2k (W^t(b_i^t))^2, as at most 2k bias terms were changed, 
  *  for every x âˆˆ [0,1] âˆ– [b_i^t, b_i+1^t) we have W^t+1(x) = W^t(x), i.e. in the t-th step the slope changes only at [b_i^t, b_i+1^t), 
  *  for every x âˆˆ [b_i^t, b_i+1^t) we have W^t+1(x) = W^t(b_i+1^t). 
Note that, by construction, for every [b_i^t_max, b_i+1^t_max] âˆˆ S^t_max we have 

    b_i+1^t_max - b_i^t_maxâ‰¥ |W^t_max(b_i^t_max)|.

We bound

    12 âˆ«_0^1 f(x)^2  dx  
       â‰¥âˆ‘_i=1^k W_i^2 (b_i+1 - b_i)^3        LemmaÂ <ref>
       â‰¥âˆ‘_i : [b_i^t_max, b_i+1^t_max] âˆˆ S^t_max W_i^2 (b_i+1 - b_i)^3 + âˆ‘_i : [b_i^t_max, b_i+1^t_max] âˆ‰S^t_max W_i^2 (b_i+1 - b_i)^3 
       = âˆ‘_i : [b_i^t_max, b_i+1^t_max] âˆˆ S^t_max W^t_max(b_i^t_max)^2 (b_i+1^t_max - b_i^t_max)^3 
          + âˆ‘_t=1^t_max-1âˆ‘_i : [b_i^t-1, b_i+1^t-1] âˆˆ S^t-1âˆ– S^t  W^t-1(b^t-1_i)^2(b^t-1_i+1 - b^t-1_i)^3       By Property (<ref>)
       â‰¥âˆ‘_i : [b_i^t_max, b_i+1^t_max] âˆˆ S^t_max |W^t_max(b_i^t_max)^5| + âˆ‘_t=1^t_max-1âˆ‘_i : [b_i^t-1, b_i+1^t-1] âˆˆ S^t-1âˆ– S^t (b^t-1_i+1 - b^t-1_i)^5       By (<ref>) and (<ref>)
       = âˆ‘_i : [b_i, b_i+1] âˆˆ S^t_max |W_i^5| + âˆ‘_i : [b_i^t_max, b_i+1^t_max] âˆ‰S^t_max (b_i+1 - b_i)^5       By Property (<ref>)

We bound the change in the first phase

    Î¸ - Î¸^t_max^2 
       â‰¤(âˆ‘_t=1^t_maxÎ¸^t-1 - Î¸^t)^2       Triangle inequality
       â‰¤ 2( âˆ‘_i : [b_i^t_max, b_i+1^t_max] âˆ‰S^t_max k^1/2(b_i+1 - b_i) )^2       By Property (<ref>)
       â‰¤ 2k^3 (1/kâˆ‘_i : [b_i^t_max, b_i+1^t_max] âˆ‰S^t_max (b_i+1 - b_i)^5 )^2/5      Power Mean Inequality
       â‰¤ 6k^13/5(âˆ«_0^1 f_Î¸(x)^2  dx )^2/5      (<ref>)
RUnow sure what we use above; what does 1 refer to? it seems that we have several 1s and 2s references around

Now we show how to change the w_i's in Î¸^t_max to make the function the 0 function - this is the second phase. By Properties (<ref>) and (<ref>) it is enough to make W_i = 0 for all i such that [b_i, b_i+1] âˆˆ S^t_max. Let i_1 < i_2 < â€¦ < i_p be all i_j's such that [b_i_j, b_i_j+1] âˆˆ S^t_max. Applying LemmaÂ <ref> to {W_i_1, W_i_2 - W_i_1, â€¦, W_i_p - W_i_p-1} we get that

    8âˆ‘_j=1^p W_i_j^2 â‰¥ W_i_1^2 + (W_i_2 - W_i_1)^2 + â€¦ (W_i_p - W_i_p-1)^2

The RHS of (<ref>) gives an upper-bound on the Â·^2 norm distance needed to change w_i's in Î¸^t_max so that all W_i_j = 0. It is because we can change w_1, â€¦, w_i_1 by at most W_i_1^2 to make W_i_1 = 0 and so on for i_2, â€¦, i_p. Call the resulting vector of parameters Î¸^*. We bound the change in the second phase

    Î¸^t_max - Î¸^*^2
       â‰¤ 8 âˆ‘_j=1^p W_i_j^2       (<ref>)
       â‰¤ 8k (1/kâˆ‘_j=1^p |W_i_j^5| )^2/5      Power Mean Inequality
       = 8k^3/5( âˆ‘_i : [b_i, b_i+1] âˆˆ S^t_max |W_i^5| )^2/5      By definition
       â‰¤ 24 k^3/5(âˆ«_0^1 f_Î¸(x)^2  dx )^2/5      (<ref>).

We conclude by

    Î¸ - Î¸^*^2 
       â‰¤ 4 max(Î¸ - Î¸^t_max^2, Î¸^t_max - Î¸^*^2 )       Triangle inequality
       â‰¤ 96 k^13/5(âˆ«_0^1 f_Î¸(x)^2  dx )^2/5      (<ref>) and (<ref>)
[Withb^(2)]
Let R âˆˆ_+, Î¸âˆˆ B_R âˆ©(P) be such that f_Î¸(x)= b^(2) + âˆ‘_i=1^k w_i [x-b_i]_+, where 0 â‰¤ b_1 â‰¤â‹¯â‰¤ b_k < +âˆ. If f_Î¸^2 is small enough, where the bound depends only on R and k, then there exists Î¸^* such that f_Î¸^*â‰¡_[0,1] 0 and

    Î¸ - Î¸^*^2 â‰¤ O ( k^5 R^4/5f_Î¸^2/5) .

Let ^2 = f_Î¸^2. For x âˆˆ, define the partial sums W(x)=âˆ‘_j: b_j â‰¤ x w_j. 




Consider the following cases:


  
Case |b^(2)| â‰¤^1/2.  We perform Î¸' â†Î¸, b^(2)'â† 0. By triangle inequality we can bound
f_Î¸'||^2 â‰¤(  + |b^(2)| )^2 â‰¤ 4 . We apply LemmaÂ <ref> to Î¸' to obtain Î¸^* such that f_Î¸^*â‰¡_[0,1] 0 and Î¸' - Î¸^*^2 â‰¤ O(k^13/5f_Î¸'||^4/5) â‰¤ O(k^13/5^2/5). We conclude by noticing

    Î¸ - Î¸^*^2 
       â‰¤(Î¸ - Î¸' + Î¸' - Î¸^*)^2       Triangle inequality
       â‰¤(^1/2 + O(k^13/10^1/5) )^2 
       â‰¤ O(k^13/5f_Î¸^2/5)       As ^2 â‰¤ 1.


  
Case |b^(2)| > ^1/2.  Without loss of generality assume that b^(2)>0. There exists x_0 âˆˆ (0,/4), such that f_Î¸(x_0) = b^(2)/2, as otherwise 
^2 â‰¥âˆ«_0^/4 f_Î¸(x)^2  dx â‰¥âˆ«_0^/4 (b^(2))^2 / 4  dx > ^2. By the mean value theorem there exists x_1 âˆˆ (0,x_0) âˆ–{b_1, â€¦, b_k} such that 

    f_Î¸(x_1) âˆˆ [b^(2)/2, b^(2)]  and  W(x_1) â‰¤f_Î¸(x_0) - f_Î¸(0)/x_0 - 0â‰¤ -4b^(2)/2â‰¤ -2^-1/2.

We perform the following transformation

    Î¸' â†Î¸, 
       for every  i  such that  b_i < x_1  do  b'_i â† b_i - x_1 + f_Î¸(x_1)/W(x_1), 
       i_0 â†_i b_i > x_1, 
       b'_i_0â† 0.

Observe that we shifted all b_i's exactly so that f_Î¸'(0) = 0. Note also that b_i_0â‰¤ 4 as otherwise by LemmaÂ <ref>^2 â‰¥âˆ«_x_1^b_i_0 f_Î¸(x)^2  dx â‰¥1/12 W(x_1)^2 (b_i_0 - x_1)^3 > 1/12 4^-1 (3)^3 â‰¥^2.

By (<ref>) we can bound 

    Î¸ - Î¸'^2 
    â‰¤ k (-x_1 + f_Î¸(x_1)/W(x_1))^2 + 16^2 â‰¤ O(k^2).
f_Î¸ is R-Lipshitz wrt to b_i's in B_R thus the triangle inequality and (<ref>) gives 

    f_Î¸'^2
    â‰¤  (f_Î¸ + O(R k^3/2))^2 
    â‰¤ O(R^2 k^5 ^2).

We apply LemmaÂ <ref> to f_Î¸', after we removed all b'_i < 0 and set w'_i_0â†âˆ‘_j â‰¤ i_0 w_j. LemmaÂ <ref> might require to change w'_i_0, which we can realize with the same cost by changing {w_j : j â‰¤ i_0}. Thus LemmaÂ <ref> and (<ref>) gives us that there exists Î¸^* such that f_Î¸^*â‰¡_[0,1] 0 and Î¸' - Î¸^*^2 â‰¤ O(k^13/5 k^2 R^4/5^4/5). We conclude by using the triangle inequality and (<ref>) to get
Î¸ - Î¸^*^2 â‰¤ O(k^23/5 R^4/5f_Î¸^4/5).
Let R âˆˆ_+, Î¸âˆˆ B_R âˆ©(P) be such that f_Î¸(x)= b^(2) + âˆ‘_i=1^k w_i [x-b_i]_+ and g(x) = b + âˆ‘_i=1^c v_i [x - t_i]_+, where c â‰¤ k, 0 â‰¤ b_1 â‰¤â‹¯â‰¤ b_k < +âˆ, 0 < t_1 < â€¦ < t_c < 1 and v_1,â€¦,v_c â‰  0. If g - f_Î¸^2 is small enough,  where the bound depends only on g,R and k, then there exists Î¸^* such that f_Î¸^*â‰¡_[0,1] g and

    Î¸ - Î¸^*^2 â‰¤ O ( k^7 R^4/5g - f_Î¸^2/5) .

Consider a model on c+k â‰¤ 2k neurons represented as

    h_Î¸ := (b^(2) - b) + âˆ‘_i=1^k w_i [x-b_i]_+ - âˆ‘_i=1^c v_i [x - t_i]_+,

where, to distinguish it from Î¸, we denoted by  the set of parameters of h. Observe that h^2 = g - f_Î¸^2. By LemmaÂ <ref> there exists ^* such that h_^*â‰¡_[0,1] 0 and - ^*^2 â‰¤ O ( k^5 R^4/5g - f_Î¸^2/5). If  is small enough then the parameters in ^* corresponding to v_i's are all still all non-zero and the bias terms corresponding to t_i's are still all different. As h_^*â‰¡_[0,1] 0 it implies that for every i âˆˆ [c] there is a set of bias terms corresponding to b_j's that are exactly at where t_i was moved. Let Ï€ : [c] â†’ 2^[k] be the mapping from t_i's to subsets of b_i's certifying that. 

We define Î¸^* such that f_Î¸^*â‰¡_[0,1] g as the result of two steps. First, changing Î¸ as its corresponding parameters were changed in the transition â†’^*. Second, changing the parameters as v_i's and t_i's are changed in ^* â†’ under the map Ï€. Observe that Î¸ - Î¸^*^2 â‰¤ k^2  - ^*^2. It is because in the second step we move at most k bias terms for every parameter corresponding to t_i.     


Proof of LemmaÂ <ref>



Let R âˆˆ_+. Notice that f_Î¸ is R^2-Lipschitz with respect to each of its parameters, when restricted to a ball B_R. This implies that for all > 0
    (A_g + B_) âˆ© B_R âŠ†{Î¸ : g - f_Î¸^2 â‰¤ R^4 ^2 }.

On the other hand by LemmaÂ <ref> we have that for small enough 
    {Î¸ : g - f_Î¸^2 â‰¤^2 }âˆ© B_R âˆ©(P) âŠ† A_g + B_O ( k^7/2 R^2/5^1/5) âŠ† A_g + B_C(k,R)^1/5,

for some function C.

Next we prove (<ref>). Let Î¸âˆˆ B_R be such that g - f_Î¸^2 â‰¤^2. Let Î·(Î”, W) denotes the minimum â„“_2 difference on [-Î”, Î”] between a linear function and a two-piece linear function that has a change of slope of W at 0, i.e.
Î·(Î”,W) = min_a,bâˆ«_-Î”^0 (ax + b)^2 dx + âˆ«_0^Î” (ax+b - W x)^2  dx. Solving the minimization problem we get

    Î·(Î”, W) = Î”^3 W^2/24.

 
We proceed by changing Î¸ in phases to arrive at an exact representation of g while incurring only a small change to Î¸ in the Â·^2 norm. In phase 1 we make sure that fâ€ roughly agrees with gâ€ at t_1, â€¦, t_c, then, in phase 2, we make sure that the agreement is exact and finally, in phase 3, we enforce agreement of f and g on whole [0,1].



  
Phase 1. 

We perform the following transformation

    Î¸' â†Î¸, 
       for every  i âˆˆ [1,c]  such that  |v_i| â‰¥^1/2 do 
              for every  j âˆˆ [1,k]  such that  |_j^(1) - t_i| â‰¤ 4^1/3 do 
                     _j^(1)'â† t_i,

First note that every bias term is changed at most once because the intervals [t_i - 4^1/3,t_i + 4^1/3] don't intersect by assumption that = o(Îº^3). After this transformation the following holds. For every i âˆˆ [1,c] we have |fâ€_Î¸' - v_i| â‰¤^1/2
Observe that there exists _j^(1) such that |_j^(1) - t_i| â‰¤ 4^1/3 as otherwise the cost incurred to g - f_Î¸^2 on [t_i - 4^1/3, t_i + 4^1/3] is at least 64/24^2. Note that we implicitly assumed that < 1/4Îº^3.

If we perform Î¸' â†Î¸, _i^(1)'â† t_i then Î¸ - Î¸'^2 â‰¤ 16^2/3 and 

    g - f_Î¸'^2 
       â‰¤ (g - f_Î¸ + f_Î¸ - f_Î¸')^2 
       â‰¤ ( + 4 R^2 ^1/3)^2       f is R^2-Lipschitz in B_R with respect to _i^(1)
       â‰¤^2 + 8^4/3 R^2 + 16 R^4 ^2/3
       â‰¤ 32 R^4 ^2/3.
I think we need to be careful here. All operations should be done at the same time
We can view the transformation Î¸â†’Î¸' as an operation after which we have a new target function g' = g - _i^(2)_i^(1) [x - t_i]_+ and a new model for f, where we drop the i-th node. We apply the operation for as long as possible. This process terminates because in each step we remove one node. After the process is finished, if we denote the resulting set of parameters by Î¸â€, we have that for every i âˆˆ [1,c]
|gâ€(t_i) - f_Î¸â€â€(t_i)| < ^1/2.

Moreover by an analogous argument to (<ref>) we have that g - f_Î¸â€^2 â‰¤ O( k R^4 ^2/3 ). We also have Î¸ - Î¸â€^2 â‰¤ O( k ^2/3).



  
Phase 2. In this phase we change Î¸â€ further to obtain Î¸â€' so that for every j âˆˆ [1,c]gâ€(t_j) = f_Î¸â€'â€(t_j). Let j âˆˆ [1,c] and let S_j := {i âˆˆ [1,c] : _i^(1)â€ = t_j}. Let i âˆˆ S_j. We can change each of w_i^(2)â€, w_i^(1)â€ by at most ^1/2 in the Â·^2 norm so that âˆ‘_i âˆˆ S_j w_i^(2)â€  w_i^(1)â€ = f_Î¸â€â€(t_j) = gâ€(t_j). We apply such a transformation for every j âˆˆ [1,c] and call the result Î¸â€'.  The result satisfies Î¸ - Î¸â€'^2 â‰¤ O(k ^2/3) + 2k ^1/2â‰¤ O(k ^1/2), 
    g - f_Î¸â€'^2 
       â‰¤ O( k R^4 ^2/3 ) + k(R + ^1/4)^4 ^1/2
       â‰¤ O( k R^4 ^1/2 )       As ^1/4 < R,

where in the first inequality we used the fact that f_Î¸ is R-Lipshitz with respect to w_i^(2) in B_R. 



  
Phase 3. Let S := {i âˆˆ [1,k] : _i^(1)â€'âˆˆ{t_1, â€¦, t_c }}. Let Î¸^0 represent a model where the weights are equal to Î¸â€' but all nodes in S are removed. We will change Î¸^0 so that it represents the 0 function. By definition

    f_Î¸^0^2 â‰¤ O( k R^4 ^1/2 ).

We would like to now use LemmaÂ <ref>. But note that in this lemma we assumed that the model is b^(2) +âˆ‘_i=1^k w_i [x-b_i]_+ not âˆ‘_i=1^k _i^(2)Â·_i^(1)[x - _i^(1)]_+ + b^(2). Let i âˆˆ [1,k]. If w_i was changed by Î´^2 in the Â·^2 norm then we can realize the same effective change in _i^(2)Â·_i^(1) by changing the weight with the smaller absolute value by at most Î´ +Î´^2 in the Â·^2 norm. Thus LemmaÂ <ref> and (<ref>) give us that there exists Î¸^* such that f_Î¸^*â‰¡_[0,1] 0 and
Î¸ - Î¸^*^2 â‰¤ O (k^5 R^4/5 k^1/5 R^4/5^1/10) â‰¤ O (k^6 R^8/5^1/10).

To finish the proof we bound

    Ï‡^#(g, U([0,1])) 
       = lim_Ïµâ†’ 0log[_Î¸{Î¸: g - f_Î¸^2 â‰¤^2 }]/log()
       (1)=lim_R â†’âˆlim_Ïµâ†’ 0log[_Î¸{Î¸: g - f_Î¸^2 â‰¤^2, Î¸_2 â‰¤ R }]/log()
       (2)â‰¥lim_R â†’âˆlim_â†’ 0log(( (A + B_C(k,R) ^1/5) âˆ© B_R âˆ©(P) ) max_Î¸âˆˆ B_R P(Î¸) )/log()
       (3)=lim_R â†’âˆlim_â†’ 0log(( (A + B_C(k,R) ^1/5) âˆ© B_R âˆ©(P)) )/log(C(k,R) ^1/5)Â·log(C(k,R) ^1/5)/log()
       (4)=1/5lim_R â†’âˆlim_â†’ 0log(( (A + B_C(k,R) ^1/5) âˆ© B_R âˆ©(P)) )/log(C(k,R) ^1/5)
       = 1/5_P(A_g),

where in (1) we assumed that the two quantities are equal, in (2) we used (<ref>), in (3) we used  lim_â†’ 0max_Î¸âˆˆ B_R P(Î¸)/log() = 0 and in (4) we used lim_â†’ 0log(C(k,R)^1/5)/log() = 1/5. The second bound reads

    Ï‡^#(g, U([0,1])) 
       = lim_R â†’âˆlim_Ïµâ†’ 0log[_Î¸{Î¸: g - f_Î¸^2 â‰¤^2, Î¸_2 â‰¤ R }]/log()
       (1)â‰¤lim_R â†’âˆlim_â†’ 0log(( (A + B_R^2 ) âˆ© B_R âˆ©(P)) Â·min_Î¸âˆˆ B_R âˆ©(P) P(Î¸) )/log()
       (2)=lim_R â†’âˆlim_â†’ 0log(( (A + B_R^2 ) âˆ© B_R âˆ©(P)))/log( R^2 )Â·log(R^2 )/log()
       = _P(A_g),

where in (1) we used (<ref>) and in (2) we used min_Î¸âˆˆ B_R âˆ©(P) P(Î¸) > 0, which is true because B_R is compact.









Proof of LemmaÂ <ref>
Let  and  denote the vectors of t_i's, and v_i's respectively. Note that if for i âˆˆ [1,c] we define  b_i^(1) := t_i, w_i^(2) := v_i/w_i^(1) and b^(2) := b then for every x âˆˆ [0,1]
g(x) = âˆ‘_i=1^c w_i^(2)Â· w_i^(1)[x - b_i^(1)]_+ + b^(2).

Moreover if the neurons i âˆˆ [c+1,k] are inactive on [0,1], that is if b_i^(1) > 1 for all i > c, then g â‰¡_[0,1] f_Î¸, i.e. functions g an f_Î¸ agree on [0,1]. If we denote by _[p,q] the restrictions of  to coordinates p,â€¦,q, then for < max(t_1, t_2 -t_1, â€¦, t_c, 1 - t_c) we can write

    (A_g + B_) âˆ© B_R âˆ©(P) 
       âŠ‡{Î¸ : _[1,c] - ^2 â‰¤^2/3, _[c+1,k]âˆˆ [1,M]^k-c, ^(2)^(1) - ^2 â‰¤^2/3, (b^(2) - b)^2 â‰¤^2/3}âˆ© B_R.

Now we will estimate ({ : ^(2)^(1) - ^2 â‰¤^2 }âˆ© B_R).





If k=1 and R^2 > 5|v_1|:

    ({w^(1),w^(2)âˆˆ : (w^(2)w^(2) - v)^2 â‰¤^2 }âˆ© B_R ) 
       â‰¥ 2âˆ«_|v|^1/2^2|v|^1/22/w^(1) dw^(1)
       = 4(log(2|v|^1/2) - log(|v|^1/2)) = 4log(2) .

Bound from (<ref>) generalizes to higher dimensions. If R^2 > 5^2 then

    ({ : ^(2)^(1) - ^2 â‰¤^2 }âˆ© B_R) â‰¥Îº^c,

where Îº is independent of , Îº depends only on the volume of balls in ^c and the constants 4log(2) from (<ref>). Now we can lower-bound the co-dimension

    _P(A_g)    =
    lim_R â†’âˆlim_â†’ 0log(( (A_g + B_) âˆ© B_R âˆ©(P)))/log()
       â‰¤lim_â†’ 0log(Îº' (/âˆš(3))^c Â· (M-1)^k-cÂ·Îº (/âˆš(3))^c Â·2/âˆš(3))/log()      By (<ref>) and (<ref>)
       = 2c+1,

where similarly as before Îº' is a constant independent of .

Now we will show an inequality in the other direction. Assume towards contradiction that (A_g) < 2c+1. This means that there exists Î¸âˆˆint((P)), f_Î¸ = g and u_1, â€¦, u_3k+1-2câˆˆ^3k+1 linearly independent such that Î¸ + ConvHull(u_1, â€¦, u_3k+1-2c) âŠ† A_g. Fix one such Î¸.

Next observe that 

    b^(2) = b.

Moreover

    {t_1, â€¦, t_c}âŠ†{_1^(1),â€¦, _k^(1)},

because if there was t_i âˆ‰{_1^(1),â€¦, _k^(1)} then fâ€_Î¸(t_i) = 0 but gâ€(t_i) = v_i â‰  0. For every i âˆˆ [1,k] define S_i := {j âˆˆ [1,k] : _j^(1) = _i^(1)}. Note that for every i âˆˆ [1,k] such that _i^(1) = t_j for some j âˆˆ [1,c] we have:

    âˆ‘_p âˆˆ S_i_p^(2)Â·_p^(1) =  
                v_j    _i^(1) = t_j 
     
                0    _i^(1)âˆˆ [0,1] âˆ–{t_1, â€¦, t_c}

If not then let i_0 be such that _i_0^(1) is the minimal one such that (<ref>) doesn't hold. Note that then g â‰¢_[_i_0^(1), _i_0^(1) + Î´] f_Î¸, where Î´ > 0 is small enough so that {_1^(1),â€¦, _k^(1)}âˆ© (_i_0^(1) , _i_0^(1) + Î´) = âˆ…. 
Now observe that (<ref>), (<ref>) and (<ref>) give us locally at least 2c+1 linearly independent equations around Î¸ which contradicts with Î¸ + ConvHull(u_1, â€¦, u_3k+1-2c) âŠ† A_g. Thus (A_g) â‰¥ 2c+1. 


Next we give a helpful fact.


Let X,Y be two independent random variables distributed according to ğ’©(0,Ïƒ_w^2). Then for every a_0 âˆˆ we have that the density of XY at a_0 is equal to

    f_XY(a_0) = 1/2Ï€Ïƒ_w^2âˆ«_-âˆ^+âˆ e^-1/2Ïƒ_w^2(w^2 + a_0^2/w^2) dw = 1/âˆš(2Ï€Ïƒ_w^2)e^-|a_0|/Ïƒ_w^2.


Proof of LemmaÂ <ref>
To prove the lemma we estimate the probability of f_Î¸'s close to g_1. Without loss of generality assume that a > 0.



  
Upper bound. We can represent g_1 with a single node i by assigning âˆš(a) to the outgoing weight (^(2)_i), âˆš(a) to the incoming weight (^(1)_i) of this node, the bias term (^(1)_i) to t and b^(2) to b. The bias terms of all other nodes lie in (1,M], i.e. they are inactive in the interval [0,1].

These are exact representations of the function but to compute a lower bound on the probability we should also consider functions that are close to g_1. We can change _i^(1), _i^(2), _i^(1) by a little bit and still have a function that satisfies g_1 - f_Î¸^2 â‰¤^2. We claim that the target probability is lower bounded by

    ( /21/âˆš(2Ï€Ïƒ_w^2) e^-10 a/9 Ïƒ_w^2) Â·(9/20 M a) Â·( /401/âˆš(2Ï€Ïƒ_b^2) e^-(|b| + /40)^2/2Ïƒ_b^2) Â·( M-1/M)^k-1.

We arrive at this expression by noting the following facts. By (<ref>) and the assumption that a â‰¥ 20 the probability that _i^(2)_i^(1) = a Â±/2 is lower bounded by /21/âˆš(2Ï€Ïƒ_w^2) e^-10 a/9 Ïƒ_w^2. The probability that _i^(1) = t Â±9/20a is equal 9/20M a. The probability that b^(2) = b Â±/40 is lower bounded by /401/âˆš(2Ï€Ïƒ_b^2) e^-(|b| + /40)^2/2Ïƒ_b^2. The last term is the probability that all other nodes have bias terms in [1,M]. Their weights can realm over the whole space and these nodes don't affect the function on [0,1]. We claim that all functions of this form satisfy g_1 - f_Î¸^2 â‰¤^2. We bound the pointwise difference of g_1 and f_Î¸ in [0,1], i.e. for every x âˆˆ [0,1]
    f_Î¸(x) = b + (_i^(2)_i^(1)Â±/2)[x - (_i^(1)Â±9/20a)]_+ Â±/40
       = b + _i^(2)_i^(1)[x - (_i^(1)Â±9/20a)]_+ Â±/2[x - (_i^(1)Â±9/20a)]_+ Â±/40
       = b + _i^(2)_i^(1)[x - _i^(1)]_+ Â±_i^(2)_i^(1)9/20aÂ±/2(1 + 9/20a) Â±/40
       = b + _i^(2)_i^(1)[x - _i^(1)]_+ Â±9/20Â±/2(21/20 + 9/20a)       As _i^(2)_i^(1) = a 
       = b + _i^(2)_i^(1)[x - _i^(1)]_+ Â±      As  a â‰¥ 20,

which implies that for such representations g_1 - f_Î¸^2 â‰¤^2. From (<ref>) we get an upper bound on the sharp complexity 

    Ï‡^#( g_1, ^2) 
       â‰¤ -log[ ( /21/âˆš(2Ï€Ïƒ_w^2) e^-10 a/9 Ïƒ_w^2) Â·(9/20 M a) Â·( /401/âˆš(2Ï€Ïƒ_b^2) e^-(|b| + /40)^2/2Ïƒ_b^2) Â·( M-1/M)^k-1] 
       â‰¤10/9(a/Ïƒ_w^2 + |b|/Ïƒ_b^2) + log(M a ) - (k-1) log(1 - 1/M) + log(2Ï€Ïƒ_w Ïƒ_b) + 7 - 3 log()
       â‰¤10/9(a/Ïƒ_w^2 + |b|/Ïƒ_b^2) + log(M a ) - (k-1) log(1 - 1/M) + 10 - 3 log().       As Ïƒ_b^2 â‰¤1/Ïƒ_w^2
       â‰¤ 2(a/Ïƒ_w^2 + |b|/Ïƒ_b^2) + 11 - 3log(),

where in the last inequality we used that log(x) < x/2,  log(1+x) < x for x> 0 and the assumption k â‰¤ M â‰¤1/Ïƒ_w^2.
















Observe that according to CorollaryÂ <ref> we have that Ï‡^#(g_1, _x) â‰¤ 3. Recall that Ï‡^#(g_1, _x) = lim_â†’ 0 -Ï‡^#(g_1, _x, ^2)/log(). This means that, at least approximately, if we took the bound from (<ref>), divided it by -log() we would get an upper bound on  Ï‡^#(g_1, _x). This would yield for us Ï‡^#(g_1, _x) â‰¤ 3, as all other terms go to 0 when â†’ 0. 



  
Lower bound. There are other Î¸'s that represent the function approximately. For example we could represent g_1 with more than 1 node, by spreading the change of slope a over many nodes. Another possibility is that a number of nodes with the same bias terms t â‰  b âˆˆ [0,1] effectively cancel out. These Î¸'s contribute to the probability and decrease the complexity. 






Let Î¸ be such that g_1 - f_Î¸^2 â‰¤^2 and let S := {i âˆˆ{1, â€¦, k} : _i^(1)âˆˆ [t - 9^1/2, t + 9^1/2] }. 




Assume towards contradiction that âˆ‘_i âˆˆ S |_i^(1)_i^(2)| < a -^1/4. This implies that either

    âˆ‘_i : _i^(1)âˆˆ [t - 9^1/2,t] |_i^(1)_i^(2)| < f'_Î¸(t) - ^1/4/2

or

    âˆ‘_i : _i^(1)âˆˆ [t, t + 9^1/2] |_i^(1)_i^(2)| < a - f'_Î¸(t) -  ^1/4/2.

Assume that (<ref>) holds. A similar argument covers (<ref>). Now consider two cases.



  
Case 1. For all x âˆˆ [t, t+ 3^1/2] we have f_Î¸(x) > a(x-t) + ^3/4. Then g_1 - f_Î¸^2 â‰¥ 3^1/2Â·^3/2 > ^2. 


  
Case 2. There exists x_0 âˆˆ [t,t+3^1/2] such that 
    f_Î¸(x_0) < a(x_0-t) + ^3/4.

By (<ref>) we know that for all x âˆˆ [t,t+9^1/2] we have f'_Î¸(x) < a - ^1/4/2. This means that f_Î¸(x) is below a linear function of slope a-^1/4/2 passing through (x_0,f_Î¸(x_0)). Now we lower bound the error using the fact that f_Î¸ is below this line. 

    g_1 - f_Î¸^2 
       â‰¥âˆ«_x_0^t+9^1/2[a(x-t) - (f(x_0) + (a - ^1/4/2)(x-x_0)) ]^2 1_{a(x-t) > f(x_0) + (a - ^1/4/2)(x-x_0)} dx

Note that the function Î´(x) := a(x-t) - (f(x_0) + (a - ^1/4/2)(x-x_0)) is increasing in x and moreover 

    Î´(7^1/2 + t) 
       =  a(x_0-t) - f(x_0) + ^1/4/2(7^1/2 + t - x_0) 
       â‰¥ -^3/4 + 2^3/4      By (<ref>) and  x_0 < t + 3^1/2
       â‰¥^3/4.

Combining (<ref>) and (<ref>) we get that
g_1 - f_Î¸^2 â‰¥ 2^1/2Â·^6/4 > ^2,

which is a contradiction .

We arrived at a contradiction in both cases thus âˆ‘_i âˆˆ S |_i^(1)_i^(2)| â‰¥ a -^1/4. We claim that for every such S the probability of âˆ‘_i âˆˆ S |_i^(1)_i^(2)| â‰¥ a -^1/4 is at most

    ( 18^1/2/M)^|S|âˆ«_a - ^1/4^âˆ x^(|S| - 1)2^|S|/|S|!Â·2/âˆš(2Ï€Ïƒ_w^2)e^-x/Ïƒ_w^2 dx.





We arrive at this expression by noting that x^(|S| - 1)2^|S|/|S|! is the area of an â„“_1 sphere of radius x in |S| dimensions; the density for _i's satisfying âˆ‘_i âˆˆ S |_i^(1)_i^(2)| = x is, by FactÂ <ref>, 2/âˆš(2Ï€Ïƒ_w^2)e^-x/Ïƒ_w^2; the probability that a single bias term is equal to t Â± 9^1/2 is 18^1/2/M.


There has to exist S âŠ†{1, â€¦, k} such that âˆ‘_i âˆˆ S_i^(1)_i^(2) = a  Â± and for all i âˆˆ S we have _i^(1) = t  Â±/âˆš(a), i.e. there exists a subset of nodes whose slopes add up to approximately a and their bias terms are around t. For every such S the probability What about +1/-1? that âˆ‘_i âˆˆ S_i^(1)_i^(2) = a  Â± and _i^(1) = t  Â±/âˆš(a) is approximately

    a^(|S| - 1)/22 Ï€^|S|/2/Î“(|S|/2)Â·Â·( /âˆš(a)M)^|S|Â·âˆš(2Ï€)e^-a/Ïƒ_w^2.

We arrive at this expression by noting that a^(|S| - 1)/22 Ï€^|S|/2/Î“(|S|/2) is the area of a sphere of radius âˆš(a) in |S| dimensions, multiplying it by thickness ; the density for _i's satisfying âˆ‘_i âˆˆ S_i^(1)_i^(2) = a is by (<ref>)âˆš(2Ï€)e^-a/Ïƒ_w^2; the probability that a single bias term is equal to t Â±/âˆš(a) is /âˆš(a)M.


Now we upper bound the probability of all these functions by taking a union bound over sets S. We get 

    _Î¸[g_1 - f_Î¸^2 â‰¤^2 ] 
       â‰¤âˆ‘_S âŠ†{1,â€¦,n}âˆ«_a - ^1/4^âˆ x^(|S| - 1)2^|S|/|S|!Â·( 18^1/2/k)^|S|Â·âˆš(2/Ï€Ïƒ_w^2)e^-x/Ïƒ_w^2 dx       By (<ref>) and k â‰¤ M
       â‰¤âˆš(2/Ï€Ïƒ_w^2)âˆ‘_i=1^k âˆ«_a - ^1/4^âˆki2^i/i!( 1/2k)^iÂ· x^i - 1 e^-x/Ïƒ_w^2 dx        As  18^1/2â‰¤1/2
       â‰¤âˆš(2/Ï€Ïƒ_w^2)âˆ‘_i=1^k âˆ«_a/2^âˆx^i-1/2^i-1 e^- x/Ïƒ_w^2 dx       As kiâ‰¤ k^i, i! â‰¥ 2^i-1, a â‰¥ 2^1/4

For every i âˆˆ [1,k] we can upper bound 

    âˆ«_a/2^âˆx^i-1/2^i-1 e^-x/Ïƒ_w^2 dx 
       â‰¤âˆ«_a/2^2 e^-x/Ïƒ_w^2 dx + [-x^i/2^i-1 e^-x/Ïƒ_w^2]_2^âˆ      As (-x^i e^-x/Ïƒ_w^2)' â‰¥ x^i-1 e^-x/Ïƒ_w^2 for  x â‰¥ 2 
       â‰¤[-Ïƒ_w^2 e^-x/Ïƒ_w^2]^2_a/2  + 2e^-2/Ïƒ_w^2
       â‰¤Ïƒ_w^2 e^-a/2Ïƒ_w^2 + 2e^-2/Ïƒ_w^2
       â‰¤ 3e^-a/2Ïƒ_w^2      As Ïƒ_w^2 â‰¤ 1, a â‰¤ 2

Plugging (<ref>) back to (<ref>) we get 

    _Î¸[g_1 - f_Î¸^2 â‰¤^2 ] â‰¤âˆš(18/Ï€)k/Ïƒ_w e^-a/2Ïƒ_w^2.

With (<ref>) we can bound the sharp complexity

    Ï‡^#(_x, g_1, ^2) 
       â‰¥a/2Ïƒ_w^2 - log(k/Ïƒ_w) + log(âˆš(2Ï€)) 
       â‰¥a/3Ïƒ_w^2      As Î©(Ïƒ_w^2log(k/Ïƒ_w)) â‰¤ |a|.

    _Î¸[g_1 - f_Î¸^2 â‰¤^2 ] 
       â‰¤âˆš(2Ï€)âˆ‘_S âŠ†{1,â€¦,n} e^-ak a^(|S| - 1)/22 Ï€^|S|/2/Î“(|S|/2)Â·( /âˆš(a)k)^|S|      By (<ref>), k = M = 1/Ïƒ_w^2
       â‰¤âˆš(2Ï€)âˆ‘_i=1^k e^-akki a^(|S| - 1)/22 Ï€^|S|/2/Î“(|S|/2)Â·( /âˆš(a)k)^|S|
       â‰¤âˆš(2Ï€)âˆ‘_i=1^k e^-ak + ilog(k e/i) + i-1/2log(a) - i/2log(i/2Ï€ e) + i log(/âˆš(a)k)       As kiâ‰¤(k e/i)^i  and Î“(x+1) â‰ˆâˆš(2Ï€ x)(x/e)^x 
       â‰¤âˆš(2Ï€)âˆ‘_i=1^k e^-ak + ilog(  e âˆš(2Ï€ e)/âˆš(a) i^3/2) + i-1/2log(a)
       â‰¤âˆš(2Ï€)âˆ‘_i=1^k e^-ak/2 + ilog(  e âˆš(2Ï€ e)/âˆš(a) i^3/2)      Because log(a) â‰¤ a  for  a > 0.

Using the assumption  e âˆš(2 Ï€ e)/âˆš(a) < 1 we can upper bound it further

    âˆš(2Ï€)e^-ak/2Â·âˆ‘_i=1^k (  e âˆš(2Ï€ e)/âˆš(a) i^3/2)^i 
       â‰¤âˆš(2Ï€)e^-ak/2Â· 2       As âˆ‘_i=1^k (1/i^3/2)^i â‰¤âˆ‘_i=1^k 2^-iâ‰¤ 2.

Finally we get a lower bound for the complexity

    Ï‡^#(_x, g_1, ) 
       â‰¥ak/2 -1/2log(2Ï€) - log() - log(2) 
       â‰¥ak/2 - log() - 3.