
	
	A.L. Gallo, P. RomÃ¡n]Andrea L. Gallo, Pablo RomÃ¡n
	March 30, 2023
	
	2020 Mathematics Subject Classification. Primary 33C45.
	Partially supported by CONICET, FONCyT and SECyT-UNC
	
	
		We study algebras of differential and difference operators acting on matrix valued orthogonal polynomials (MVOPs) with respect to a weight matrix of the form  W^(Î½)_Ï•(x) = x^Î½e^-Ï•(x) W^(Î½)_pol(x), where Î½>0, W^(Î½)_pol(x) is certain matrix valued polynomial and Ï• an entire function. We introduce a pair differential operators ğ’Ÿ, ğ’Ÿ^â€  which are mutually adjoint with respect to the matrix inner product induced by W^(Î½)_Ï•(x). We prove that the Lie algebra generated by ğ’Ÿ and ğ’Ÿ^â€  is finite dimensional if and only if Ï• is a polynomial, giving a partial answer to a problem by M. Ismail. In the case Ï• polynomial, we describe the structure of this Lie algebra.  The case Ï•(x)=x, is discussed in detail. We derive difference and differential relations for the MVOPs. We give explicit expressions for the entries of the MVOPs in terms of classical Laguerre and Dual Hahn polynomials.
	
	
	Lie algebras of differential operators for Matrix valued Laguerre type polynomials
    [
    
==================================================================================



Â§ INTRODUCTION

	The theory of matrix valued orthogonal polynomials (MVOPs) was initiated by Krein 1940s, and it has since been used in various areas of mathematics and mathematical physics. These areas include spectral theory, scattering theory, tiling problems, integrable systems, and stochastic processes. For further details and insights on these subjects, refer to <cit.>, <cit.>, <cit.>, <cit.>, <cit.>, <cit.>, and the references therein.
	
	Significant progress has been made in the past two decades towards understanding how the differential and algebraic properties of classical scalar orthogonal polynomials can be extended to the matrix valued setting. A fundamental role has been played by the connection between harmonic analysis of matrix valued functions on compact symmetric pairs and matrix valued orthogonal polynomials. In <cit.>, A. DurÃ¡n poses the problem of determining families of MVOPs which are eigenfunctions of a suitable second order differential operator. In the scalar case, the answer to this problem is a classical result due to Bochner <cit.>. The only families with this property are those of Hermite, Laguerre and Jacobi. The matrix valued setting turns out to be much more involved. The first explicit examples appeared in connection with spherical functions of the compact symmetric pair (SU(3),U(2)). Following <cit.>, a direct approach was taken in <cit.>, <cit.> for the case of (SU(2) Ã—SU(2), diag), leading to a general set-up in the context of multiplicity free pairs <cit.>. In this context, certain properties of the orthogonal polynomials, such as orthogonality, recurrence relations, and differential equations, are understood in terms of the representation theory of the corresponding symmetric spaces. Recently, Casper and Yakimov developed a framework in <cit.> to solve the matrix Bochner problem. This involves the classification of all N Ã— N weight matrix W(x) whose associated MVOPs are eigenfunctions of a second-order differential operator.
	
	
	
	Given N âˆˆâ„• we consider a matrix valued function W: [a,b] â†’ M_N(â„‚) such that W(x) is positive definite for all xâˆˆ [a,b] and W has finite moments of all order. In such a case, we say that W is a weight function,  which induces matrix valued inner product
	
    âŸ¨ P,Q âŸ©=âˆ«_a^b P(x)W(x)Q(x)^*dx âˆˆ M_N(),

	such that for all P,Q,Râˆˆ M_N()[x], Tâˆˆ M_N(C) and a,bâˆˆâ„‚ 
	the following properties are satisfied
	
    âŸ¨ aP+bQ,RâŸ©=aâŸ¨ P,RâŸ©+bâŸ¨ Q,RâŸ©,     âŸ¨ TP,QâŸ©=TâŸ¨ P,QâŸ©, âŸ¨ P,QâŸ©^*=âŸ¨ Q,PâŸ©.

	Moreover âŸ¨ P,P âŸ© = 0 if and only if P=0. Using standard arguments, it can be shown that there exists a unique sequence (P(x,n))_n monic MVOPs with respect to W in the following sense:
	
    âŸ¨ P(x,n), P(x,m)âŸ© = â„‹(n) Î´_n,m.

	where the squared norm â„‹(n) is a positive definite matrix.
	
	
	By orthogonality, the polynomials P(x,n)'s satisfy the following three-term recurrence
	relation:
	
    xP(x,n) = P(x,n+1) + B(n) P(x,n) + C(n) P(x,n-1)

	where B(n), C(n) âˆˆ M_N(â„‚) and n â‰¥ 1.
	Notice that B(n) and C(n) satisfy 
	
    B(n)=X(n)-X(n+1),    C(n)= â„‹(n) â„‹(n-1)^-1,

	where  X(n) is the one-but-leading coefficient of P(x,n) and â„‹(n) as in (<ref>).
	Moreover, for n â‰¥ 2, let Y(n) denotes the second-but-leading coefficient of P(x,n). Then
	
    Y(n)=Y(n+1)+B(n)X(n)+C(n).

	
	In <cit.>, the authors studied differenceâ€“differential relations for a specific class of MVOPs associated with the weight W(x)=e^-v(x)e^xAe^xA^âˆ—, where x âˆˆâ„, v(x) is a scalar polynomial of even degree, and A is a constant matrix. There is a way of obtaining information about the matrix orthogonal polynomials by investigating two mutually adjoint operators ğ’Ÿ and ğ’Ÿ^â€ . If v(x) is a polynomial of degree two, in addition to ğ’Ÿ and ğ’Ÿ^â€ , there exists a second order differential operator D having the MVOPs as eigenfunctions. It turns out that ğ’Ÿ, ğ’Ÿ^â€  and D generate a finite dimensional Lie algebra which is isomorphic to the Lie algebra of the oscillator group. The Casimir operator for this algebra is given explicitly and used to obtain information of the MVOPs.
	In this work, we solve the analogous problem for Laguerre-type weights. This case is more involved than the previous one due to the structure of the associated Lie algebra and the non-diagonality of certain formulas that involve W.
	
	In the scalar case, this problem is closely related to <cit.>. Here Ismail proposed to study the finite dimensionality of certain Lie algebra generated by a pair of differential operators which are mutually adjoint respect to a Laguerre-type weight. More precisely, given the scalar weight w_1(x)=x^Î±e^-Ï•(x) with x>0,  Î±>1 and differential operators
	
    ğ’Ÿ_1,n=xâˆ‚_x +x B_n(x),     ğ’Ÿ_2,n=-xâˆ‚_x + x B_n(x)+xÏ•'(x),

	where {B_n} is a sequence of scalar polynomials, the problem asks to prove that â€œThe Lie algebra generated by ğ’Ÿ_1,n and ğ’Ÿ_2,n is finite dimensional if and 	only if Ï• is a polynomialâ€.
	
	In this paper we provide a partial answer to this problem in the context of matrix valued orthogonal polynomials. We give an explicit matrix valued weight W^(Î½)_Ï•(x) =x^Î½ e^-Ï•(x) W^(Î½)_pol(x), where W^(Î½)_pol(x) is a matrix polynomial depending on Î½, and differential operators 
	
    ğ’Ÿ = âˆ‚_x x + x(A-1),   ğ’Ÿ^â€  = -âˆ‚_x x - (1+Î½+J)+xÏ•'(x)-x.
 
	In this case, we prove that the Lie algebra generated by is finite dimensional if and only if Ï• is a polynomial.	As a consequence, this solves <cit.> when B_n(x)=-1 for all nâˆˆâ„•.
	
	

 Â§.Â§ Outline and main results

	
	In Section 2 we recall some preliminaries. In particular, we introduce the left and right Fourier algebras related to the sequence of monic MVOPs.
	
	In Section 3 for a given analytic function Ï• on a neighborhood of the interval [0,âˆ), we introduce a Laguerre type weight W^(Î½)_Ï• and the operators ğ’Ÿ , ğ’Ÿ^â€  and prove that they are mutually adjoint with respect to W^(Î½)_Ï•(x). For the MVOPs {P_n} respect to W^(Î½)_Ï•,
	we find discrete operators M,  M^â€  associated to ğ’Ÿ, ğ’Ÿ^â€  respectively, given by the relations M Â· P_n = P_n Â·ğ’Ÿ and M^â€ Â· P_n = P_n Â·ğ’Ÿ^â€ .
	
	In Section 4 we study the Lie algebra ğ”¤_Ï• generated by the differential operators ğ’Ÿ, ğ’Ÿ^â€ . We prove that ğ”¤_Ï• is finite dimensional if and only if Ï• is a polynomial. Also, for this family of Lie algebras {ğ”¤_Ï•} we obtain that ğ”¤_Ï•=â„‚^2âŠ•ğ”¥ and ğ”¥ is a solvable Lie algebra with nilradical of codimension one. Moreover, we obtain a classification of this family of Lie algebra up to isomorphisms.
	
	In Section 5 we give an explicitly expression for ğ’Ÿ, ğ’Ÿ^â€ , M and M^â€  in the case Ï•(x)=x.	In this case, we also find a symmetric second-order differential operator D which have {P_n} as eigenfunctions. We describe the Lie algebra ğ’œ generated by ğ’Ÿ, ğ’Ÿ^â€  and D, ğ’œ=ğ’µ_ğ’œâŠ• [ğ’œ,ğ’œ] where ğ’µ_ğ’œ=2 and [ğ’œ,ğ’œ] is isomorphic to SL(2,â„‚). Also, we obtain some relations between â„‹_n, B_n and C_n. 
	
	In Section 6, we consider the polynomials R(x,n)=K_n P(x,n)e^xA 
	where P(x,n) are the MVOPs associated with the weight W^(Î½) and
	K_n certain lower triangular matrices. Using the operator D,
	we show that the matrix entries of R_n can be put in terms of 
	generalized Laguerre polynomials  and a family of constants Î¾(n,i,j)'s. 
	Finally, we give two-terms recursions for the constants Î¾(n,i,j)'s 
	and for the squared norm â„‹_n.
	
	Finally, in Section 7, in the case A=- âˆ‘_k=1^N-1 E_k+1,k, and Î´^k>0 
	satisfying two non-linear conditions (related to Pearson's equations),  we show that the constants Î¾(n,i,j)'s are written in terms of dual Hanh polynomials.
	
	

Â§ PRELIMINARIES

	
	
	
	This section presents the left and right Fourier algebras associated with the sequence of monic MVOPs, as developed by Casper and Yakimov in <cit.>. The results discussed in this section have been previously covered in a more comprehensive context in <cit.>.
	
	Let Q(x,n) be a function Q:â„‚Ã—â„•_0 â†’ M_N(â„‚) such that Q(x,n) is a rational function of x for fixed n. A differential operator of the form
	
    =âˆ‘_j=0^n âˆ‚_x^j F_j(x),     âˆ‚_x^j := d^jdx^j,

	where F_j:â„‚â†’ M_N(â„‚) is a rational function of x, acts on Q from the right by
	
    (QÂ·)(x,n)  = âˆ‘_j=0^n (âˆ‚_x^jQ)(x,n)   F_j(x).

	
	The algebra of all differential operators of the form (<ref>) will be denoted by â„³_N.  In addition to the right action by differential operators, we also consider a left action on Q by difference operators on the variable n. For jâˆˆâ„¤, let Î´^j be the discrete operator which acts on a sequence A:â„•_0 â†’ M_N(â„‚) by
	
    (Î´^j Â· A)(n)=A(n+j).

	Here we assume that the value of a sequence at a negative integer is equal to zero. For given sequences A_-â„“,â€¦,A_k, a discrete operator of the form
	
    M=âˆ‘_j=-â„“^k A_j(n) Î´^j,

	acts on Q from the left by
	
    (M Â· Q)(x,n)    = âˆ‘_j=-â„“^k A_j(n)   (Î´^jÂ· Q)(x,n) = âˆ‘_j=-â„“^k A_j(n)   Q(x,n+j).

	
	We shall denote the algebra of difference operators (<ref>) by ğ’©_N. As in <cit.> we define:
	
		The left and right Fourier algebras are given by:
		
    â„±_L(P)   ={ Mâˆˆğ’©_N âˆƒ âˆˆâ„³_N,  MÂ· P = PÂ·}âŠ‚ğ’©_N,
    â„±_R(P)   ={âˆˆâ„³_N âˆƒ  Mâˆˆğ’©_N,  MÂ· P = PÂ·}âŠ‚â„³_N.

	
	
	The definition of the Fourier algebras directly implies a connection between the elements of â„±_L(P) and â„±_R(P). Moreover, the map
	
    Ï†â„±_L(P) â†’â„±_R(P),     defined by    MÂ· P = P Â·Ï†(M),

	is an algebra isomorphism. In <cit.> this map is called the generalized Fourier map. More precisely, M_1M_2Â· P = P Â·Ï†(M_1)Ï†(M_2) for all M_1,M_2âˆˆâ„±_L(P). On the other hand, by the definition of Ï†, we have that M_1M_2Â· P = PÂ·Ï†(M_1M_2).
	
	
		
		In this context, the three term recurrence relation (<ref>) can be written as
		
    xP = PÂ· x = LÂ· P,     where    L=Î´ + B(n) + C(n)Î´^-1.

		Therefore xâˆˆâ„±_R, Lâˆˆâ„±_L and Ï†(L)=x. For every polynomial v âˆˆâ„‚[x], we have
		
    PÂ· v(x) =PÂ· v(Ï†(L))= v(L)Â· P.

	
	
	On of the crucial results from <cit.> is the existence of an adjoint operation â€  in the Fourier algebras â„±_L(P) and â„±_R(P) as described in <cit.>. To define the adjoint operation in â„±_L(P), we initially observe that the algebra of difference operators ğ’©_N has a âˆ—-operation defined as follows:
	
    ( âˆ‘_j=-â„“^k A_j(n)  Î´^j )^âˆ— = âˆ‘_j=-â„“^k A_j(n-j)^âˆ— Î´^-j,

	where A_j(n-j)^âˆ— is the conjugate transpose of A_j(n-j). Now, the adjoint of Mâˆˆğ’©_N is given by 
	
    M^â€  = â„‹(n) M^âˆ—â„‹(n)^-1,

	where â„‹(n) is the squared norm which we view as an difference operator of order zero. The following holds:
	
    âŸ¨ (MÂ· P)(x,n),P(x,m)âŸ© = âŸ¨ P(x,n),(M^â€ Â· P)(x,m)âŸ©.

	
	In <cit.> the authors show that every differential operator Dâˆˆâ„±_R(P) has a unique adjoint ^â€ âˆˆâ„±_R(P) with the property
	
    âŸ¨ PÂ·, Q âŸ© = âŸ¨ P,QÂ·^â€ âŸ©,

	for all P,Qâˆˆ M_N(â„‚)[x]. Moreover, Ï†(M^â€ ) = Ï†(M)^â€  for all Mâˆˆâ„±_L(P).
	
	
	

Â§ SEMI-CLASSICAL LAGUERRE TYPE SOLUTIONS

	
	
	In the sequel, we consider the following two matrices A,Jâˆˆ M_N(â„) which satisfy
	
    J=âˆ‘_k=1^N k E_k,k     A =âˆ‘_k=1^N-1 a_k E_k+1,k.

	Notice that, it is straightforward to show that
	
    [J,A]=A   and   e^xAJ e^-xA=J-Ax.

	Let us consider the following weight matrix supported on the interval [0,âˆ):
	
    W^(Î½)_Ï•(x) = e^Ax T^(Î½)_Ï•(x) e^A^âˆ— x,     T^(Î½)_Ï•(x) =  e^-Ï•(x)âˆ‘_k=1^N Î´^(Î½)_k x^Î½+k  E_k,k,

	where Î´^(Î½)_k is a constant real number for 1 â‰¤ k â‰¤ N, and Ï• be an analytic function on a neighborhood of the interval [0,âˆ).
	In the sequel, we assume that W(x)P(x) = 0 has vanishing limits at the endpoints of support for any matrix polynomial P.
	
	
	
		Let A,Jâˆˆ M_N(â„‚) as in (<ref>). 
		Then, the first order differential operators
		
    ğ’Ÿ = âˆ‚_x x + x(A-1),   ğ’Ÿ^â€  = -âˆ‚_x x - (1+Î½+J)+xÏ•'(x)-x,

		are mutually adjoint.
	
	
		Let P,Q âˆˆ M_N(â„‚[x]). 
		In order to simplify notation, in the rest of the proof, we denote by W(x):=W^(Î½)_Ï•(x) and T(x)=W^(Î½)_Ï•(x)
		
    âŸ¨ P Â·ğ’Ÿ, Q âŸ©   =   âˆ«_0^âˆ (PÂ·ğ’Ÿ) W(x) Q^âˆ—(x) dx
       =   âˆ«_0^âˆ( xP'(x)+xP(x)(A-1) ) W(x) Q^âˆ—(x) dx.
    
		Notice that, since W(x)P(x) has vanishing limits at the endpoints x=0, and x=âˆ, integration by parts implies that
		
    âˆ«_0^âˆ xP'(x)W(x)Q^âˆ—(x)dx = -âˆ«_0^âˆ P(x) (xW(x)Q^âˆ—(x) )'  dx.

		On the other hand, we have that
		
    âˆ«_0^âˆ xP(x)(A-1)W(x) Q^âˆ—(x) dx=âˆ«_0^âˆ P(x)W(x) ( W^-1(x) x (A-1)W(x) )Q^âˆ— (x)  dx,

		by linearity we obtain that
		
    âŸ¨ P Â·ğ’Ÿ, Q âŸ©   =    - âˆ«_0^âˆ P(x) (xW(x)Q^âˆ—(x) )'  dx + âˆ«_0^âˆ P(x)W(x) ( W^-1(x) x (A-1)W(x) )Q^âˆ— (x) dx
       =    -âˆ«_0^âˆ P(x)(W(x)Q^âˆ—(x) +x W'(x) Q^âˆ—+xW(x)(Q^âˆ—(x))') dx
          + âˆ«_0^âˆ P(x)W(x) ( W^-1(x) x (A-1)W(x) )Q^âˆ— (x) dx.

		Notice that since  (Q Â· (1+xâˆ‚_x) )^âˆ—(x)=Q^âˆ—(x)+x(Q^âˆ—(x))', 
		we can put
		
    âˆ«_0^âˆ P(x)(W(x)Q^âˆ—(x) +W(x)x(Q^âˆ—(x))') dx=âˆ«_0^âˆ P(x)W(x)(Q Â· (1+xâˆ‚_x) )^âˆ—(x)  dx.

		On the other hand,
		
    âˆ«_0^âˆ P(x) x W'(x) Q^âˆ—(x) dx=âˆ«_0^âˆ P(x) W(x) xW^-1(x) W'(x) Q^âˆ—(x) dx.

		Hence, we obtain that
		
    âŸ¨ P Â·ğ’Ÿ, Q âŸ©   =    - âˆ«_0^âˆ P(x)W(x)(Q Â· (1+xâˆ‚_x) )^âˆ—(x)  dx - âˆ«_0^âˆ P(x) W(x) xW^-1(x) W'(x) Q^âˆ—(x) dx
          + âˆ«_0^âˆ P(x)W(x) ( W^-1(x) x (A-1)W(x) )Q^âˆ— (x) dx.

		By (<ref>) we have that
		
    W^-1(x) W'(x)    =e^-A^âˆ— x(T^-1(x) A  T(x)+T ^-1(x)T'(x)+ A^âˆ—) e^A^âˆ— x,
    
    			W^-1(x) x (A-1)W(x)    = e^-A^âˆ—x(x T^-1(x)  A  T(x)  - x)e^A^âˆ—x.

		Thus, we obtain 
		
    âŸ¨ P Â·ğ’Ÿ, Q âŸ©   =    - âˆ«_0^âˆ P(x)W(x)(Q Â· (1+xâˆ‚_x) )^âˆ—(x)  dx
          - âˆ«_0^âˆ P(x) W(x)  e^-A^âˆ— x(xT^-1(x)  A   T(x)+x T^-1(x)T'(x)+ x A^âˆ—) e^A^âˆ— x Q^âˆ—(x) dx
          + âˆ«_0^âˆ P(x)W(x) e^-A^âˆ—x(x T^-1(x)  A  T(x)  - x)e^A^âˆ—x Q^âˆ—(x)dx
       =    - âˆ«_0^âˆ P(x)W(x)(Q Â· (1+xâˆ‚_x) )^âˆ—(x)  dx
          - âˆ«_0^âˆ P(x) W(x)  e^-A^âˆ— x(x T^-1(x)T'(x)+ x A^âˆ—+x) e^A^âˆ— x Q^âˆ—(x) dx.

		By taking into account that xT'(x)=T(x) (-xÏ•'(x)+Î½+J), we obtain that
		
    âŸ¨  P Â·ğ’Ÿ, Q âŸ©   =    - âˆ«_0^âˆ P(x)W(x)(Q Â· (1+xâˆ‚_x) )^âˆ—(x)  dx
       -   âˆ«_0^âˆ P(x) W(x)  e^-A^âˆ— x ( -xÏ•'(x)+Î½+J+xA^âˆ—+x) e^A^âˆ—x Q^âˆ—(x) dx.

		Notice that  the second expresion of the right hand of the above equality is
		
    e^-A^âˆ— x ( -xÏ•'(x)+Î½+J+xA^âˆ—+x) e^A^âˆ—x = -xÏ•'(x)+ Î½+ e^-A^âˆ— x J e^A^âˆ—x+xA^âˆ—+x.

		On the other hand, the equation e^xAJ e^-xA=J-Ax
		implies that e^-A^âˆ— x J e^A^âˆ—x=J-A^âˆ—x. Hence, we obtain that
		
		
    âŸ¨ P Â·ğ’Ÿ, Q âŸ©   =    - âˆ«_0^âˆ P(x)W(x)(Q Â· (1+xâˆ‚_x) )^âˆ—(x)  dx
          - âˆ«_0^âˆ P(x) W(x)   (x -xÏ•'(x)+(Î½+J-A^âˆ—x+xA^âˆ—) Q^âˆ—(x) dx
       =   âˆ«_0^âˆ P(x)W(x)(Q Â· -(xâˆ‚_x+x-xÏ•'(x)+(Î½+J+1) )^âˆ—(x)  dx
       =   âŸ¨ P,QÂ·ğ’Ÿ^â€ âŸ©.

		Therefore, the operators ğ’Ÿ and ğ’Ÿ^â€  are mutually adjoint, as asserted.
	
	
	By the above theorem, since ğ’Ÿ = âˆ‚_x x + x(A-1) and
	ğ’Ÿ^â€  = -âˆ‚_x x - (1+Î½+J)+xÏ•'(x)-x, then we obtain that
	
    ğ’Ÿ^â€  = -ğ’Ÿ + (Ax-J) -(1+Î½) + xÏ•'(x)-2x.

	
	
		Let A,Jâˆˆ M_N(â„‚) be matrices as in (<ref>). 
		Then, ğ’=Ax-J  is a symmetric operator respect to the weight W:=W^(Î½)_Ï• as in (<ref>). 
		Moreover, if P(x,n)'s are monic MVOPs associated with the weight W, such that
		
    PÂ·ğ’=M_ğ’Â· P,   then   M_ğ’=âˆ‘_i=-1^1 U_j(n)Î´^j,

		with 
    U_1(n):=A,     U_0(n):=X(n)A-AX(n+1)-J,
 
    U_-1(n):= Y(n)A-AY(n+1) + [J,X(n)] + (AX(n+1)-X(n)A)X(n),
 
		where X(n) and Y(n) are the coefficients of the (n-1)-term and (n-2)-term of P(x,n) respectively.
	
	
		In the same manner as Proposition <ref>, it can be shown that ğ’ is an symmetric operator respect with W.
		
		If we put M_ğ’=âˆ‘ U_j(n)Î´^j such that PÂ·ğ’=M_ğ’Â· P.
		By taking into account that ğ’  increases the degree of any polynomial in 1, we obtain that U_j(n)=0 for j>1. On the other hand, since ğ’ is an symmetric operator respect to W, we have that M_ğ’=M^â€ _ğ’ and so U_j(n)=0 for j<-1.
		
		The formulas for U_-1(n),U_0(n) and U_1(n) can be obtained by direct computation from PÂ·ğ’=M_ğ’Â· P.
	
	
	
		Since ğ’=Ax-J=(Ax-J)^â€ , then M_ğ’=M_ğ’^â€ .
		Thus, from equations (<ref>) we have that 
		
    U_1(n)    =â„‹(n) U_-1(n+1)^âˆ—â„‹(n+1)^-1,
     
    			U_0(n)    =â„‹(n)U_0(n)^âˆ—â„‹(n)^-1,

		and so we obtain that
		
    A=â„‹(n)(Y(n+1)A-AY(n+2)+[J,X(n+1)]+(AX(n+2)-X(n+1)A)X(n+1))^âˆ—â„‹(n+1)^-1,

		
    X(n)A-AX(n+1)-J=â„‹(n) (X(n)A-AX(n+1)-J)^âˆ—â„‹(n)^-1.
 
	
	
	
		Let W:=W^(Î½)_Ï• be a matrix weight as in (<ref>), 
		with monic MVOPs P(x,n) such that
		
    ğ’Ÿ= âˆ‚_x x + (A-1)x,     ğ’Ÿ^â€ = -ğ’Ÿ + ğ’ + v'(x)

		for some polynomial v(x) of degree k and ğ’=Ax-J. 
		If X(n) and Y(n) are the coefficients of the (n-1)-term and (n-2)-term of P(x,n) respectively. 
		Then, the monic polynomials P(x,n) satisfy the following relation
		
    PÂ·ğ’Ÿ=MÂ· P,      M= âˆ‘_j=-k+1^1 A_j(n)Î´^j

		with 
		
    A_1(n)=A-1,   A_0(n)=n+X(n)A - A X(n+1)-B(n),
 
			
    A_-1(n)=(n-1)X(n)+Y(n)(A-1)-(A-1)Y(n+1)-A_0(n)X(n),

			
    A_j(n)=(v'(L))_j(n),    -k+1 <j< -1

		where B(n) is given by (<ref>).
	
	
		Clearly, the formulas for A_j(n) with j=-1,0,1 can be derived from the equalities in (<ref>) by using the definition of ğ’Ÿ.
		
		For j<-1, we have that
		
    A_j(n)    =   âŸ¨ PÂ·ğ’Ÿ,Î´^j Â· P âŸ©â„‹(n-j)^-1=âŸ¨ P, Î´^j Â· P Â·ğ’Ÿ^â€ âŸ©â„‹(n-j)^-1
        =   âŸ¨ P, Î´^j Â· P Â· v'(x)âŸ©â„‹(n-j)^-1=âŸ¨ PÂ· v'(x), Î´^j Â· PâŸ©â„‹(n-j)^-1
       =    âŸ¨ v'(L)Â· P, Î´^jÂ· P âŸ©â„‹(n-j)^-1,

		where we have used that âŸ¨ P, Î´^j Â· PÂ·ğ’ŸâŸ© and âŸ¨ P, Î´^j Â· PÂ·ğ’âŸ© are both zero for j<-1 in the third equality, and the fact that v'(x) is a scalar funtion in the fourth one. Then, we have that 
		
    A_j(n)= (v'(L))_j(n)   for j<-1.

		To complete the proof, notice that (v'(L))_j(n)=0 for jâ‰¤ -k.
	
	
	As a direct consequence, we obtain the following corollary.
	
		In the same hypothesis as in Theorem <ref>.
		If the polynomial v has degree 1, then the discrete operator M associated  with ğ’Ÿ satisfies
		
    M=  A_0(n)+(A-1)Î´

		with A_0(n) as in Theorem <ref>. Moreover, in this case we have that
		
    (n-1)X(n)+Y(n)(A-1)-(A-1)Y(n+1)-( n+X(n)A - A X(n+1)-B(n))X(n) = 0.

	
	
		By Theorem <ref>, 
		since (v) < 2 we obtain that A_j(n)=0 for all j<-1.
		On the other hand, notice that since v has degree 1, 
		then v'(x) is a constant function and so the operator
		ğ’Ÿ^â€  does not increase degrees. 
		This implies that A_1^â€ =0 and therefore 
		
    A_-1(n)=(n-1)X(n)+Y(n)(A-1)-(A-1)Y(n+1)-A_0(n)X(n) = 0,
 
		the formula for A_1(n) and A_0(n) are consequence of Theorem <ref>.
	
	

Â§ LIE ALGEBRAS ASSOCIATED TO ORTHOGONAL POLYNOMIALS

	
	In this section, we solve a particular case of the problem proposed by Ismail in <cit.>, as described in the introduction. For this purpose, we study the structure of a Lie algebra related with the operators ğ’Ÿ and ğ’Ÿ^â€ . 
	
	Recall that if ğ”¤ is a finite dimensional Lie algebra, and if ğ”¤^j and ğ”¤_j denote the following recursions
	
    ğ”¤^0=ğ”¤_0=ğ”¤,   ğ”¤^j+1=[ğ”¤^j,ğ”¤^j]   and   ğ”¤_j+1=[ğ”¤,ğ”¤_j],

	then ğ”¤ is called solvable (nilpotent) if ğ”¤^j=0 for some j (if ğ”¤_j=0 for some j).
	Clearly, any nilpotent Lie algebra is solvable.
	The radical (nilradical) of ğ”¤ is its maximal solvable ideal (maximal nilpotent ideal) of ğ”¤.
	We will denote by Rad(ğ”¤) and Nil(ğ”¤) to the radical and nilradical of ğ”¤, respectively.
	
	
	

 Â§.Â§ Lie algebra generated by ğ’Ÿ and ğ’Ÿ^â€ 

	
	
	
		Let A,Jâˆˆ M_N(â„‚) as in (<ref>) and let Ï• an entire function over â„‚, let us consider the operators
		
    ğ’Ÿ = âˆ‚_x x + x(A-1),   ğ’Ÿ^â€  = -âˆ‚_x x - (1+Î½+J)+xÏ•'(x)-x.

		If x and x^jÏ•^(j)(x)  act over matrix valued polynomials by right constant multiplication, then we have that 
		
    [ğ’Ÿ,x] = -x,     [ğ’Ÿ^â€ ,x]=x,     [ğ’Ÿ,ğ’Ÿ^â€ ] = -x^2Ï•^(2)(x)+(2-Ï•'(x))x,

		
    [ğ’Ÿ,Ï•^(j)(x)x^j] =  -(jx^jÏ•^(j)(x)+x^j+1Ï•^(j+1)(x)) = -[ğ’Ÿ^â€ ,Ï•^(j)(x)x]   for all jâ‰¥ 1.
	
	
	
	In the sequel, given Ï• an entire function over â„‚, we denote by
	
    ğ”¤_Ï•= âŸ¨ 1,ğ’Ÿ, ğ’Ÿ^â€ , x, xÏ•'(x), x^2Ï•^(2)(x),â€¦âŸ©

	with bracket as above. We are interested in the case that this Lie algebra is finite dimensional. The following proposition states that this happens if and only if Ï• is a polynomial. We will need the following notation, given Ï• a polynomial over â„‚ with â„“ non-zero coefficients
	
    k=â„“+2    if Ï•'(0)=Ï•(0)=0,
    â„“+1    if Ï•'(0)=0, Ï•(0)â‰  0,
    â„“+1    if Ï•(0)=0, Ï•'(0)â‰  0,
    â„“   if Ï•(0)â‰  0, Ï•'(0)â‰  0,
	
	
	
		Let Ï• an analitic function over â„‚ and let ğ”¤:=ğ”¤_Ï• its associated Lie algebra as in (<ref>). 
		Then, we have that
		(ğ”¤) is finite if and only if Ï• is a polynomial. 
		In such case, if k is as in (<ref>) then
		
    (ğ”¤)= k+2.

	
	
		Clearly, if Ï• is a polynomial, then the dimension of ğ”¤ is finite, since if n is the degree of Ï• then Ï•^(m)(x)=0 for all m>n. 
		
		Conversely, assume now that Ï• is not a polynomial. 
		Since Ï• is analytic, we can express Ï• as follow
		
    Ï•(x)= âˆ‘_i=0^âˆ a_ix^i.

		This implies that 
		
    x^jÏ•^(j)(x)= âˆ‘_i=0^âˆ b_i,j x^i,   with   b_i,j=
    			ijj!  a_i     if jâ‰¤ i, 
       
    				0     if i<j.

		In particular, if a_i=0 then b_i,j=0 for all j âˆˆâ„•.
		
		Let {i_t}_tâˆˆâ„• be the sequence 
		of non-zero coefficients indices of Ï•, that is  i_t<i_t+1 for all t âˆˆâ„•, such that a_i â‰  0 if and only if i= i_t for some t âˆˆâ„•. 
		
		
		Claim: The vector space âŸ¨ x^i_1Ï•^(i_1)(x),â€¦, x^i_â„“Ï•^(i_â„“)(x)âŸ© has dimension â„“.
		
		Let c_1,â€¦,c_â„“âˆˆâ„‚ such that 
		
    c_1x^i_1Ï•^(i_1)(x)+â‹¯+ c_â„“x^i_â„“Ï•^(i_â„“)(x)=0,

		this induces the following system of equations
		
    âˆ‘_t=1^h c_ti_hi_t i_h! a_i_t=0   for h=1,â€¦,â„“.

		By taking into account that a_i_1â‰  0, 
		the equation for h=1 implies that c_1=0. 
		In the same way, since c_1=0, the equation for h=2 implies that
		c_2 a_i_2 i_2!=0 and so c_2=0 since a_i_2â‰  0. Inductively,
		if c_1=c_2=â€¦=c_â„“-1=0, then the equation for h=â„“ implies that
		c_â„“ a_i_â„“ i_â„“!=0 and so c_â„“=0 since a_i_â„“â‰  0, 
		hence we obtain that c_h=0 for all hâˆˆ{1,â€¦,â„“}.
		
		By the claim, the space ğ”¤ has subspaces of all of the possible dimensions and so is non-finite dimensional, as asserted.
		
		Now, assume that Ï• is a polynomial of degree n, in the same notation as above,
		by (<ref>) we have that 
		
    âŸ¨ xÏ•'(x),x^2Ï•^(2)(x),â€¦, x^nÏ•^(n)(x)âŸ©âŠ†âŸ¨ x^i_1,â€¦,x^i_â„“âŸ©.

		The claim and the above statement imply that âŸ¨ xÏ•'(x),x^2Ï•^(2)(x),â€¦, x^nÏ•^(n)(x)âŸ© has dimension â„“. 
		
		Finally, the last assertion follows from the fact that
		ğ’Ÿ,ğ’Ÿ^â€  are linearly independent respect to
		
    âŸ¨ 1,x,xÏ•'(x),x^2Ï•^(2)(x),â€¦, x^nÏ•^(n)(x)âŸ©
 
		and this vector space has dimension k, with k as in the statement.
	
	
	
		The above proposition solves the problem proposed by Ismail in <cit.> for the case B_n=-1 for all n natural number. In the notation of <cit.>, the differential operators ğ’Ÿ and ğ’Ÿ^â€  correspond to ğ’Ÿ=x L_1,n and ğ’Ÿ^â€ =x L_2,n +(1+Î½). Then, the algebra generated by {ğ’Ÿ, ğ’Ÿ^â€ ,1} is isomorphic to the algebra generated by {xL_1,n, xL_2,n,1}.
	
	
	
	
		By the proof of the above theorem,
		if Ï•(x)=a_0+a_1 x +â€¦+ a_nx^n is a polynomial of degree n with â„“ non-zero coefficients.
		If {i_1,â€¦,i_â„“}âŠ†{0,â€¦,n} is the set of indices such that a_i_jâ‰  0.
		then we have that
		
    âŸ¨ xÏ•'(x),x^2Ï•^(2)(x),â€¦, x^nÏ•^(n)(x)âŸ©=âŸ¨ x^i_1,â€¦,x^i_â„“âŸ©.

	
	
	
	
		Let Ï•_1(x)=x^3 and Ï•_2(x)=x^3+x^2, by the above theorem the associated Lie algebras
		ğ”¤_Ï•_1 and ğ”¤_Ï•_2 have the dimensions 5 and 6, respectively. Then, the algebras
		ğ”¤_Ï•_1 and ğ”¤_Ï•_2 are non-isomorphic. 
	
	
	
	
		The element z= ğ’Ÿ+ğ’Ÿ^â€  +2x -xÏ•'(x) is a symmetric differential operator which
		belongs to the center of the Lie algebra ğ”¤.
	
	
		It is follows immediately from the definition of the bracket of ğ”¤_Ï•.
	
	
	
		The central element that we found in the above lemma, it is related with the symmetric operator ğ’ that was considered in Lemma <ref>,
		we will see this in the following section.
	
	
	In the sequel, given a polynomial Ï•(x)=a_0+a_1 x+ â‹¯ +a_n x^n  of degree nâ‰¥ 2 
	with â„“ non-zero coefficients and k as in (<ref>), let us consider the following notations. 
	
    I_Ï•={i âˆˆ{2,â€¦,n}: a_iâ‰  0}={ j_1,â€¦,j_k-2}=
    		{i_3,â€¦,i_â„“}   if a_0â‰  0, a_1â‰  0,
    {i_2,â€¦,i_â„“}   if a_0=0 and a_1â‰  0,
    {i_2,â€¦,i_â„“}   if a_0â‰  0 and a_1= 0,
    {i_1,â€¦,i_â„“}   if a_0=0 and a_1=0,

	with j_t< j_t+1 and i_t<i_t+1.
	
	
		Let Ï•(x)=a_0+a_1 x+ â‹¯ +a_n x^n be a polynomial of degree nâ‰¥ 2 
		with â„“ non-zero coefficients and k as in (<ref>). 
		If ğ”¤:=ğ”¤_Ï• is the associated Lie algebra of Ï• as in (<ref>),
		then we have that
		
    ğ”¤â‰…â„‚^2 âŠ•ğ”¥

		where ğ”¥  is a solvable Lie algebra of dimension k, with an abelian nilradical of dimension k-1. More precisely,
		if I_Ï• is as in (<ref>)	then
		
    ğ”¥â‰…âŸ¨ E âŸ©â‹‰âŸ¨ E_1, â€¦ E_k-1âŸ©

		where âŸ¨ E_1, â€¦ E_k-1âŸ© is abelian and the rest of the brackets satisfy
		
    [E,E_1]=E_1   and   [E,E_t]= j_t-1 E_t   for t=2,â€¦,k-1.

	
	
		By Lemma <ref>, the element 
		z= ğ’Ÿ+ğ’Ÿ^â€  +2x -xÏ•'(x) belongs to the center of ğ”¤, 
		and so we obtain an element in the center which does not belong to âŸ¨ 1âŸ©, 
		thus if 
		
    ğ”¥=âŸ¨ğ’Ÿ, x,xÏ•'(x),x^2Ï•^(2)(x),â€¦, x^nÏ•^(n)(x) âŸ©

		then we obtain that
		
    ğ”¤â‰…â„‚^2 âŠ•ğ”¥,

		with ğ”¥  a Lie algebra of dimension k.
		
		Thus, it is enough to show that ğ”¥ is solvable with nilradical of dimension k-1. 
		Let us consider
		
    ğ”¨=âŸ¨ x,xÏ•'(x),x^2Ï•^(2)(x),â€¦, x^nÏ•^(n)(x)âŸ©,

		by definition of the bracket and by taking into account that 
		
    [x,x^lÏ•^(l)(x)]=[x^i Ï•^(i)(x),x^j Ï•^(j)(x)]=0    for all iâ‰  j,

		we obtain that [ğ”¥,ğ”¥]âŠ†ğ”¨.
		Hence, by (<ref>) we obtain that [[ğ”¥,ğ”¥],[ğ”¥,ğ”¥]]=0,
		and so ğ”¥ is solvable.
		Finally, notice that
		ğ”¨ is an abelian ideal of ğ”¥ of dimension 
		
    (ğ”¨)= (ğ”¥)-1=k-1,

		this implies that ğ”¨ is the nilradical of ğ”¥, as desired.
		
		In the same manner as in Remark <ref> we have that
		
    ğ”¥=âŸ¨ğ’Ÿ, x, x^j_1,â€¦, x^j_k-2âŸ©,
 
		in this case âŸ¨ x, x^j_1,â€¦, x^j_k-2âŸ© is an abelian subalgebra of dimension k-1. 
		It is enough to see the brackets [ğ’Ÿ,x^j_t] and [ğ’Ÿ,x], in this case we obtain that
		
    [ğ’Ÿ,x]=-x     and     [ğ’Ÿ,x^j_t]= -j_t x^j_t,

		so we obtain that âŸ¨ x, x^j_1,â€¦, x^j_k-2âŸ© is an abelian ideal. Finally, 
		if we consider the following correspondence
		
    ğ’ŸâŸ¼ -E,    xâŸ¼ E_1,    x^j_iâŸ¼ E_i+1  for i=1,â€¦,k-2,

		is an Lie Algebra isomorphism between ğ”¥ and âŸ¨ E âŸ©â‹‰âŸ¨ E_1, â€¦ E_k-1âŸ© with brackets given as in (<ref>), as asserted.
	
	
	
	In the sequel we are going to study the structure of the solvable Lie algebra ğ”¥_Ï•.
	In general, a Lie algebra ğ”¥' with an abelian ideal of codimension 1 is called almost abelian.
	This kind of algebra was studied by V.V. Gorbatsevich in <cit.>. 
	The author asserted that in general this kind of algebra it decomposes as
	
    â„‚â‹‰_Ïˆâ„‚^k-1,

	this semidirect product gives a linear transformation Ïˆ: â„‚â†’ gl_k-1(â„‚),
	moreover he asserted that the structure of this kind of algebras it determines by the matrix Î¨=Ïˆ(1). More precisely,
	
    â„‚â‹‰_Ïˆâ„‚^k-1â‰…â„‚â‹‰_Ïˆ'â„‚^k-1âŸº  Î¨ and Î¨' are conformally similar,

	recall that Î¨ and Î¨' are conformally similar if and only if there exist a matrix Pâˆˆ Gl_k-1(â„‚) and a non-zero complex number Î»âˆˆâ„‚âˆ–{0} such that Î¨= Î» P Î¨' P^-1.
	
	
		Let k be an integer greater than 1 and let 1<j_1<â€¦<j_k-2 and 1<j'_1<â€¦< j'_k-2 be two sequences of positive integers.
		Let us consider 
		
    Î¨ = diag(1, j_1,â€¦,j_k-2)   and  Î¨' = diag(1, j'_1,â€¦,j'_k-2).
 
		Then, Î¨ and Î¨' are conformally similar if and only if Î¨=Î¨'.
		
	
		Clearly, if Î¨=Î¨' then they are conformally similar trivially.
		
		Now, assume that Î¨ and Î¨' are conformally similar, so there exist Î»âˆˆâ„‚^* and Pâˆˆ GL_k-1(â„‚) such that
		
    Î¨' = Î» P Î¨ P^-1,
 
		by similarity we obtain the following spectral relationship
		
    Spec(Î¨')= Î»Â·Spec(Î¨),

		i.e. all of the eigenvalues of Î¨' can be obtained from the eigenvalues of Î¨ by multiplication by Î».
		Since Î¨ and Î¨' are both diagonal, we have that 
		
    Spec(Î¨)={1,j_1,â€¦,j_k-2}   and  Spec(Î¨')={1, j'_1,â€¦,j'_k-2},
 
		since 1 belong to both spectra and the rest of the eigenvalues of Î¨ and Î¨' are greater than 1, we obtain that Î»=1 necessarily. 
		Hence, we obtain that
		
    Spec(Î¨')= Spec(Î¨).

		Therefore, Î¨=Î¨' as asserted.
	
	
	We are in position to give the following theorem, which says when the Lie algebra associated to two different polynomials (as in (<ref>)) are isomorphic.
	
		Let Ï•_1(x),Ï•_2(x) be polynomials over â„‚ of degree greater or equal than 2.
		Let ğ”¥_Ï•_1 and ğ”¥_Ï•_2 be its associated solvable Lie algebras given as in Theorem <ref>.
		Then, 
		
    ğ”¥_Ï•_1â‰…ğ”¥_Ï•_2âŸº I_Ï•_1 = I_Ï•_2,

		where I_Ï•_1, I_Ï•_2 are as in (<ref>).
		Moreover, we have that
		
    ğ”¤_Ï•_1â‰…ğ”¤_Ï•_2âŸº I_Ï•_1 = I_Ï•_2,

		where ğ”¤_Ï•_1 and ğ”¤_Ï•_2 are the associated Lie algebras of Ï•_1 and Ï•_2, respectively.
	
	
		From Theorem <ref>, we have that ğ”¤_Ï•_1â‰…ğ”¤_Ï•_2 if and only if ğ”¥_Ï•_1â‰…ğ”¥_Ï•_2.
		So, it is enough to see that
		
    ğ”¥_Ï•_1â‰…ğ”¥_Ï•_2âŸº I_Ï•_1 = I_Ï•_2.

		Now by (<ref>), it enough to see that the associated matrices Î¦_1 and Î¦_2 are conformally similar. 
		By Theorem <ref> and (<ref>) we have that Î¦_1 and Î¦_2 are conformally similar to 
		
    Î¨ = diag(1, j_1,â€¦,j_k-2)   and  Î¨' = diag(1, j'_1,â€¦,j'_k-2)   respectively,

		where  {j_1,â€¦,j_k-2} =I_Ï•_1 and {j'_1,â€¦,j'_k-2}=I_Ï•_2.
		Finally, by Lemma <ref>, we obtain that Î¨ and Î¨' are conformally similar if and only if 
		Î¨=Î¨' which is equivalent to say that I_Ï•_1=I_Ï•_2. 
		Therefore ğ”¥_Ï•_1â‰…ğ”¥_Ï•_2 if and only if I_Ï•_1= I_Ï•_2 as asserted.	
	
	
	As a direct consequence, we obtain the following.
	
		Let Ï•_1(x),Ï•_2(x) be polynomials over â„‚ with degree greater than 2. 
		Then, we have the following cases:
		
			
  * If Ï•_1=Ï•_2=2, then ğ”¤_Ï•_1â‰…ğ”¤_Ï•_2.
			
  * If Ï•_1â‰ Ï•_2, then ğ”¤_Ï•_1â‰‡ğ”¤_Ï•_2.
			
	
	
	
		Notice that if we consider Ï•_m(x)=x^m+ax with mâ‰¥ 2, then (ğ”¥_Ï•_m)=3. 
		The structure of solvable Lie algebras of dimension 3 
		was studied by J.Â Patera and H.Â Zassenhaus in <cit.>. 
		In page 4, the authors 
		define the Lie algebra 
		L_3,6=âŸ¨ a_1,a_2,a_3âŸ© with brackets
		
    [a_1,a_2]= a_3     [a_1,a_3]= a_3-Î±Â· a_2

		with parameter Î± satisfying Î±â‰  0 and 1-4Î±â‰  0,
		this parameter Î± is in one-to-one correspondence with isomorphism classes of this kind of algebras.
		Its associated matrix Ïˆ_Î±(1) is 	
		
    Ïˆ_Î±(1)=
    			[  0 -Î±;  1  1 ]

		The eigenvalues of Ïˆ_Î±(1) are 
		
    Î»_0=1-âˆš(1-4Î±)2  and  Î»_1=1+âˆš(1-4Î±)2.

		On the other hand, if we consider Ï•_m(x)=x^m+ax with mâ‰¥ 2, 
		then ğ”¥_Ï•_m has dimension 3 and
		its associated matrix Î¨_m is conformally similar to 
		
    [ 1 0; 0 m ]
 
		thus, Î¨_m is conformally similar to Ïˆ_Î±(1) if and only if 
		
    Î»_0=r,     Î»_1=rm     for some complex number r,

		since diagonalizable matrices are similar if and only if its spectrum are equal. 
		This system of equation has a solution r=1m+1 and Î±= m(m+1)^2.
		Therefore ğ”¥_Ï•_mâ‰… L_3,6^Î± with Î±=m(m+1)^2.
		
	
	
	

Â§ LAGUERRE TYPE SOLUTIONS

	Let Aâˆˆ M_N(â„‚) be a constant matrix and let Î½âˆˆâ„ such that Î½>0. 
	In this section and the sequel, we are going to 
	consider the weight matrix  W given by
	
    W^(Î½)(x) = e^Ax T^(Î½)(x) e^A^âˆ— x,     T^(Î½)(x) =  e^-xâˆ‘_k=1^N Î´^(Î½)_k x^Î½+k  E_k,k.

	If we denote L(x)=e^Ax, then 
	
    W^(Î½)(x)=L(x) T^(Î½)(x) L^*(x).

	Recall that if A,J are as in (<ref>), the equation (<ref>) 
	in terms of L says that
	
    L(x)J L^-1(x)=J- Ax.

	In this case, we obtain the same kind of weight that was consider in section 3, with Ï•(x)=x.
	
	
		The first order differential operators
		
    ğ’Ÿ = âˆ‚_x x + x(A-1),   ğ’Ÿ^â€  = -âˆ‚_x x - (1+Î½ +J),

		are mutually adjoint and 
		satisfy
		
    M = Ïˆ^-1(ğ’Ÿ) =     (A-1)Î´-(n+1+Î½)-â„‹(n)Jâ„‹^-1(n),
    
    			M^â€  = Ïˆ^-1(ğ’Ÿ^â€ ) =    -(n+Î½+J+1) + â„‹(n)(A-1)^âˆ—â„‹^-1(n-1) Î´^-1.

	
	
		The operators ğ’Ÿ and ğ’Ÿ^â€  are mutually adjoint by taking Ï•(x)=x in Proposition <ref>. 
		
		On the other hand, since v(x) has degree 1 in this case, by Corollary <ref> 
		we obtain that A_j(n)=0 for jâ‰¤ -1 and A_1(n)=A-1.
		
		Finally, the formula for A^â€ _0(n) can be obtained directly from the relation PÂ·ğ’Ÿ^â€ =M_ğ’Ÿ^â€ Â· P 
		and the term A_0(n) can be obtained from equation (<ref>).
	
	
	As a direct consequence of the above proposition and  Corollary <ref> we obtain the following result.
	
		Let A,Jâˆˆ M_N(â„‚) as in (<ref>) and let W:=W^(Î½)_Ï• be a matrix weight as in (<ref>) with Ï•(x)=x 
		and MVOPs P(x,n). 
		If X(n) and Y(n) are the coefficients of the (n-1)-term and (n-2)-term of P(x,n) respectively, then
		
    n+X(n)A - A X(n+1)-B(n) = -(n+1+Î½)-â„‹(n)Jâ„‹^-1(n),

		
    X(n)+[J,X(n)]=â„‹(n)(A^âˆ—-1) â„‹^-1(n-1),

		where â„‹(n) and B(n)are as in (<ref>) and (<ref>). 
	
	
		It follows from Proposition <ref> and Corollary <ref>, by taking into account the term A_0(n) of ğ’Ÿ.
		
		On the other hand, from the equality PÂ·ğ’Ÿ^â€ = M^â€ Â· P with
		
    ğ’Ÿ^â€ = -âˆ‚_x x - (1+Î½ +J)   and    M^â€ =-(n+Î½+J+1)+A^â€ _-1(n) Î´^-1,

		we can obtained the equation (<ref>) from the above theorem. 
	
	
	

 Â§.Â§ Existence of the operator D

	Families of matrix valued orthogonal polynomials which are eigenfunctions of a second order differential operator are of great importance, see e.g. <cit.>, <cit.>, <cit.>, <cit.>.  Using the approach of <cit.>, we get a symmetric second-order differential operator which preserves polynomials and its degree. For this we establish a conjugation with a diagonal matrix differential operator. 
	
	Let us consider matrix valued polynomials F_2, F_1, F_0 of degrees two, one and zero respectively and let us assume that we have a matrix valued second-order differential operator D such that
	
    QÂ· D=(d^2Qdx^2)(x)   F_2(x) + (dQdx)(x)   F_1(x) +Q(x) F_0(x).

	for a matrix valued polynomial Q. It follows from the definition of the matrix valued inner product (<ref>) that a differential operator D is symmetric with respect to W if for all matrix valued polynomials G,H we have
	
    âˆ«_0^âˆ (GD)(x)W(x)(H(x))^âˆ—  dx = âˆ«_0^âˆ G(x)W(x)((HD)(x))^âˆ— dx.

	By <cit.>, this symmetry condition is equivalent to the following equations
	
    F_2(x)W(x) = W(x) ( F_2(x))^âˆ—,      
    		2 d(F_2W)dx(x) - F_1(x)W(x) = W(x) ( F_1(x))^âˆ—, 
    d^2(F_2W)dx^2(x) - d(F_1W)dx(x) + F_0(x) W(x) = W(x) ( F_0(x))^âˆ—,

	and	the boundary conditions 
	
    lim_xâ†’ 0 F_2(x)W(x) = 0 = lim_xâ†’âˆ F_2(x)W(x), 
    lim_xâ†’ 0 F_1(x)W(x) - d(F_2W)dx(x) = 0 = 
    		lim_xâ†’âˆ F_1(x)W(x) - d(F_2W)dx(x).

	
	We have the following lemma.
	
		The second order differential operator 
    D_Q=âˆ‚_x^2 x +âˆ‚_x ( 1+Î½-x+J) -J
 
		is symmetric respect to the weight T^(Î½)(x).
	
	
		By taking into account that F_2(x)=x, F_1(x)= 1+Î½ -x+J and F_0(x)=-J, it is a straightforward computation see that 
		(<ref>), (<ref>), (<ref>) and (<ref>) are satisfied for D_Q and T^(Î½)(x).
	
	
	 
		The second order differential operator 
		
    D=âˆ‚_x^2 x +âˆ‚_x ( (A-1)x +1+Î½+J) +AÎ½ + JA -J
 
		is symmetric respect to the weight W(x). Moreover
		
    PÂ· D = Î“Â· P   where  Î“(n)=A(n+Î½+1+J)-n-J.

	
	
		It follows from Remark 4.1 in  <cit.>. 
	
	
	

 Â§.Â§ The Lie Algebra associated to W
 	
	Recall that a Lie algebra ğ”¤ is called reductive if its radical is equal to its center. 
	
	
		Let A,Jâˆˆ M_N(â„‚) as in (<ref>) and 
		let us consider the operators
		
    ğ’Ÿ = âˆ‚_x x + x(A-1),  ğ’Ÿ^â€  = -âˆ‚_x x - (1+Î½+J),   
    			D=âˆ‚_x^2 x +âˆ‚_x ( (A-1)x +1+Î½+J) +AÎ½ + JA -J.

		If x acts over matrix valued polynomials by right constant multiplication, 
		then we have that 
		
    [ğ’Ÿ,x] = -x,     [ğ’Ÿ^â€ ,x]=x,     [ğ’Ÿ,ğ’Ÿ^â€ ] = x,      [D,x]=-ğ’Ÿ+ğ’Ÿ^â€ ,

		
    [ğ’Ÿ,D]= -ğ’Ÿ+ D - (1+Î½),    [ğ’Ÿ^â€ ,D]= ğ’Ÿ^â€ - D+ (1+Î½).

		The subjacent Lie algebra generated by {ğ’Ÿ, ğ’Ÿ^â€ , D,x, I}	is isomorphic to the Lie algebra ğ’œ=âŸ¨ x_1,x_2,x_3,x_4,x_5âŸ© with brackets
		
    [x_1,x_2]=-x_4,   [x_1,x_4]=-x_4 ,   [x_2,x_4]=x_4,    [x_3,x_4]=-x_1+x_2,

		
    [x_1,x_3]= -x_2+ x_3 +x_4 - (1+Î½)x_5   and  [x_2,x_3]= x_1 - x_3 -x_4 + (1+Î½)x_5,

		with correspondence:
		
    x_1âŸ¼ğ’Ÿ+x,   x_2âŸ¼ğ’Ÿ^â€ +x,    x_3âŸ¼ D,   x_4âŸ¼ x,    x_5 âŸ¼ 1.

	
	
		
		Let ğ’Ÿ'=ğ’Ÿ+x and ğ’Ÿ'^â€ =ğ’Ÿ^â€ +x.
		It can be shown by direct computation that
		
    [ğ’Ÿ',x]=-x,    [ğ’Ÿ'^â€ ,x]= x,    [ğ’Ÿ',ğ’Ÿ'^â€ ]=-x,    [D,x]=-ğ’Ÿ'+ğ’Ÿ'^â€ ,

		
    [ğ’Ÿ',D]= -ğ’Ÿ'^â€ + D +x - (1+Î½),    [ğ’Ÿ'^â€ ,D]= ğ’Ÿ'- D -x + (1+Î½).

		Clearly, the subjacent Lie algebra associated to this representation, is the Lie algebra ğ’œ=âŸ¨ x_1,x_2,x_3,x_4,x_5âŸ© with brackets
		
    [x_1,x_2]=-x_4,   [x_1,x_4]=-x_4 ,   [x_2,x_4]=x_4,    [x_3,x_4]=-x_1+x_2,

		
    [x_1,x_3]= -x_2+ x_3 +x_4 - (1+Î½)x_5   and  [x_2,x_3]= x_1 - x_3 -x_4 + (1+Î½)x_5,

		with correspondence 
		
    x_1âŸ¼ğ’Ÿ+x,   x_2âŸ¼ğ’Ÿ^â€ +x,    x_3âŸ¼ D,   x_4âŸ¼ x,    x_5 âŸ¼ 1,

		as desired.		
	
	
	
	
	We have the following structure result.
	
	
		The Lie algebra ğ’œ defined as above is a 5-dimensional reductive algebra with center of dimension two, given by ğ’µ_ğ’œ=âŸ¨ x_1+x_2- x_4,x_5âŸ©. Moreover, 
		ğ’œ=[ğ’œ,ğ’œ]âŠ•ğ’µ_ğ’œ  with
		[ğ’œ,ğ’œ] isomorphic to SL(2,â„‚). In particular, 
		
    ğ’_1= -4x_4(x_1-x_3-x_4+(1+Î½)x_5)+(x_4-x_1+x_2)^2,   ğ’_2= x_1+x_2- x_4  and  ğ’_3=x_5
 
		are Casimir elements of ğ’œ.
	
	
		From Lie algebra theory (see <cit.>), the radical of ğ’œ can be computed from its Killing form, in this case we have that 
		
    Rad(ğ’œ)=ğ’µ_ğ’œ=âŸ¨ x_1+x_2- x_4,x_5âŸ©,

		and so, the Lie algebra ğ’œ is reductive. 
		Now, from general theory, since ğ’œ is reductive, we obtain
		
    ğ’œ=[ğ’œ,ğ’œ] âŠ•ğ’µ_ğ’œ.

		In this case, we obtain that
		
    [ğ’œ,ğ’œ]= âŸ¨  x_4,   x_1 -x_2,   x_1-x_3 -x_4 +(1+Î½) x_5âŸ©.

		By taking a_1=x_4, a_2= x_1-x_2 and a_3=x_1-x_3-x_4+(1+Î½)x_5 we obtain that 
		
    [a_1,a_2]=-2a_1,    [a_1,a_3]=a_1-a_2,    [a_2,a_3]=-a_3

		and so if we take Ã¢_2=a_1-a_2 and Ã¢_3=-a_3 we have 
		
    [a_1,Ã¢_2]=2a_1,    [a_1,Ã¢_3]=-Ã¢_2,    [Ã¢_2,Ã¢_3]=2Ã¢_3,

		and so [ğ’œ,ğ’œ] is isomorphic to SL(2,â„‚) by consider the map a_1â†¦ e_1 Ã¢_2 â†¦ e_2 and Ã¢_3 â†¦ e_3.
		In particular, the Casimir element of SL(2,â„‚) given by 4e_1e_3+e_2^2 induces a Casimir element of [ğ’œ,ğ’œ]
		
    ğ’_[ğ’œ,ğ’œ]= -4x_4(x_1-x_3-x_4+(1+Î½)x_5)+(x_4-x_1+x_2)^2.

		By taking into account that ğ’_[ğ’œ,ğ’œ] commutes with the central elements of ğ’œ, we obtain that ğ’_[ğ’œ,ğ’œ] commutes with all of the elements of  ğ’œ and so is a Casimir element of ğ’œ. 
		
		The last assertion is clear, since the central elements always are Casimir elements of a given Lie algebra.
	
	
	
	
		Notice that 
		
    ğ’=ğ’_2+ (1+Î½ )ğ’_3 = ğ’Ÿ+ğ’Ÿ^â€ +x+(1+Î½)
 
		it is also a Casimir invariant of ğ’œ. 
		Hence, under the representation given by ğ’Ÿ,ğ’Ÿ^â€ , D,x,1, 
		the image of this Casimir satisfies
		
    ğ’= Ax-J.

		Thus, in terms of M,M^â€  and L, we obtain that
		
    Ï†^-1(ğ’)=M+M^â€ +L+(1+Î½).

		On the other hand, it can be check that
		
    ğ’_[ğ’œ,ğ’œ]=18(A^2x^2+Î½^2+J^2+Ax-2Î½ Ax-2xJA+2Î½ J -1).

		Thus, ğ’'=A^2x^2-2xJA+J+J^2 it is also a Casimir since
		
    ğ’'=8ğ’_[ğ’œ,ğ’œ]-(1-2Î½)ğ’ - (Î½^2-1)ğ’_3,

		moreover, notice that the relation [J,A]=A implies that
		ğ’'=ğ’^2-ğ’, and so we obtain that
		
    ğ’_[ğ’œ,ğ’œ]=18( ğ’^2-2Î½ğ’ + (Î½^2-1)ğ’_3).

		Therefore, in this representation the Casimir element corresponding to ğ’_[ğ’œ,ğ’œ] does not give more information than ğ’.
		Hence, in the rest of the paper we will only consider the Casimir element ğ’.
	
	
	We can also consider the Lie subalgebra generated by {x_1,x_2,x_4,x_5}. 
	Notice that a representation of this kind of algebra was consider in the above section by taking Ï•(x)=x.
	In this case, we have the following structure result.
	
	
	
		The Lie subalgebra ğ’œ' = âŸ¨ x_1,x_2,x_4,x_5 âŸ© of ğ’œ is isomorphic to ğ”¤_2âŠ•â„‚^2 where ğ”¤_2 is the 2-dimensional solvable Lie algebra with bracket [e_1,e_2]=e_2.
		In particular, ğ’œ' has no non-central Casimir invariants. 
	
	
	
		By taking the map 
		
    x_2â†¦ e_1,    x_4 â†¦ e_2,    x_1+x_2-x_4â†¦ e_3   and    x_5 â†¦ e_4.

		we obtain an isomorphic algebra of ğ’œ', in this case the only non-vanishing bracket of âŸ¨ e_1,e_2,e_3,e_4âŸ© is the bracket 
		[e_1,e_2]=e_2 and so ğ’œ' is isomorphic to ğ”¤_2âŠ•â„‚^2, as asserted. 
		
		The last assertion is a consequence of ğ”¤_2 has not central elements.
		Hence, the only Casimir invariants of ğ’œ' are the central elements. 
	
	
	In the sequel, in order to simplify the notation, we will consider 
	
    B_n:=B(n),   C_n:=C(n),   â„‹_n:=â„‹(n),   Î“_n= Î“(n).

	The following proposition is a consequence, of the relations between the brackets of M,M^â€ ,L,Î“. 
	
	
		Let A,Jâˆˆ M_N(â„‚) be matrices as in (<ref>) and let B_n,C_n,â„‹_n and Î“_n be as in (<ref>). 
		Then,
		
    B_n (A-1) - (A-1) B_n+1 = 2 + â„‹_n+1 J â„‹_n+1^-1 - â„‹_n J â„‹_n^-1,

		
    B_n=[B_n,J] + â„‹_n (A^t-1) â„‹_n-1^-1 - â„‹_n+1 (A^t-1) â„‹_n^-1,

		
    2 â„‹_n â„‹_n-1^-1= [â„‹_n â„‹_n-1^-1,J] - B_n â„‹_n (A^t-1) â„‹_n-1^-1 - â„‹_n (A^t-1) â„‹_n-1^-1 B_n-1,

		
    B_n = -[J,â„‹_n J â„‹_n^-1] - â„‹_n (A^t-1) â„‹_n-1^-1 (A-1) + (A-1) â„‹_n+1 (A^t-1) â„‹_n^-1,

		
    [Î“, C_nÎ´^-1] = â„‹_n(A-1)^*â„‹_n-1^-1,

		
    [Î“_n,â„‹_nJ â„‹_n^-1]= n+Î“_n+â„‹_nJ â„‹_n^-1,

		
    [Î“,â„‹_n(A-1)^*â„‹_n-1^-1Î´^-1]=-â„‹_n(A-1)^*â„‹_n-1^-1.

	
	
		The equation (<ref>) is consequence of seeing the coefficient of Î´^1 in the bracket 
		relation [M,L]=L. 
		
		In the same way,  the equations (<ref>), (<ref>) are consequence of seeing the coefficients of Î´^0 and Î´^-1 in the bracket relation [M^â€ , L] = L.
		
		On the other hand, the equation (<ref>) it follows from the bracket relation [M,M^â€ ] = L.
		The equation (<ref>) is a consequence of the coefficient of Î´^-1 in the bracket [Î“,L] = -M+M^â€ .
		The equation (<ref>) is obtained from the coefficient of Î´^0 in the bracket [Î“,M] = M-Î“+(1+Î½).
		Finally, the equation (<ref>) can be obtained from the coefficient of Î´^-1 in the bracket relation
		[Î“,M^â€ ] = -M^â€ +Î“-(1+Î½).
	
	
	 
		Let A,Jâˆˆ M_N(â„‚) be matrices as in (<ref>).
		Then,
		
    [B_n,J]    =  B_n  - Î“_nC_n + C_n Î“_n-1 + Î“_n+1 C_n+1 - C_n+1Î“_n, 
    
    			[C_n,J]   = 2C_n+B_n (Î“_nC_n - C_n Î“_n-1) + (Î“_nC_n - C_n Î“_n-1) B_n-1,

		where B_n,C_n,â„‹_n and Î“_n be as in (<ref>)
	
	
		By (<ref>) we have that 
		
    [B_n,J] = B_n - â„‹_n (A^t-1) â„‹_n-1^-1 + â„‹_n+1 (A^t-1) â„‹_n^-1.

		On the other hand, by (<ref>) and taking into account that â„‹_nâˆˆ M_N(â„), we obtain that
		
    â„‹_n(A^t-1)â„‹_n-1^-1 =  [Î“, C_nÎ´^-1]   = Î“_nC_n - C_n Î“_n-1,
    â„‹_n+1(A^t-1)â„‹_n^-1 = [Î“, C_nÎ´^-1]   = Î“_n+1 C_n+1 - C_n+1Î“_n,

		and so we have that
		
    [B_n,J] =  B_n  - Î“_nC_n + C_n Î“_n-1 + Î“_n+1 C_n+1 - C_n+1Î“_n,

		as asserted.
		
		For the second equality, notice that since C_n=â„‹_nâ„‹_n-1^-1, 
		thus the equation (<ref>)  implies that 
		
    [C_n,J]=2C_n+B_n â„‹_n (A^t-1) â„‹_n-1^-1 + â„‹_n (A^t-1) â„‹_n-1^-1 B_n-1.

		In the same way as above, we obtain that
		
    [C_n,J]=2C_n+B_n (Î“_nC_n - C_n Î“_n-1) + (Î“_nC_n - C_n Î“_n-1) B_n-1,

		as desired.
	
	
	
	

Â§ MATRIX ENTRIES OF P(X,N) AS CLASSICAL LAGUERRE POLYNOMIALS

	
	In this section we will give explicit expressions of the entries of the Laguerre-type MVOPs in terms of the classical scalar Laguerre polynomials. For this we use the approach of <cit.>, <cit.>, <cit.>, which consists in observing that a symmetric second order differential operator can be diagonalized via conjugation with an appropriate matrix valued function. The present situation is more involved than the previous cases because, although the differential operator can be diagonalized, the eigenvalue remains non-diagonal.
	
	In the rest of the section, the weight matrix W(x) is as in the previous section.
	

 Â§.Â§ Step I: Diagonalizing the differential operator:
 
	Let A,Jâˆˆ M_N(â„‚) be matrices as in (<ref>). We can define the following auxiliary matrix valued polynomials
	
    Q(x,n):=P(x,n)L(x),     where L(x)= e^xA.

	The polynomials Q_n satisfy the following relations,
	
    Q_nÂ·ğ’Ÿ_Q = M Â· Q_n,     Q_nÂ· D_Q = Î›_n Â· Q_n,     Q_nÂ·ğ’_Q = M_ğ’Â· Q_n,

	where 
	
    ğ’Ÿ_Q= L(x)^-1ğ’Ÿ L(x),      D_Q=L(x)^-1 D L(x),     ğ’_Q=L(x)^-1ğ’ L(x).

	Here ğ’Ÿ, D are as in Proposition <ref>, Proposition <ref> respectively and ğ’=Ax-J . 
	In the following lemma, we show that ğ’Ÿ_Q, D_Q and ğ’_Q are simple diagonal operators.
			
		The operators ğ’Ÿ_Q, D_Q and ğ’_Q as in (<ref>)
		are given explicitly as follows: 
		
    ğ’Ÿ_Q=  âˆ‚_x x -x,      
    		D_Q=âˆ‚_x^2 x +âˆ‚_x ( 1+Î½-x+J) -J,     ğ’_Q=-J.

	
	
	
		All of the equalities are follow directly from definition and the equation (<ref>).
	
	
	In the following proposition, we will use the expressions of ğ’_Q, ğ’ and ğ’Ÿ 
	in order to obtain an equation which relates Q(x,n) and the recurrent matrix H_n(A^âˆ—-1)H_n-1^-1.
	
	
		The auxiliary functions Q(x,n)'s defined in (<ref>), 
		satisfy the following equation which depend on the squared norms:
		
    -Q(x,n)J=xQ'(x,n)- (n+J)Q(x,n)+â„‹(n)(A-1)^âˆ—â„‹^-1(n-1)Q(x,n-1)   for nâ‰¥ 1

		and for n=0
		
    -Q(x,0)J=-J-xQ'(x,0).

	
	
		By Lemmas <ref> and <ref> we have that 	
		
    -Q(x,n)J = Q(x,n)Â·ğ’_Q = (M_ğ’Â· P(x,n))e^xA

		where M_ğ’ is the discrete operator
		
    M_ğ’=A Î´ + X(n)A-AX(n+1)-J + (Y(n)A-AY(n+1) + [J,X(n)] + (AX(n+1)-X(n)A)X(n))Î´^-1.
		
		By equation (<ref>), we have
		
    (n-1)X(n)+Y(n)(A-1)-(A-1)Y(n+1)-( n+X(n)A - A X(n+1)-B(n))X(n) = 0,
 
		and so 
		
    Y(n)A-AY(n+1)  + (AX(n+1)-X(n)A)X(n)= X(n)+Y(n)-Y(n+1)-B(n)X(n).

		By taking into account the relation PÂ· x =LÂ· P with L=Î´+B(n)+C(n)Î´^-1, 
		thus we have that
		
    Y(n)=Y(n+1)+B(n)X(n)+C(n).

		Hence, we obtain that
		
    (M_ğ’Â· P(x,n))e^xA= AQ(x,n+1) + (X(n)A-AX(n+1)-J)Q(x,n)+ (C(n) + [J,X(n)] + X(n))Q(x,n-1).

		On the other hand, by Corollary <ref> we have that
		
    (M_ğ’ŸÂ· P(x,n))e^xA   =    (A-1) Q(x,n+1)+ (n+X(n)A - A X(n+1)-B(n))Q(x,n), 
    
    				(L Â· P(x,n))e^xA   =    Q(x,n+1) + B(n)Q(x,n)+ C(n) Q(x,n-1),

		where B(n) and C(n) are as in equation (<ref>). Hence, we have that
		
    ((M_ğ’Ÿ+L)Â· P(x,n))e^xA= A Q(x,n+1)+(n+X(n)A - A X(n+1))Q(x,n)+C(n)Q(x,n-1)

		and thus
		
    (M_ğ’Â· P(x,n))e^xA= ((M_ğ’Ÿ+L)Â· P(x,n))e^xA-(n+J)Q(x,n)+ (X(n)+[J,X(n)])Q(x,n-1).

		Notice that if we denote L(x)=e^xA, the Lemma <ref> implies that
		
    ((M_ğ’Ÿ+L)Â· P(x,n))L(x)=(P(x,n)Â·(ğ’Ÿ+x))L(x)= Q(x,n)Â· L^-1(x)(ğ’Ÿ+x))L(x)= Q(x,n)Â·âˆ‚_xx,

		and by (<ref>), X(n)+[J,X(n)]=â„‹(n)(A-1)^âˆ—â„‹^-1(n-1). 
		Thus, we obtain that
		
    -Q(x,n)J= xQ'(x,n)- (n+J)Q(x,n)+â„‹(n)(A-1)^âˆ—â„‹^-1(n-1),

		as asserted.
		Finally, the equation for n=0, it follows from equation (<ref>).
	
	
	
	
	

 Â§.Â§ Step II: Diagonalizing the eigenvalue Î›_n:
 
	Although the differential operator D_Q is a diagonal operator, the system of equations given by Q_nÂ· D_Q = Î›_n Q_n is not a decoupled system since Î›_n is a lower triangular matrix. However, Î›_n can be diagonalized in a somewhat simple way:
	
    Î“_n=A(n+Î½+J+1) - (n+J) = K_n Î›_n K_n^-1,

	where Î›_n is the diagonal matrix Î›_n = -(n+J).   
	
		We can choose K_n such that is a lower triangular matrix with diagonal elements (K_n)_i,i=1 for all i=1,â€¦,N. 
		Moreover, in this case K_n is the following matrix: 
		
    (K_n)_i,j=
    			
    				(-1)^i-j(n+Î½ + j+1)_i-1(i-j)!âˆ_k=j^i-1a_k      i> j, 
    
    				1     i=j, 
    
    				0     i<j.

	
	
		Since A(n+Î½+J+1) - (n+J) is lower triangular, the its characteristic polynomial satisfy 
		
    (Î» I -(A(n+Î½+J+1) - (n+J)))=(Î» I +nI+J)=âˆ_r=1^N(Î»+n+r).

		Then, the eingevalues of A(n+Î½+J+1) - (n+J) are 
		
    Î»_1=-(n+1), â€¦, Î»_N=-(n+N)   with multiplicity 1.

		Since K_n diagonalizes A(n+Î½+J+1) - (n+J), 
		then its r-th column can be obtained from the eigenspace correspond 
		to Î»_r=-(n+r), that is
		
    Nu(Î»_r I-A(n+Î½+J+1) + n+J)=Nu(-A(n+Î½+J+1) +J-rI),    for r=1, â€¦,N.

		We can obtain (<ref>) by a straightforward computation of these eigenspaces. 
	
	With the matrix K_n as in (<ref>), we will consider the following matrix polynomial 
	
    R(x,n):=K_n^-1Q(x,n).

	The following result that shows a relationship between the non-zero matrix entries of R(x,n) and generalized Laguerre polynomials.
	
	
		Let nâˆˆâ„• and let Î½>0.
		The matrix elements of R(x,n) are multiples of scalar Laguerre functions 
		
    R(x,n)_i,j= 
    			
    				L^(Î½ + j)_n+i-j(x) Î¾(n,i,j)    if n+i-j â‰¥ 0
    
    				0    if n+i-j < 0.

	
	
		Notice that the polynomials  R(x,n)'s are eigenfunctions of  D_Q=âˆ‚_x^2 x + âˆ‚_x ( 1+Î½-x+J) -J 
		with associated eigenvalues Î›_n=-(n+J) where J is the diagonal matrix diag(1,2,â€¦,N). 
		If we look the (i,j)-entry of
		
    xRâ€(x,n) + R'(x,n) (1+Î½-x+J) + (nR(x,n) + JR(x,n) -R(x,n)J)=0,

		we obtain that the following expression
		
    xRâ€(x,n)_i,j + âˆ‘_k=1^N R'(x,n)_i,k (1+Î½-x+J)_k,j + nR(x,n)_i,j + âˆ‘_k=1^N (J_i,kR(x,n)_k,j - R(x,n)_i,kJ_k,j) = 0.

		Since J=diag(1,2,â€¦,N), the above equality is equivalent to
		
    xRâ€(x,n)_i,j +  R'(x,n)_i,j (1+Î½-x+j) + (n+i-j)R(x,n)_i,j = 0.

		Hence, we obtain that 
		
    R(x,n)_i,j= L^(Î½+j)_n+i-j(x) Î¾(n,i,j),

		as asserted.
		
		On the other hand,  it is well-known that if M<0 the only solution for the differential equation 
		
    x Pâ€(x) +  P'(x) (1+Î½-x) + M P(x) = 0,

		is P(x)=0 and since
		
    xRâ€(x,n)_i,j +  R'(x,n)_i,j (1+Î½-x+j) + (n+i-j)R(x,n)_i,j = 0,

		we obtain that R(x,n)_i,j=0 if n+i-j<0, as asserted.
	
	
	
		Notice that by the above theorem the are only defined for n+i-j â‰¥ 0, so we extend its definition as follows
		
    Î¾(n,i,j)=0     if n+i-j < 0.

	
	
	It is well-known that the generalized Laguerre polynomial satisifes
	
    L^(Î±)_N(0)=(Î±+1)_N/N!,

	where (a)_N is the Pochhammer symbol defined by
	
    (a)_N= 
    		
    			1    if N=0,
    
    			a(a+1)â‹¯(a+N-1)    if N>0.

	As a direct consequence of the above theorem we obtain the following corollary.
	
		Let nâˆˆâ„• and let Î½>0.
		Then, the coefficients of R(0,n) satisfy
		
    R(0,n)_i,j= 
    			(Î½+j+1)_n+i-j/(n+i-j)!Î¾(n,i,j)    if n+i-j â‰¥ 0,
    
    				0    if n+i-j < 0.

		In particular, the (i,n+i)-th and (i,n+i-1)-th coordinates of R(0,n) satisfy 
    R(0,n)_i,n+i=Î¾(n,i,n+i)   and   R(0,n)_i,n+i-1=(n+Î½+i)Î¾(n,i,n+i-1).

	
	Now we need to identify the coefficients Î¾(n,i,j). 
	For this, we exploit the relation in Proposition <ref>. In the following lemma, we observe that the factor â„‹(n)(A-1)^âˆ—â„‹^-1(n-1) in this relation is turned into a diagonal matrix via multiplication by appropriate matrices K_n. This will allow us to obtain a simple recursion for Î¾(n,i,j). For this purpose, we define the following 
	
    G(n):= K_n^-1â„‹_n (A^âˆ—-1)â„‹_n-1^-1K_n-1     I(n):= K_n^-1â„‹_n J â„‹_n^-1K_n,
	
	where â„‹_n and K_n are as in (<ref>) and (<ref>), respectively. 
	
		For nâ‰¥ 1 and let  G(n), I(n) be the matrices as in (<ref>).
		Then, G(n) is diagonal and I(n) satisfies
		
    (I(n))_i,i = i,      (I(n))_i,j=0   for  iâ‰  j  and  i â‰  j-1.

		Moreover
		
    (G(n))_i,i= (â„‹_n (A^âˆ—-1)â„‹_n-1^-1)_i,i  and   (I(n))_i,i+1=(â„‹_n J â„‹_n^-1)_i,i+1.

	
	
	
		By equation (<ref>), 
    [Î“_n,â„‹_n(A^âˆ—-1)â„‹_n-1^-1Î´^-1]=-â„‹_n(A^âˆ—-1)â„‹_n-1^-1.

		Then, 
		
    K_n^-1Î“_n(â„‹_n(A^âˆ—-1)â„‹_n-1^-1)K_n-1-K_n^-1(â„‹_n(A^âˆ—-1)â„‹_n-1^-1)Î“_n-1K_n-1=-G(n).

		Then, by K_n^-1Î“_nK_n=Î›_n=-(n+J) we obtain that
		
    Î›_n G(n)-G(n) Î›_n-1=-G(n).

		The assertion it follows by observing the (i,j)-entry for iâ‰  j.
		On the other hand, from definition we have that
		
    K_n G(n) K_n-1^-1=  â„‹_n (A^âˆ—-1)â„‹_n-1^-1.

		Since K_n and K_n-1^-1 are both lower triangular matrices with 1's in its diagonal, then the left term in the above equation is a lower triangular matrix with (i,i)-th coordinate equal to (G(n))_i,i and so
		
    (â„‹_n (A^âˆ—-1)â„‹_n-1^-1)_i,i=(K_n G(n) K_n-1^-1)_i,i=(G(n))_i,i,

		as asserted.
		
		Now, for the second assertion, we can proceed as in the same way, 
		in this case by equation (<ref>), we have that 
		
    [Î“_n,â„‹_nJ â„‹_n^-1]=n+Î“_n + â„‹_nJâ„‹_n^-1.

		Then, we obtain that
		
    K_n^-1Î“_n â„‹_nJ â„‹_n^-1K_n-K_n^-1â„‹_nJ â„‹_n^-1Î“_n K_n = K_n^-1(n+Î“_n+â„‹_nJ â„‹_n^-1)K_n.

		Hence, by K_n^-1Î“_nK_n=Î›_n=-(n+J) we obtain that
		
    Î›_n I(n)-I(n) Î›_n = n+ Î›_n + I(n)).

		The proof follows by observing the (i,j)-entry in the above matrix equality.
		Finally, from definition we have 
		
    K_nI(n)K_n^-1=â„‹_n J â„‹_n^-1.

		So, in general we have that 
		
    (K_nI(n)K_n^-1)_i,j= âˆ‘_k=1^N (K_n)_i,k (I(n)K_n^-1)_k,j  and   (I(n)K_n^-1)_k,j=(I(n))_k,k(K_n^-1)_k,j+(I(n))_k,k+1(K_n^-1)_k+1,j.

		By taking into account that (K_n)_i,j=(K_n^-1)_i,j=0 for j>i, 
		if j=i+1 we obtain that
		
    (K_nI(n)K_n^-1)_i,i+1=âˆ‘_k=1^N (K_n)_i,k (I(n)K_n^-1)_k,j=âˆ‘_k=1^i (K_n)_i,k (I(n)K_n^-1)_k,i+1= (I(n))_i,i+1(K_n^-1)_i+1,i+1,

		by taking into account that (K_n^-1)_i+1,i+1=1 for any i. Therefore, we have that (K_nI(n)K_n^-1)_i,i+1=(I(n))_i,i+1, as desired.
	
	
	
	The following proposition is a consequence of the relation given by the Casimir operator and Proposition 6.4
	
	
		Let Î¾(n,i,j) as in Theorem <ref>.  
		If n+i-j> 0, then the constants Î¾(n,i,j)'s satisfy the following: 
		
			
  * Î¾(0,i,j)=(K_0^-1)_i,j(i-j)!(Î½+j+1)_i-j,
			
  * If i=1 and n>0 then 
			
    Î¾(n,1,j) =(G(n))_1,1 n+Î½+1Î¾(n-1,1,j),

			
  * If i>1 and n>0, then 
			
    Î¾(n,i,j) = a_i-1Î¾(n,i-1,j) +(G(n))_i,i n+Î½+iÎ¾(n-1,i,j),

			
		with G(n) as in (<ref>).
	
	
		For the first assertion, recall that 
		
    R(0,0)=K_0^-1Q(0,0)=K_0^-1P(0,0)=K_0^-1,
 
		thus we have that  
		
    (K_0^-1)_i,j=Î¾(0,i,j)L^(Î½+j)_i-j(0).

		By taking into account that L^(Î½)_N(0)=(Î½+1)_NN! for any N, hence we obtain 
		
    (K_0^-1)_i,j(i-j)!(Î½+j+1)_i-j=Î¾(0,i,j),

		as asserted.
		
		For items (b) and (c), recall that Proposition <ref> implies that 
		
    -Q(0,n)J = -(n+J)Q(0,n) + â„‹(n) (A^âˆ—-1) â„‹(n-1)^-1 Q(0,n-1).

		Then,
		
    -K_n R(0,n)J = -(n+J)K_n R(0,n) + â„‹(n) (A^âˆ—-1) â„‹(n-1)^-1 K_n-1R(0,n-1),

		and so we obtain that
		
    -R(0,n)J = -K_n^-1(n+J)K_n R(0,n) +G(n) R(0,n-1)

		where G(n)=K_n^-1â„‹(n) (A^âˆ—-1) â„‹(n-1)^-1 K_n-1.
		By recalling that 
		
    K_n^-1(n+J)K_n R(0,n)=(n+J)-A(n+Î½+J+1),

		we obtain that 
		
    -R(0,n)J = -(n+J) R(0,n)+ A(n+Î½+J+1) R(0,n)+ G(n)R(0,n-1).

		Thus, in terms of coordinates we have that
		
    -j R(0,n)_i,j = -(n+i)R(0,n)_i,j + âˆ‘_k=1^N(A(n+Î½ + J+1))_i,kR(0,n)_k,j +  âˆ‘_k=1^N (G(n))_i,kR(0,n-1)_k,j.

		
		Since A has only non-zero entries a_i's in the place (i,i+1) and n+Î½ + J+1 is diagonal, we obtain that
		
    âˆ‘_k=1^N(A(n+Î½ + J+1))_i,kR(0,n)_k,j=
    			
    				(a_i-1(n+Î½ + i))R(0,n)_i-1,j   if i>1, 
    
    				0    if i=1.
	
		Thus, for i>1 the equation (<ref>) takes the form	
		 
    -j R(0,n)_i,j=  -(n+i)R(0,n)_i,j + a_i-1(n+Î½ + i)R(0,n)_i-1,j+  (G(n))_i,iR(0,n-1)_i,j
 
		where in the last term of the equality, we use Lemma <ref>. 
		By Theorem <ref>, we have that
		
    (n+i-j) L^(Î½+j)_n+i-j(0) Î¾(n,i,j) = L^(Î½+j)_n+i-1-j(0) (a_i-1(n+Î½+i)   Î¾(n,i-1,j)+ (G(n))_i,iÎ¾(n-1,i,j)).

		Therefore, since n+i-j>0 we obtain a similar expression of (<ref>) by multiplication for ((n+i-j) L^(Î½+j)_n+i-j(0))^-1, that is
		
    Î¾(n,i,j) = C_1(n,i,j)Î¾(n,i-1,j) +C_2(n,i,j) Î¾(n-1,i,j),

		where
		
    C_1(n,i,j) = (a_i-1(n+Î½+i))  L^(Î½+j)_n+i-1-j(0)(n+i-j) L^(Î½+j)_n+i-j(0)  and   C_2(n,i,j) = (G(n))_i,i L^(Î½+j)_n-1+i-j(0)(n+i-j) L^(Î½+j)_n+i-j(0).

		To finish the proof, recall that
		
    L^(Î±)_N(0)=(Î±+1)_N/N!,

		where (a)_N is the Pochhammer symbol defined by
		
    (a)_N= 
    		
    			1    if N=0,
    
    			a(a+1)â‹¯(a+N-1)    if N>0.

		Hence, we have that 
		
    L^(Î½+j)_n+i-1-j(0)/L^(Î½+j)_n+i-j(0)= n+i-j/n+Î½+i.

		Therefore we obtain (<ref>), as asserted.
		
		Now, for  i=1 the equation (<ref>) takes the form
		
    -j R(0,n)_1,j = -(n+1)R(0,n)_i,j + (G(n))_1,1R(0,n-1)_1,j.

		So, the equation (<ref>) it can be prooved in a similar way as in the case i>1. 
	
	
		Notice that the item (a) in the above proposition still holds for n+i-j=0 since in this case we just use the definition of Î¾'s.
	
	
	Now, we are going to study the case n+i-j=0. 
	In this case, we have the following result.
	
	
		Let nâˆˆâ„•_0 and let I(n),  G(n) be as in (<ref>). 
		If iâ‰¥1, then the constants Î¾'s satisfy the following:
		
			
  * Î¾(0,i,i)= 1 and Î¾(1,i,i+1)= I(0)_i,i+1.
			
  * If i=1 and n>0, then 
			
    N_1(n,i) Î¾(n,1,n+1)= N_2(n,i) Î¾(n-1,2,n+1),    with
 
			
    N_1(n,i)=(Î½+2n+3) (G(n+1))_1,1 n+Î½+2 + (n+2+Î½) + I(n)_1,2 (Î½+2n+2) a_1,    N_2(n,i)=I(n)_1,2 (Î½+2n+2)(G(n))_2,2 n+Î½+2.

			
  * If i>1 and n>0, then 
			
    M_1(n,i)Î¾(n+1,i-1,n+i)= M_2(n,i)Î¾(n,i,n+i)+M_3(n,i)Î¾(n-1,i+1,n+i),

			
    with    M_1(n,i)=a_i-1( i(n+1+Î½+i)_i-2-(n+Î½+i)),
 
			
    M_2(n,i)=(G(n+1))_i,i + (n+Î½+i+1),     M_3(n,i)=(I(n))_i,i+1 G(n)_i+1,i+1.

		
	
	
	
		The first assertion of item (a) it follows from item (a) of <ref> (see Remark <ref>). Indeed, since K_n^-1 has a diagonal of 1's, in this case we have that
		
    Î¾(0,i,i)= (K_0^-1)_i,i0!(Î½+i+1)_0=(K_0^-1)_i,i=1.
 
		
		By Proposition <ref>, we have
		ğ’Ÿ = âˆ‚_x x + x(A-1) and M = (A-1)Î´-(n+1+Î½)-â„‹(n)Jâ„‹^-1(n) satisfies 
		
    P_n Â·ğ’Ÿ = M Â· P_n.

		By recalling that (P_n Â·ğ’Ÿ)(0)=0, 
		we obtain that 
		
    (A-1)P(0,n+1)-(n+1+Î½)P(0,n)-â„‹_nJâ„‹^-1_n P(0,n)=0,
 
		since P(0,m)=K_m R(0,m), we have that
		
    K_n^-1(A-1)K_n+1 R(0,n+1)-(n+1+Î½)R(0,n)-I(n) R(0,n)=0

		where I(n)=K_n^-1â„‹_n Jâ„‹_n ^-1K_n. 
		
		If we consider the expression (<ref>) with n=0, we arrive to
		
    0 = K_0^-1(A-1)K_1 R(0,1)-K_0^-1(1+Î½)K_0 R(0,0)-I(0) R(0,0).

		By taking the (i,i+1)-th coordinate, we obtain that
		
    0 = - R(0,1)_i,i+1-(1+Î½)R(0,0)_i,i+1-I(0)_i,i R(0,0)_i,i+1- I(0)_i,i+1R(0,0)_i+1,i+1.

		From Theorem <ref> we have 
		
    Î¾(1,i,i+1)= I(0)_i,i+1Î¾(0,i+1,i+1)=I(0)_i,i+1.

		as asserted.
		
		Now, let us consider n>0 in the equation (<ref>). 
		By taking into account the (i,n+i)-coordinate in (<ref>),
		
		
    âˆ‘_r=1^N(K_n^-1(A-1)K_n+1)_i,rR(0,n+1)_r,n+i-(n+1+Î½) R(0,n)_i,n+i-âˆ‘_r=1^NI(n)_i,rR(0,n)_r,n+i=0.
 
		By Lemma (<ref>) and since R(0,n+1)_r,n+i= 0 for r<i-1 we have that 
		
    âˆ‘_r=i-1^N(K_n^-1(A-1)K_n+1)_i,rR(0,n+1)_r,n+i-(n+1+Î½+i) R(0,n)_i,n+i-I(n)_i,i+1R(0,n)_i+1,n+i=0.
 
		
		On the other hand, since the matrix K_n^-1(A-1)K_n+1 is lower triangular we obtain that
		
    âˆ‘_r=i-1^N(K_n^-1(A-1)K_n+1)_i,rR(0,n+1)_r,n+i= âˆ‘_r=i-1^i(K_n^-1(A-1)K_n+1)_i,rR(0,n+1)_r,n+i.
 
		By taking into account that
		(K_n^-1(A-1)K_n+1)_i,i-1= a_i-1 -(K_n^-1K_n+1)_i,i-1 and  (K_n^-1(A-1)K_n+1)_i,i=-1,
		we obtain that
		
    0    =   (a_i-1 -(K_n^-1K_n+1)_i,i-1) R(0,n+1)_i-1,n+i- R(0,n+1)_i,n+i
       -   (n+1+Î½+i)R(0,n)_i,n+i-I(n)_i,i+1R(0,n)_i+1,n+i.

		By Corollary <ref> we have
		
    0    =   (a_i-1 -(K_n^-1K_n+1)_i,i-1) Î¾(n+1,i-1,n+i) - (n+1+Î½+i) Î¾(n+1,i,n+i) 
       -   (n+1+Î½+i) Î¾(n,i,n+i) -I(n)_i,i+1 (n+Î½ +i+1)Î¾(n,i+1,n+i).

		
		On the other hand, by Proposition <ref> if n+i-j>0 we know that 
		
    Î¾(n,i,j) = a_i-1Î¾(n,i-1,j) +(G(n))_i,i n+Î½+iÎ¾(n-1,i,j).

		Thus, in particular we obtain 
		
    Î¾(n+1,i,n+i) = a_i-1Î¾(n+1,i-1,n+i) +(G(n+1))_i,i n+1+Î½+iÎ¾(n,i,n+i),

		
    Î¾(n,i+1,n+i) = a_iÎ¾(n,i,n+i) + (G(n))_i+1,i+1)n+Î½+i+1) Î¾(n-1,i+1,n+i)

		and so we have 
		
    (a_i-1 -(K_n^-1K_n+1)_i,i-1) Î¾(n+1,i-1,n+i)
          - (Î½+n+i+1) (a_i-1Î¾(n+1,i-1,n+i) +(G(n+1))_i,i n+1+Î½+iÎ¾(n,i,n+i))
          = (n+1+Î½+i) Î¾(n,i,n+i) 
          + I(n)_i,i+1 (n+1+Î½+i)( a_iÎ¾(n,i,n+i) + (G(n))_i+1,i+1n+Î½+i+1Î¾(n-1,i+1,n+i)).

		Hence 
		
		
    M_1(n,i)Î¾(n+1,i-1,n+i)= M_2(n,i)Î¾(n,i,n+i)+M_3(n,i)Î¾(n-1,i+1,n+i),

		with M_1(n,i)=-(K_n^-1K_n+1)_i,i-1 - a_i-1(Î½+n+i),  M_2(n,i)=(G(n+1))_i,i + (n+Î½+i+1), and M_3(n,i)=(I(n))_i,i+1 G(n)_i+1,i+1.
		To finish the proof, notice that since K_n^-1 and K_n+1 are both lower triangular matrix with 1's in the diagonal, we have that
		
    (K_n^-1K_n+1)_i,i-1=(K_n^-1)_i,i-1+(K_n+1)_i,i-1  and   (K_n^-1)_i,i-1=-(K_n)_i,i-1,

		by definition of K_n's we have that
		
    (K_n^-1K_n+1)_i,i-1=a_i-1( (n+Î½+i)_i-1-(n+1+Î½+i)_i-1)=-a_i-1 i(n+1+Î½+i)_i-2.

		Hence, 
    M_1(n,i)=a_i-1( i(n+1+Î½+i)_i-2-(n+Î½+i)),

		as asserted.
		
		For the case i=1, j=n+1 in the expression (<ref>) we obtain
		
    0 = - R(0,n+1)_1,n+1-(n+2+Î½) R(0,n)_1,n+1-I(n)_1,2R(0,n)_2,n+1,
 
		then, from Corollary <ref> we have
		
    0 = - (Î½+2n+3)Î¾(n+1,1,n+1)-(n+2+Î½) Î¾(n,1,n+1)-I(n)_1,2 (Î½+2n+2) Î¾(n,2,n+1).
 
		As a consequence of Proposition <ref>	we have that	 
		
    Î¾(n,i,j) = a_i-1Î¾(n,i-1,j) +(G(n))_i,i n+Î½+iÎ¾(n-1,i,j)   for j<n+i,

		which implies that	
		
    Î¾(n,2,n+1) = a_1Î¾(n,1,n+1) +(G(n))_2,2 n+Î½+2Î¾(n-1,2,n+1),

		and 
		
    Î¾(n,1,j) =(G(n))_1,1 n+Î½+1Î¾(n-1,1,j)   for j<n+1.
 
		In particular    
    Î¾(n+1,1,n+1)=(G(n+1))_1,1 n+Î½+2Î¾(n,1,n+1).
 
		Thus, we obtain     
		
    N_1(n,i) Î¾(n,1,n+1)= N_2(n,i) Î¾(n-1,2,n+1),

		with 
		
    N_1(n,i)=	(Î½+2n+3) (G(n+1))_1,1 n+Î½+2 + (n+2+Î½) + I(n)_1,2 (Î½+2n+2) a_1,    N_2(n,i)=I(n)_1,2 (Î½+2n+2)(G(n))_2,2 n+Î½+2

		
		as desired.     
	
	
	
	As a consequence of Propositions <ref> and	<ref> we obtain the following result.
	
		Let nâ‰¥ 0 and let G(n),I(n) as in (<ref>). 
		Then, all of the non-zero entries of R(x,n) can be found in terms of G(â„“) and I(â„“)  and the generalized Laguerre polynomials 
		L^(Î±)_â„“ for â„“=0,â€¦,n.
	 
	
		The equality (<ref>) implies that
		(R(x,n))_i,j=L^(Î½+j)_n+i-j(x)Î¾(n,i,j) for n+i-jâ‰¥ 0. 
		It is enough to show that all of the non-zero constants Î¾(n,i,j) can be obtained in terms of G(â„“) and I(â„“) for â„“=0,â€¦,n+1.
		
		By items (a)'s of Propositions <ref> and <ref> we obtain the values of Î¾(0,i,j). 
		Thus, assume that n>0 and suppose that we want to determine Î¾(n,i,j) with n+i-j>0. 
		Notice that each time that we use items (b) and (c) of Proposition <ref>, 
		the value of "n+i-j" it reduces by 1, so if we use these items inductively we obtain that 
		Î¾(n,i,j) can be determined by the values of somes Î¾(n',i',j')'s with n'+i'-j'=0  and in each step also appear G(â„“) with â„“=0,â€¦,n.
		So, it is enough to see that we can determine Î¾(n,i,j) with n+i-j=0, in terms of G(â„“) and  I(â„“).
	
	
	 
		Notice that by Lemma <ref> and Propositions <ref>, <ref>, 
		we can replace (G(n))_i,i and (I(n))_i,i+1 by the expressions (â„‹_n(A^âˆ—-1)â„‹_n-1^-1))_i,i and (â„‹_n J â„‹_n^-1)_i,i+1, respectively.
	
	
	As a direct consequence of the above results and the equations obtained in Proposition <ref>, 
	we obtain a three-terms non-linear recursion for â„‹_n. With this in mind, we need the following lemma.
	
	
		Let A,Jâˆˆ M_N(â„‚) be matrices as in (<ref>).
		Then, the matrix â„‹_1 can be obtained from â„‹_0.
	
	
		By (<ref>), we have that
		
    â„‹_1=(X(1)+[J,X(1)])â„‹_0 (A^*-1)^-1.

		So, it is enough to show that we can obtain X(1) in terms of â„‹_0.
		
		In order to show this, recall that P(x,1)=x+ X(1). 
		Let us put P_1(x):=P(x,1), by applying the operator D=âˆ‚_x^2 x +âˆ‚_x ( (A-1)x +1+Î½+J) +AÎ½ + JA -J to P_1(x), we have that
		
    (P_1Â· D)(x)=  (A-1)x +1+Î½+J + (x+X(1))(AÎ½ + JA -J),

		by taking into account that P_1Â· D= Î“_1 Â· P_1, where Î“_1 is the discrete constant operator A(Î½+2+J)-1-J. 
		So we obtain that
		
    (A-1)x +1+Î½+J + (x+X(1))(AÎ½ + JA -J)= (A(Î½+2+J)-1-J)(x+X(1)).

		After some computation, we obtain that
		
    X(1)(AÎ½ + JA -J) +1+Î½+J = (A(Î½+2+J)-1-J)X(1),

		by taking into account that [J,A]=A, we obtain that JA=A+AJ and hence
		
    [X(1),A(1+Î½+J) ] +X(1)+[J,X(1)] + 1+Î½+J -AX(1)=0.

		Thus, by seeing the (i,j)-th coordinate in the above equality we obtain the following recurrences
		
    a_j(Î½+j+1) X(1)_1,j+1+ (2-j) X(1)_1,j+ (1+Î½+J)_1,j=0,

		
    a_j(Î½+j+1) X(1)_i,j+1- a_i-1(Î½+i+1)X(1)_i-1,j + (1+i-j) X(1)_i,j+ (1+Î½+J)_i,j=0   for iâ‰¥ 2.

		
		Recall that by Theorem <ref> we have that 
		(R(0,1))_i,j=0 if i+1< j.
		
		Claim:  If i+1<j then X(1)_i,j=0.
		
		We are going to prove this assertion by induction on i.
		Assume first that i=1 and let us consider  j>2,  in this case
		
    0=(R(0,1))_1,j= (K_1 P(0,1))_1,j=âˆ‘_r=1^N(K_1)_1,r X(1)_r,j=X(1)_1,j.

		
		Now, let i>1 and assume that the statement is true for r<i, that is X(1)_r,j=0 when r+1<j. 
		Thus, if i+1<j then
		
    0=(R(0,1))_i,j= (K_1 P(0,1))_i,j=âˆ‘_r=1^N(K_1)_i,r X(1)_r,j= (K_1)_i,iX(1)_i,j=X(1)_i,j.

		By induction hypothesis and by taking into account that K_1 is a lower triangular matrix with 1's  in its diagonal, 
		we have that 
		
    âˆ‘_r=1^N(K_1)_i,r X(1)_r,j=âˆ‘_r=1^i(K_1)_i,r X(1)_r,j= (K_1)_i,iX(1)_i,j=X(1)_i,j.

		Therefore, X(1)_i,j=0 when i+1<j as claimed.
		
		Hence, by equations (<ref>) and (<ref>), we can observe by a recursive argument, that in order to compute X(1), 
		it is enough to know the value of X(1)_i,i+1 for any iâ‰¥ 1.
		By taking into account that 
		
    (R(0,1))_i,i+1=(K_1 P(0,1))_i,i+1=âˆ‘_r=1^i(K_1)_i,r (X(1))_r,i+1=X(1)_i,i+1,

		thus by Corollary <ref>, we obtain that
		
    X(1)_i,i+1=(R(0,1))_i,i+1=Î¾(1,i,i+1).

		Thus, by item (a) of Proposition <ref>, we obtain that 
		
    X(1)_i,i+1=Î¾(1,i,i+1)=I(0)_i,i+1= (â„‹_0 J â„‹_0^-1)_i,i+1.

	
	
	
		Let A,Jâˆˆ M_N(â„‚) be matrices as in (<ref>).
		Then,
		
    â„‹_n+2 = (A-1)^-2( (-[J,â„‹_n J â„‹_n^-1] - â„‹_n (A^t-1) â„‹_n-1^-1 (A-1) + (A-1) â„‹_n+1 (A^t-1) â„‹_n^-1)(A-1) 
    
    				-2-â„‹_n+1 J â„‹_n+1^-1 + â„‹_n J â„‹_n^-1 +(A-1)[J,â„‹_n+1 J â„‹_n+1^-1]+(A-1)â„‹_n+1(A^t-1)â„‹_n^-1(A-1) )â„‹_n+1 (A^t-1)^-1,

		where B_n,C_n and â„‹_n be as in (<ref>). 
		
		Moreover,
		
    (â„‹_0)_i,j = Î“(Î½) âˆ‘_r=1^min{i,j}Î´_r^(Î½)/(i-r)!(j-r)!(âˆ_k=r^i-1 a_k ) (âˆ_s=r^j-1 a_s) (Î½)_i+j-r,

		where Î“ is the Gamma function.
	
	
		By (<ref>), we have that
		
    B_n+1 =(A-1)^-1(B_n (A-1) - 2 - â„‹_n+1 J â„‹_n+1^-1 + â„‹_n J â„‹_n^-1).

		On the other hand, the equation (<ref>) implies
		
    B_n = -[J,â„‹_n J â„‹_n^-1] - â„‹_n (A^t-1) â„‹_n-1^-1 (A-1) + (A-1) â„‹_n+1 (A^t-1) â„‹_n^-1.

		
    B_n+1 = -[J,â„‹_n+1 J â„‹_n+1^-1] - â„‹_n+1 (A^t-1) â„‹_n^-1 (A-1) + (A-1) â„‹_n+2 (A^t-1) â„‹_n+1^-1

		The statement it follows by changing B_n+1, and B_n in (<ref>).
		
		For the last assertion, by definition we have that
		
    â„‹_0= âˆ«_0^âˆ e^xA T^(Î½)(x)e^xA^âˆ— dx     with    T^(Î½)(x)=e^-xâˆ‘_k=1^NÎ´_k^(Î½)x^Î½+kE_k,k.
 
		Then,
		
    (â„‹_0)_i,j = âˆ‘_r=1^NÎ´_r^(Î½)âˆ«_0^âˆ e^-x x^(Î½+r) (e^xA)_i,r (e^xA^âˆ—)_r,j.

		By taking into account that A^âˆ—_r,j=A_j,r, and (e^xA)_i,r=1(i-r)!((xA)^i-r)_i,r if r< i and 
		0 otherwise, we have
		
    (â„‹_0)_i,j = âˆ‘_r=1^min{i,j}Î´_r^(Î½)âˆ«_0^âˆ e^-x x^(Î½+r)((xA)^i-r)_i,r(i-r)!((xA)^j-r)_j,r(j-r)! dx = âˆ‘_r=1^min{i,j}Î´_r^(Î½)(A^i-r)_i,r(i-r)!(A^j-r)_j,r(j-r)!âˆ«_0^âˆ e^-x x^(Î½+i+j-r) dx.

		Notice that (A^i-r)_i,r= âˆ_k=r^i-1a_k, and recall that Î“(z+1)=âˆ«_0^âˆ e^-x x^z dx, we can write 
		
    (â„‹_0)_i,j= âˆ‘_r=1^min{i,j}Î´_r^(Î½)/(i-r)!(j-r)!(âˆ_k=r^i-1 a_k ) (âˆ_s=r^j-1 a_s) Î“(Î½+i+j-r+1).

		
		Taking into account that Î“(z+1)=zÎ“(z) we obtain that
		
    (â„‹_0)_i,j = Î“(Î½) âˆ‘_r=1^min{i,j}Î´_r^(Î½)/(i-r)!(j-r)!(âˆ_k=r^i-1 a_k ) (âˆ_s=r^j-1 a_s) (Î½)_i+j-r,

		as asserted.
	
	
	
		Notice that we also have the expression 
		
    â„‹_0 = (L^(Î½)_Î¼(0))^-1â„‹^(Î½,Î½)_0 (L^(Î½)_Î¼(0))^âˆ—,
 
		with L^(Î½)_Î¼(0) and  â„‹^(Î½,Î½)_0 defined 
		in <cit.>, where 
		
    Î¼=(Î¼_1, â€¦, Î¼_N)   such that  a_i=Î¼_i+1Î¼_i  for i=1, â€¦, N-1.

		This assertion can be deduced from W^Î½(x)= (L^(Î½)_Î¼(0))^-1 W^(Î½,Î½)(x) (L^(Î½)_Î¼(0))^âˆ—, where W^(Î½,Î½)(x) are as in <cit.>. 
		They also proved that  â„‹^(Î½,Î½)_0 is a diagonal matrix.
	
	
	
	The following result gives a recursion for X(n)'s in terms of I(n).
	
	
		For n â‰¥ 1, let I(n) as in (<ref>).
		If Î´_i,j denotes the kronecker delta function, then: 
		
			
  * n Î´_1,j + X(n)_1,j+1 a_j - X(n)_1,j = -(n+1+Î½)Î´_1,j - I(n)_1,j.
			
			
  * n Î´_i,j + X(n)_i,j+1 a_j - a_i-1 X(n+1)_i-1,j - X(n)_i,j + X(n+1)_i,j = -(n+1+Î½)Î´_i,j - I(n)_i,j for iâ‰¥ 2.
		
	
	
	
		By Corollary <ref>, we have that
		
    n+X(n)A - A X(n+1)-B(n) = -(n+1+Î½)-â„‹(n)Jâ„‹^-1(n).

		The result is a direct consequense of taking (i,j)-th coordinate in the above equation.
	
	
	
		
			
  * By item (a) of Corollary <ref> we can obtain that G(n)_i,i=X(n)_i,i for any i â‰¥ 1.
			
  * In order to compute P(x,n), for a given n, we can do the following:
			
				
  * Compute â„‹_n and the explicit form of â„‹_0, â„‹_1 
				using Lemma <ref> and Proposition <ref>.
				
  * Compute G(n) and I(n) using â„‹_n.
				
  * Compute the Î¾(n,i,j) using the recursions of Propositions <ref> and <ref>. 
				
  * Then we have R(x,n) and so P(x,n)=K_n R(x,n) e^-xA.
			
		
	
	
	
	

Â§ MATRIX ENTRIES OF P(X,N) IN TERMS OF LAGUERRE AND DUAL HAHN POLYNOMIALS.

	
	In this section, we will show that under some hypothesis, the Î¾(n,i,j)'s can be expressed in terms of dual Hahn polynomials. 
	
	

 Â§.Â§  Some technical lemmas

	Let Nâ‰¥ 1 be a fixed integer and let Î¼=(Î¼_1,â€¦,Î¼_N) be a sequence of non-zero coefficients and Î±>0.
	Then L_Î¼^() is the NÃ— N unipotent lower triangular matrix defined by
	
    L^(Î±)_Î¼(x)_m,n=Î¼_m/Î¼_n L^(Î±+n)_m-n(x),     mâ‰¥ n,
    
    			0    n<m.

	For Î½>0 we consider the weight matrix
	
    W^(Î±,Î½)_Î¼(x)=L_Î¼^(Î±)(x) T^(Î½)(x) L_Î¼^(Î±)(x)^âˆ—,     T^(Î½)(x)=e^-xâˆ‘_k=1^N x^Î½+kÎ´_k^(Î½)  E_k,k.

	It can be showed that
	
    W_Î¼^(Î±, Î½)(x) = L^(Î±)_Î¼(0) e^xA_Î¼ T^(Î½)(x) e^xA_Î¼^âˆ—  L^(Î±)_Î¼(0)^âˆ—  where   
    		A_Î¼=- âˆ‘_k=1^N-1Î¼_k+1Î¼_kE_k+1,k.

	We impose conditions on the sequence {Î¼_i}_i=1^N and the coefficients Î´_k^(Î½). 
	First of all, we assume that the coefficients Î¼_i are real and non-zero for all i 
	and Î´_k^(Î½)>0, 1â‰¤ kâ‰¤ N, so that the weight matrix is positive definite 
	(see <cit.> for more information about the weight matrix W^(Î±,Î½)_Î¼).
	On the other hand, we consider the diagonal matrix Î”^(Î½) = diag(Î´_1^(Î½), â€¦, Î´_N^(Î½)), so that (T^(Î½))_k,k=e^-x x^Î½+k (Î”^(Î½))_k,k. We assume that there exist coefficients c^(Î½) and d^(Î½) such that 
	
    Î”^(Î½+1)=(d^(Î½) J+c^(Î½))  Î”^(Î½).

	We also assume that the coefficients Î¼_k and Î´^(Î½)_k satisfy the  relation
	
    Î¼_k+1^2Î¼_k^2=d^(Î½)k(N-k) Î´_k+1^(Î½)Î´_k^(Î½+1),      k=1,â€¦,N-1.
	
	Under the above conditions, Propositions 5.1 and 5.2 from <cit.> say that 
	
    Î¦^(Î±, Î½)(x)=(W_Î¼^(Î±, Î½)(x))^-1W_Î¼^(Î±, Î½+1)(x) 
    		  and  Î¨^(Î±, Î½)(x)=(W_Î¼^(Î±, Î½)(x))^-1dW_Î¼^(Î±, Î½+1)dx(x)
	
	are matrix polynomials of degree 2 and 1 respectively.
	Moreover, Corollary 6.3 from <cit.> asserts 
	that the operator D_2 defined by 
	
    D_2(x)= d^2dx^2Î¦^âˆ—(x) + ddxÎ¨^âˆ—(x)

	is symmetric respect to W_Î¼^(Î±, Î½).	
	
	
	We begin with the following technical lemma which relates the matrix polynomials R_n(x) 
	with the constants c^( Î½) and d^( Î½). The proof of Lemma <ref> and Lemma <ref> can be found in the appendix.
	
		Let Î¼=(Î¼_1,â€¦,Î¼_N) and Î´^(Î½)_k>0 for 1â‰¤ kâ‰¤ N, satisfying (<ref>) and (<ref>).
		Let A:=A_Î¼ as in (<ref>).
		If R(x,n) are the matrix polynomials defined in (<ref>), then
		
    (  R'(0,n)- R(0,n) A)C^(Î½)=D^(Î½)R(0,n)

		where C^(Î½)= (d^(Î½)J+c^(Î½))(Î½+J+1)+ ((Î”^(Î½))^-1A Î”^(Î½+1))^âˆ— and
		D^(Î½)= n(d^(Î½)(J-N-1)-c^(Î½))
		with c^( Î½) and d^( Î½) as in (<ref>).
	
	
	
	
	In the sequel, let 0 â‰¤ n, 1 â‰¤ i â‰¤ N. We consider the sequence Ïµ_j:=Ïµ_j^(n,i) defined recursively by  
	
    Ïµ_0=1,     Ïµ_j=(n+i-j+1) d^(Î½)((j-1) + c^(Î½)d^(Î½)) Ïµ_j-1  for n+i-j â‰¥ 0,

	with c^(Î½), d^(Î½) defined as in (<ref>).    
	We have the following result.
	
	
		Let 0â‰¤ n and let 1 â‰¤ N, 1 â‰¤ i â‰¤ N integers and let {Ïµ_l}_l=0^i+n be the sequence defined as in (<ref>). 
		If Î½>0, Î´^(Î½) satisfies (<ref>) and 0 â‰¤ j < n+i, we have
		
    Ïµ_jÏµ_j+1M_j=1
    		    where     M_j= (n+i-j) (d^(Î½) j + c^(Î½))

		with c^(Î½), d^(Î½) as in (<ref>).
	
	
		It follows by a simple inductive argument from the definition of Ïµ_j.
	
	
	Given i=1,â€¦,N, n â‰¥ 0 and  j a positive integer such that n+i-j â‰¥ 0, 
	in the sequel we consider the sequence q_j:=q_j^(n,i) by the expression
	
    q_j^(n,i) := Ïµ_j^(n,i)Î¾(n,i,j),

	where Ïµ_j's are as in (<ref>).
	
	
		
		Let Î¼=(Î¼_1,â€¦,Î¼_N) and Î´^(Î½)_k>0 for 1â‰¤ kâ‰¤ N, satisfying (<ref>) and (<ref>). 
		For 1 â‰¤ i â‰¤ N and 0 â‰¤ n, let {q_l}_l=0^i+n be the sequence as in (<ref>).
		Then, the sequence {q_l}_l=0^i+n satisfies
		
    E_j q_j +  F_j  q_j-1 + 1d^(Î½)   q_j+1 = 0,    n+i-j > 0,

		where 
		
    E_j    =(n+i-j) ( j + c^(Î½)d^(Î½)) +  (j-1) (N-j+1) + n  ( (i-N-1)-c^(Î½)d^(Î½)) ,
    
    			F_j    =(j-1) (N-j+1) Î¼_j-1Î¼_j  (n+i-j+1)  (d^(Î½) (j-1) + c^(Î½))

		with c^(Î½), d^(Î½) as in (<ref>).
	
	
	

 Â§.Â§ Dual Hahn polynomials

	
	For 0 â‰¤ n, 1 â‰¤ i â‰¤ N let us consider the following sequence 
	
    q_j^(n,i):= (d^(Î½))^-j q_j^(n,i),    n+i-j > 0,
where q_j's are as in (<ref>) and d^(Î½) as (<ref>).
	
	
	
		Let Î¼=(Î¼_1,â€¦,Î¼_N) and 0 < Î´^(Î½)_k, for 1â‰¤ kâ‰¤ N, satisfying (<ref>) and (<ref>). 
		Let q_l be  as in (<ref>).
		If Î¼_j=1 for all j then the q_l's satisfy the following equation
		
    E_j q_j+ F_j  q_j-1 +  q_j+1 = 0,    n+i-j > 0,

		where
		
    E_j    =(n+i-j) ( j + c^(Î½)d^(Î½)) +  (j-1) (N-j+1) + n  ( i-N-1-c^(Î½)d^(Î½)), 
    F_j    = (j-1) (N-j+1)  (n+i-j+1)  (j-1 + c^(Î½)d^(Î½))

		with c^(Î½), d^(Î½) as in (<ref>).
	
	
		By Lemma <ref>, we have that E_j q_j +  F_j  q_j-1 + 1d^(Î½)   q_j+1 = 0
		with 
		
    E_j    =(n+i-j) ( j + c^(Î½)d^(Î½)) +  (j-1) (N-j+1) + n  ( (i-N-1)-c^(Î½)d^(Î½)) ,
    
    				F_j    =(j-1) (N-j+1) Î¼_j-1Î¼_j  (n+i-j+1)  (d^(Î½) (j-1) + c^(Î½)).

		Now, since Î¼_j=1 for all j and  q_j(x):= (d^(Î½))^-j q_j(x),
		we have that
		
    ((n+i-j) ( j + c^(Î½)d^(Î½)) +  (j-1) (N-j+1) + n  ( (i-N-1)-c^(Î½)d^(Î½)) ) q_j(d^(Î½))^j
       +     (j-1) (N-j+1)  (n+i-j+1)  (d^(Î½) (j-1) + c^(Î½)) (d^(Î½))^j-1q_j-1 + 1d^(Î½)(d^(Î½))^j+1q_j+1 = 0.

		By multiplication for (d^(Î½))^-j, we obtain that
		
    E_j q_j+ F_j  q_j-1 +  q_j+1 = 0,

		with
		
    E_j    =(n+i-j) ( j + c^(Î½)d^(Î½)) +  (j-1) (N-j+1) + n  ( i-N-1-c^(Î½)d^(Î½)), 
    F_j    = (j-1) (N-j+1)  (n+i-j+1)  (j-1 + c^(Î½)d^(Î½)),

		as asserted.
	
	
	Recall that if the sequence of polynomials  {s_k} satisfies the normalized recurrence relations 
	
    xs_k(x)= s_k+1(x) -(u_k+v_k) s_k(x)+u_k-1v_k s_k-1(x),

	with 
	
    u_k=(k+Î³+1)(k-M),      v_k=k(k-Î´-M-1),

	then s_k satisfies 
	
    T_k(Î»(x);Î³,Î´,M) = 1(Î³+1)_k (-M)_k s_k(Î»(x))
 
	where Î»(x)= x(x+Î³+Î´ +1) and {T_k} is the sequence of dual Hahn polynomials defined by
	
    T_k(Î»(x);Î³,Î´,M)=  _3 F_2(-k,      -x,      x+Î³+Î´+1
          Î³+1,      -M   ;1)     for  k=0,1,â€¦,M.

	
		Let Î¼=(Î¼_1,â€¦,Î¼_N) and Î´^(Î½)_k>0 for 1â‰¤ kâ‰¤ N, satisfying (<ref>) and (<ref>). 
		Let q_j be  as in (<ref>).
		If Î¼_â„“=1 for all â„“=1,â€¦,N, then the q_j's satisfy
		
    q_j= (Î³+1)_j-1(-(N-1))_j-1 T_j-1(Î»(x^(n,i)); Î³,Î´, N-1)    n+i-j > 0

		where Î³= c^(Î½)d^(Î½),  Î´=n+i-N and x^(n,i)=(Î³+1)(N+i-2)-n(N-i).
	
	
		By Lemma <ref>, we have that
		
    E_j q_j+ F_j  q_j-1 +  q_j+1 = 0,    n+i-j > 0,

		where
		
    E_j    =(n+i-j) ( j + c^(Î½)d^(Î½)) +  (j-1) (N-j+1) + n  ( i-N-1-c^(Î½)d^(Î½)), 
    F_j    = (j-1) (N-j+1)  (n+i-j+1)  (j-1 + c^(Î½)d^(Î½))

		with c^(Î½), d^(Î½) as in (<ref>). Now, if we consider
		
    u_k=(k+Î³+1)(k-M) and  v_k=k(k-Î´-M-1),

		with Î³= c^(Î½)d^(Î½), Î´=n+i-N and M=N-1. It is straightforward to check that
		
    F_j = u_j-2 v_j-1  and  E_j = -(u_j-1+v_j-1+x^(n,i))
	
		where x^(n,i)=(Î³+1)(N+i-2)-n(N-i). 
		Thus, since q_j can be seen as constants polynomial, 
		we have that
		
    x^(n,i)q_j(x^(n,i)) = 
    		q_j+1(x^(n,i)) -(u_j-1+v_j-1) q_j(x^(n,i))+u_j-2 v_j-1q_j-1(x^(n,i)).

		Therefore, by definition of dual Hahn polynomials and by taking into account that q_j is a constant polynomial, we obtain (<ref>) as desired.
	
	
	
	By recalling that q_j=(d^(Î½))^-j q_j = Ïµ_j (d^(Î½))^-jÎ¾(n,i,j) for n+i-j > 0, we obtain the following result
	
	
		Let Î¼=(Î¼_1,â€¦,Î¼_N) and Î´^(Î½)_k > 0, for 1â‰¤ kâ‰¤ N, satisfying (<ref>) and (<ref>). Let Ïµ_j as in (<ref>).
		If Î¼_â„“=1 for all â„“=1,â€¦,N, then the constants Î¾(n,i,j)'s satisfy
		
    Î¾(n,i,j)= (d^(Î½))^j(Î³+1)_j-1(-(N-1))_j-1Ïµ_j T_j-1(Î»(x^(n,i)); Î³,Î´, N-1),    n+i-j > 0

		where Î³= c^(Î½)d^(Î½),  Î´=n+i-N and x^(n,i)=(Î³+1)(N+i-2)-n(N-i).
		Moreover, if n+i=j, the constants Î¾(n,i,j)'s satisfy the recursion	
		
    Î¾(0,1,1)=1Î½ +2,     Î¾(n,i,j-1) =
    			( n(N+1-i)(i-1)(j-1) (N-j+1) + 1 )Î¾(n,i,j),    j >1,

		
	
	
		If n+i-j > 0, by Proposition <ref> we have that 
		
    Î¾(n,i,j)=(d^(Î½))^jÏµ_jq_j= (d^(Î½))^j(Î³+1)_j-1(-(N-1))_j-1Ïµ_j T_j-1(Î»(x^(n,i)); Î³,Î´, N-1)

		with Î³= c^(Î½)d^(Î½),  Î´=n+i-N and x^(n,i)=(Î³+1)(N+i-2)-n(N-i) as asserted.	
		
		Now, if we take j=n+i in the expression (<ref>), we obtain
		
    R_n'(0)_i,j (d^(Î½) j + c^(Î½)) (Î½ + j +1)  + R_n'(0)_i(j-1)((Î”^(Î½))^-1A Î”^(Î½+1))^âˆ—_(j-1)j
           - (R_n(0)_i,j A_j(j-1)((Î”^(Î½))^-1A Î”^(Î½+1))^âˆ—_(j-1),j = n(d^(Î½)(J-N-1)-c^(Î½)) R(n,0)_i,j.

		
		
		
		By taking into account that R_n(x)_i,j=L^(Î½+j)_n+i-j(x) Î¾(n,i,j), 
		
    L^Î±_n(0)=(Î±+1)_nn!    and    âˆ‚âˆ‚ xL^Î±_n(x)=(-1) L^Î±+1_n-1(x),

		we have
		
    - Î¾(n,i,j-1) ((Î”^(Î½))^-1A Î”^(Î½+1))^âˆ—_(j-1)j   -    (Î¾(n,i,j) A_j(j-1)((Î”^(Î½))^-1A Î”^(Î½+1))^âˆ—_(j-1),j
       =    n(d^(Î½)(i-N-1)-c^(Î½)) Î¾(n,i,j).

		Recall that by (<ref>) we have that
		
    ((Î”^(Î½))^-1 A Î”^(Î½+1))^âˆ—_(j-1,j) = d^(Î½) (j-1) (N-j+1) Î¼_j-1Î¼_j,

		then, taking in account that Î¼_k=1 for all k, we have
		
    - Î¾(n,i,j-1) d^(Î½) (j-1) (N-j+1)     -    (Î¾(n,i,j) A_j(j-1)d^(Î½) (j-1) (N-j+1) 
       =    n(d^(Î½)(i-N-1)-c^(Î½)) Î¾(n,i,j).

		
		Thus, using the conditions (<ref>), (<ref>), and taking in account that A_s,s-1=-1, we obtain
		
    - d^(Î½) (j-1) (N-j+1) Î¾(n,i,j-1) =
    				(-nd^(Î½)(N+1-i)(i-1) - d^(Î½) (j-1) (N-j+1) )Î¾(n,i,j),

		as desired.
		
		The last assertion it follows from 
    Î¾(0,1,1)(Î½ +2)=Î¾(0,1,1) L^1_1(0)=R(0,0)_1,1=(K_1 P(0,0))_1,1=1

		
	
	
	
	plain
			
	
	

Â§ 

	
	In this apprendix we give the proofs of the  Lemmas <ref> and <ref>.
	
	
		Let P_n(x)=P(x,n) be the sequence of monic orthogonal polynomials 
		respect to the weight W^(Î½) as in (<ref>).
		Since W_Î¼^(Î±, Î½)(x)=L_Î¼^(Î±)(0) W^(Î½)(x) L_Î¼^(Î±)(0)^* we have that 
		
    âˆ«_0^âˆ P_n(x) (L_Î¼^(Î±)(0)^-1)W_Î¼^(Î±, Î½)(x) (P_m(x)L_Î¼^(Î±)(0)^-1)^* dx =âˆ«_0^âˆ P_n(x) W^(Î½)(x) P_m(x)^* dx= Î´_n,mâ„‹_n.

		Hence, if P_n^(Î±,Î½)(x)=L_Î¼^(Î±)(0) P_n(x) L_Î¼^(Î±)(0)^-1 then  
		P^(Î±,Î½)_n(x) is the sequence of monic orthogonal polynomials with respect to the weight W_Î¼^(Î±, Î½).
		Now, if D_2 is the operator defined in (<ref>), the Corollary 6.3 of <cit.> implies that
		P^(Î±,Î½)_n D_2= n KÌ‚_n^(Î±,Î½) P^(Î±,Î½)_n 
		for certain matrix KÌ‚_n^(Î±,Î½) defined recursively in section 6 from <cit.>, and so 
		
    P_n L_Î¼^(Î±)(0)^-1D_2 L_Î¼^(Î±)(0)=nL_Î¼^(Î±)(0)^-1KÌ‚_n^(Î±,Î½) L_Î¼^(Î±)(0) P_n.

		By Proposition 6.1 of <cit.>, we obtain that
		
    (L_Î¼^(Î±)(0))^-1KÌ‚_n^(Î±,Î½) L_Î¼^(Î±)(0)=d^(Î½)(J-(J+Î½+n)A-N-1)-c^(Î½),
 
		and by taking into account that JA-AJ=A, we have that
		
    J-JA-(Î½+n)A-N-1=J-AJ-A-(Î½+n)A-N-1.

		On the other hand, since Î“_n=A(n+Î½+J+1)-(n+J)=-J+(n+Î½)A+A+AJ-n, then
		
    (L_Î¼^(Î±)(0))^-1KÌ‚_n^(Î±,Î½) L_Î¼^(Î±)(0)=d^(Î½)(-Î“_n-n-N-1)-c^(Î½).

		By (<ref>), we have that
		
    K_n R_n e^-xA(L_Î¼^(Î±)(0))^-1D_2 L_Î¼^(Î±)(0)= n (L_Î¼^(Î±)(0))^-1KÌ‚_n^(Î±,Î½) L_Î¼^(Î±)(0)K_n R_n e^-xA

		and thus
		
    R_n e^-xA(L_Î¼^(Î±)(0))^-1D_2 L_Î¼^(Î±)(0)e^xA=n K_n^-1(d^(Î½)(-Î“_n-n-N-1)-c^(Î½))K_n R_n.

		By recalling that K_n^-1Î“_n K_n =-n-J, we have that
		
    R_n e^-xA(L_Î¼^(Î±)(0))^-1D_2 L_Î¼^(Î±)(0)e^xA=n(d^(Î½)(J-N-1)-c^(Î½))R_n.

		Now, by taking into account that D_2= d^2dx^2Î¦^âˆ—(x) + ddxÎ¨^âˆ—(x) with Î¦, Î¨ polynomials of degree 2 and 1. In general, if U(x) is a polynomial, we have that
		
    U(x) Â· e^-xA(L_Î¼^(Î±)(0))^-1D_2 L_Î¼^(Î±)(0)e^xA    =    d^2dx^2( U(x) e^-xA) (L_Î¼^(Î±)(0))^-1Î¦^âˆ—(x) L_Î¼^(Î±)(0)e^xA
           + ddx( U(x) e^-xA) (L_Î¼^(Î±)(0))^-1Î¨^âˆ—(x) L_Î¼^(Î±)(0)e^xA
        =    ( Uâ€(x)-2 U'(x)A+ U(x) A^2) e^-xA(L_Î¼^(Î±)0))^-1Î¦^âˆ—(x) L_Î¼^(Î±)(0)e^xA
           + (  U'(x)- U(x) A) e^-xA(L_Î¼^(Î±)(0))^-1Î¨^âˆ—(x) L_Î¼^(Î±)(0)e^xA.

		Hence, we want to find some easy expression for
		
    e^-xA L(0)^-1Î¦^âˆ—(x) L(0) e^xA  and   e^-xA L(0)^-1Î¨^âˆ—(x) L(0) e^xA.

		Some similar expressions was studied by Koelink and Roman (see <cit.>).
		By Corollary 5.3 in <cit.>, we have that
		
		 
    L_Î¼^(Î±)(0)^âˆ—Î¦(x) ((L_Î¼^(Î±)(0))^âˆ—)^-1   =     -d^(Î½)x^2 A^âˆ—+x (d^(Î½) J +c^(Î½))
    
    				L_Î¼^(Î±)(0)^âˆ—Î¨(x) ((L_Î¼^(Î±)(0))^âˆ—)^-1    =     x(d^(Î½)(J-A^âˆ—(J+Î½+1) -N-1)-c^(Î½)) ) 
           + (Î½+J+1)(d^(Î½)J+c^(Î½))+(Î”^(Î½))^-1A Î”^(Î½+1).

		Hence, we have that
		
    e^-xAL_Î¼^(Î±)(0)^-1Î¦^âˆ—(x)L_Î¼^(Î±)(0) e^xA   =    -d^(Î½)x^2 e^-xAA e^xA+xd^(Î½)e^-xAJe^xA+x c^(Î½)
       =    -d^(Î½)x^2 A +xd^(Î½)(xA+J)+ xc^(Î½)
       =    x(d^(Î½)J+c^(Î½)).

		
    e^-xAL_Î¼^(Î±)(0)^-1Î¨^âˆ—(x)L_Î¼^(Î±)(0) e^xA   =    x(d^(Î½)(xA+J-(xA+J+Î½+1)A-N-1)-c^(Î½)) ) 
           + (d^(Î½)(xA+J)+c^(Î½))(Î½+xA+J+1)+e^-xA ((Î”^(Î½))^-1A Î”^(Î½+1))^âˆ— e^xA.

		By evaluation in x=0 in (<ref>) and by taking into account the above expressions, 
		we obtain (<ref>), as desired.
	
	
	
	
		By taking into account that (R_n(x))_i,j satisfies the expression given by Theorem <ref>, the (i,j)-coordinate of the matrix in the right hand of (<ref>) is 
		
    n(d^(Î½)(i-N-1)-c^(Î½))(R_n(0))_i,j= n(d^(Î½)(i-N-1)-c^(Î½))L^(Î½+j)_n+i-j(0) Î¾(n,i,j).

		On the other hand, for n+i-j > 0 the (i,j)-coordinate of the matrix in the left hand of (<ref>) is
		
    R_n'(0)_i,j (d^(Î½) j + c^(Î½)) (Î½ + j +1)  + R_n'(0)_i(j-1)((Î”^(Î½))^-1A Î”^(Î½+1))^âˆ—_(j-1)j
           - R_n(0)_i(j+1) (d^(Î½) j + c^(Î½)) (Î½ + j +1) A_(j+1)j  - (R_n(0)_i,j A_j(j-1)((Î”^(Î½))^-1A Î”^(Î½+1))^âˆ—_(j-1),j.

		By taking into account that R_n(x)_i,j=L^(Î½+j)_n+i-j(x) Î¾(n,i,j), 
		
    L^Î±_n(0)=(Î±+1)_nn!    and    âˆ‚âˆ‚ xL^Î±_n(x)=(-1) L^Î±+1_n-1(x),

		we obtain that the above expression is equivalent to
		
    - n (d^(Î½) (i-N-1)-c^(Î½)) (Î½+j+1)_n+i-j(n+i-j)!Î¾(n,i,j)    =   (Î½+j+2)_n+i-j-1(n+i-j-1)! (d^(Î½) j + c^(Î½)) (Î½ +j +1) Î¾(n,i,j)
           + (Î½+j+1)_n+i-j(n+i-j)!( (Î”^(Î½))^-1 A Î”^(Î½+1))^âˆ—_(j-1,j)Î¾(n,i,j-1)
           + (Î½+j+2)_n+i-j-1(n+i-j-1)! (d^(Î½) j + c^(Î½)) (Î½+j+1) Î¾(n,i,j+1)
           + (Î½+j+1)_(n+i-j)(n+i-j)! A_j(j-1)((Î”^(Î½))^-1 A Î”^(Î½))^âˆ—_(j-1)jÎ¾(n,i,j).

		Thus, by taking into account that (Î½+j+2)_n+i-j-1(Î½ +j +1)= (Î½+j+1)_n+i-j-1, and  multiplying both sides by (n+i-j-1)!(Î½+j+1)_n+i-j-1, we obtain 
		
    - n (d^(Î½) (i-N-1)-c^(Î½)) (n+i-j-1)n+i-jÎ¾(n,i,j)    =     (d^(Î½) j + c^(Î½)) Î¾(n,i,j)
          +   (n+i-j-1)n+i-j( (Î”^(Î½))^-1 A Î”^(Î½+1))^âˆ—_(j-1,j)Î¾(n,i,j-1)
           +   (d^(Î½) j + c^(Î½)) Î¾(n,i,j+1)
          + (n+i-j-1)n+i-j A_j(j-1)((Î”^(Î½))^-1 A Î”^(Î½))^âˆ—_(j-1)jÎ¾(n,i,j).

		Finally, we obtain that 
		
    ((n+i-j)(d^(Î½) j + c^(Î½)) + A_j(j-1)((Î”^(Î½))^-1 A Î”^(Î½))^âˆ—_(j-1)j + n (d^(Î½) (i-N-1)-c^(Î½)) ) Î¾(n,i,j)
           + ( (Î”^(Î½))^-1 A Î”^(Î½+1))^âˆ—_(j-1,j)Î¾(n,i,j-1) +  (n+i-j) (d^(Î½) j + c^(Î½)) Î¾(n,i,j+1) = 0.

		By (<ref>) we have that Î´^(Î½)_k+1Î´^(Î½+1)_k = Î¼_k+1^2d^(Î½) k (N-k) Î¼_k^2,
		and then
		
    ((Î”^(Î½))^-1 A Î”^(Î½+1))^âˆ—_(j-1,j)   =   Î´^(Î½+1)_j-1Î´^(Î½)_j A_j(j-1)
       =    d^(Î½) (j-1) (N-j+1) Î¼_j-1^2Î¼_j^2Î¼_jÎ¼_j-1
       =    d^(Î½) (j-1) (N-j+1) Î¼_j-1Î¼_j.

		Thus, we can rewrite the above equation as follows 
		
    ((n+i-j)(d^(Î½) j + c^(Î½)) + d^(Î½) (j-1) (N-j+1) + n (d^(Î½) (i-N-1)-c^(Î½)) ) Î¾(n,i,j)
           + d^(Î½) (j-1) (N-j+1) Î¼_j-1Î¼_jÎ¾(n,i,j-1) +  (n+i-j) (d^(Î½) j + c^(Î½)) Î¾(n,i,j+1) = 0.

		Now, if we consider M_j=(n+i-j) (d^(Î½) j + c^(Î½)). 
		Since Ïµ^(n,i)_j Î¾(n,i,j) = q_j^(n,i),
		we can rewrite the above equation as follows
		
    ((n+i-j)(d^(Î½) j + c^(Î½)) + d^(Î½) (j-1) (N-j+1) + n (d^(Î½) (i-N-1)-c^(Î½)) ) q_jÏµ_j
     
    				+ d^(Î½) (j-1) (N-j+1) Î¼_j-1Î¼_jq_j-1Ïµ_j-1 +  M_j q_j+1Ïµ_j+1 = 0.

		If we multiply by Ïµ_j, we have that
		
    ((n+i-j)(d^(Î½) j + c^(Î½)) + d^(Î½) (j-1) (N-j+1) + n (d^(Î½) (i-N-1)-c^(Î½)) ) q_j 
     
    				+ d^(Î½) (j-1) (N-j+1) Î¼_j-1Î¼_jÏµ_jÏµ_j-1 q_j-1 +  M_j Ïµ_jÏµ_j+1 q_j+1 = 0.

		By Lemma <ref>, we have that M_j Ïµ_jÏµ_j+1 =1 and so we obtain 
		
    d^(Î½)((n+i-j)( j + c^(Î½)d^(Î½)) +  (j-1) (N-j+1) + n  ( (i-N-1)-c^(Î½)d^(Î½)) ) q_j 
       +    d^(Î½) (j-1) (N-j+1) Î¼_j-1Î¼_j  (n+i-j+1)  (d^(Î½) (j-1) + c^(Î½))  q_j-1 +   q_j+1 = 0,

		which is equivalent to 
		
    E_j q_j +  F_j  q_j-1 + 1d^(Î½)   q_j+1 = 0,

		with
		
    E_j    =(n+i-j) ( j + c^(Î½)d^(Î½)) +  (j-1) (N-j+1) + n  ( (i-N-1)-c^(Î½)d^(Î½)),
    
    				F_j    =(j-1) (N-j+1) Î¼_j-1Î¼_j  (n+i-j+1)  (d^(Î½) (j-1) + c^(Î½)),

		as asserted.
	
	
	
